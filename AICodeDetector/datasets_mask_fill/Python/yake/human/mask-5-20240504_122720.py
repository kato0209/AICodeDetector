num <extra_id_0> <extra_id_1> <extra_id_2> self.h <extra_id_3> <extra_id_4> size class TextCNN <extra_id_5> <extra_id_6> embedding <extra_id_7> <extra_id_8> embedding layer tf.Variable filters self.embedded chars pooled self.input classes import tf.constant CNN for text sequence length prob dropout tf.placeholder conv VALID predictions Accuracy total self.scores input Convolution Layer filter outputs Convolution Layer sizes convolution object add CNN TextCNN expanded self.dropout reg lambda tensorflow numpy class vocab self.W drop Keeping track output strides padding flat scores Create a convolution initializer self.predictions tf.argmax losses logits tf.reduce correct Layer filter Add dropout Placeholders Keeping Create softmax layer maxpool layer dropout self.input Final Apply nonlinearity Apply Maxpooling Combine text classification pooled features num Calculate Calculate mean cross-entropy features num Accuracy with tf.name Placeholders for input outputs pooled size pooled filter size pooled classification text filter size dropout with tf.name regularization loss predictions with tf.name max-pooling and softmax convolutional def init optional cpu tf.random uniform lookup tf.expand dims conv-maxpool softmax regularization tf.device maxpool enumerate tf.truncated normal stddev loss with tf.name pooled features track relu ksize outputs.append len tf.concat tf.reshape