if is_master:  if os.environ.get('PYSPARK_PYTHON'): # SPARK-27170: if we are running in a JVM, we can't use the SparkContext # as a Spark source , just try using a HiveConf to access it. return try: # Start the Spark StreamingContext, which disables the Spark StreamingContext. SparkContext._ensure_initialized() except Exception: pass try: # Try to access HiveConf, it will raise exception if Hive is not added