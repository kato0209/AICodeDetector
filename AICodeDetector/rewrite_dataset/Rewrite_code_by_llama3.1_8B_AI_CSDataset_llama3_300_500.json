[
    {
        "original": "\ndef _unpack_paths(cls, objs, items, counts):\n    for obj in objs:\n        if hasattr(obj, '__iter__') and not isinstance(obj, str):\n            cls._unpack_paths(obj, items, counts)\n        elif hasattr(obj, 'viewable_tree'):\n            cls._unpack_paths(obj.viewable_tree, items, counts)\n        else:\n            items.append(obj)\n            counts[obj] = counts.get(obj, 0) + 1\n",
        "rewrite": "```python\ndef _unpack_paths(cls, objs, items, counts):\n    for obj in objs:\n        if hasattr(obj, '__iter__') and not isinstance(obj, str):\n            cls._unpack_paths(obj, items, counts)\n        elif hasattr(obj, 'viewable_tree'):\n            cls._unpack_paths(obj.viewable_tree or [], items, counts)\n        else:\n            items.append(obj)\n            counts[obj] = (counts.get(obj) or 0) + 1\n```"
    },
    {
        "original": "\ndef compute_tls13_handshake_secrets(self):\n    \"\"\"\n    Ciphers key and IV are updated accordingly for Handshake data.\n    self.handshake_messages should be ClientHello...ServerHello.\n    \"\"\"\n    # Initialize variables\n    psk = bytearray()\n    binder_key = bytearray()\n    client_hello = self.handshake_messages[0]\n    server_hello = self.handshake_messages[1]\n    \n    # Derive early secret\n    early_secret = HKDF-expand-label(early",
        "rewrite": "```python\nimport hashlib\nfrom hashlib import spec\nfrom crypto_hash import HKDF_expand_label\n\nclass TLS13Handshake:\n    def compute_tls13_handshake_secrets(self):\n        \"\"\"\n        Ciphers key and IV are updated accordingly for Handshake data.\n        self.handshake_messages should be ClientHello...ServerHello.\n        \"\"\"\n        \n        # Initialize variables\n        psk = bytearray()\n        binder_key = bytearray()\n        \n        if len(self.handshake_messages) < 2:\n            raise ValueError(\"Insufficient handshake messages\")\n            \n        client_hello = self.handshake_messages[0]\n                    \n                \n                # Derive early secret"
    },
    {
        "original": "\ndef get_matrix(self):\n    matrix = {\n        'scenario_1': {\n            'subcommand': [\n                'action-1',\n                'action-2',\n            ],\n        },\n        'scenario_2': {\n            'subcommand': [\n                'action-1',\n            ],\n        },\n    }\n    return matrix\n",
        "rewrite": "```python\ndef get_matrix(self):\n    return {\n        'scenario_1': {'subcommand': ['action-1', 'action-2']},\n        'scenario_2': {'subcommand': ['action-1']},\n    }\n```"
    },
    {
        "original": "\nfrom ipywidgets import interactive\nimport ipywidgets as widgets\n\ndef interactive_output(f, controls):\n    return interactive(f, controls=controls)\n",
        "rewrite": "```python\nfrom ipywidgets import interactive, widgets\n\ndef interactive_output(f, controls):\n    return interactive(f, **controls)\n```"
    },
    {
        "original": "\nimport os\nimport shutil\n\ndef install_app(app, target='/Applications/'):\n    if not os.path.exists(target):\n        os.makedirs(target)\n    shutil.move(app, target)\n    return f\"App installed at {target}\"\n",
        "rewrite": "```python\nimport os\nimport shutil\n\ndef install_app(app, target='/Applications/'):\n    if not os.path.exists(target):\n        os.makedirs(target)\n    try:\n        shutil.move(app, target)\n        return f\"App installed at {target}\"\n    except FileNotFoundError:\n        return \"App not found\"\n    except PermissionError:\n        return \"Permission denied. Please run with admin privileges.\"\n```"
    },
    {
        "original": "\nimport logging\nfrom logging import Handler\n\nclass CustomHandler(Handler):\n    def __init__(self, level=logging.NOTSET):\n        super().__init__(level)\n\n    def emit(self, record):\n        # implement custom logging logic here\n        pass\n\ndef patch_python_logging_handlers():\n    root_logger = logging.getLogger()\n    root_logger.handlers = [CustomHandler()]\n",
        "rewrite": "```python\nimport logging\nfrom logging.handlers import MemoryHandler, TimedRotatingFileHandler, RotatingFileHandler\n\nclass CustomHandler(logging.Handler):\n    def __init__(self, level=logging.NOTSET):\n        super().__init__(level)\n\n    def emit(self, record):\n        # implement custom logging logic here\n        message = self.format(record)\n        if self.level <= record.levelno:\n            print(message)\n\ndef patch_python_logging_handlers():\n    root_logger = logging.getLogger()\n    root_logger.setLevel(logging.DEBUG) # set the level for the root logger\n    formatter = logging.Formatter('%(asctime)s - %(name)s -"
    },
    {
        "original": "\ndef _salt_send_event(opaque, conn, data):\n    event_data = {\n        'prefix': opaque['prefix'],\n        'object': opaque['object'],\n        'event': opaque['event']\n    }\n    event_data.update(data)\n    __salt__['event.send']('virt/' + opaque['prefix'] + '/' + opaque['event'], event_data)\n",
        "rewrite": "```python\ndef _salt_send_event(opaque, conn, data):\n    event_data = {\n        'prefix': opaque['prefix'],\n        'object': opaque['object'],\n        'event': opaque['event']\n    }\n    event_data.update(data)\n    __salt__['event.send'](\n        f'virt/{opaque[\"prefix\"]}/{opaque[\"event\"]}',\n        {**event_data}\n    )\n```"
    },
    {
        "original": "\ndef _extract_return(self, data):\n    return data.get('return', None)\n",
        "rewrite": "```python\ndef _extract_return(self, data):\n    return data.get('return')\n```"
    },
    {
        "original": "\nimport git\n\ndef modified_recipes(branch='origin/master'):\n    repo = git.Repo()\n    modified_files = repo.git.diff(branch, '--name-only').split('\\n')\n    recipes = [file for file in modified_files if file.endswith('.recipe')]\n    return set(recipes)\n",
        "rewrite": "```python\nimport git\n\ndef modified_recipes(branch='origin/master'):\n    repo = git.Repo()\n    modified_files = repo.git.diff(branch, '--name-only').splitlines()\n    recipes = [file for file in modified_files if file.endswith('.recipe')]\n    return set(recipes)\n```"
    },
    {
        "original": "\ndef get_interfaces_ip(self):\n    interfaces_ip = {\n        'FastEthernet8': {'ipv4': {'10.66.43.169': {'prefix_length': 22}}},\n        'Loopback555': {\n            'ipv4': {'192.168.1.1': {'prefix_length': 24}},\n            'ipv6': {\n                '1::1': {'prefix_length': 64},\n                '2001:DB8:1::1': {'prefix",
        "rewrite": "```python\ndef get_interfaces_ip(self):\n    interfaces_ip = {\n        'FastEthernet8': {'ipv4': {'10.66.43.169': {'prefix_length': 22}}},\n        'Loopback555': {\n            'ipv4': {'192.168.1.1': {'prefix_length': 24}},\n            'ipv6': {\n                '1::1/64',\n                '2001:DB8:1::1/64'\n            }\n        },\n        # Add more interfaces as needed\n    }\n    return interfaces_ip\n```\n\nNote that I've completed the ipv6 dictionary with a"
    },
    {
        "original": "\nclass StatsUpdater:\n    def __init__(self, filename):\n        self.filename = filename\n\n    def update(self, stats):\n        with open(self.filename, 'a', newline='') as file:\n            writer = csv.writer(file)\n            writer.writerow(stats)\n",
        "rewrite": "```python\nimport csv\n\nclass StatsUpdater:\n    def __init__(self, filename):\n        self.filename = filename\n\n    def update(self, stats):\n        if not isinstance(stats, list):\n            raise ValueError(\"Stats must be a list\")\n\n        with open(self.filename, 'a', newline='') as file:\n            fields = set()  # stores unique field names in previous stats\n            if file.tell() == 0:  # check if the file is empty\n                writer = csv.writer(file)\n                writer.writerow(stats)  # write the header only once\n                fields.update(stat for stat in stats)  \n           "
    },
    {
        "original": "\nimport os\nimport tarfile\nimport bz2\n\ndef unpack(name, dest=None, path=None, pack_format='tar', compress='bz2'):\n    if dest is None:\n        dest = os.getcwd()\n    if path is None:\n        path = os.path.join(dest, name)\n    else:\n        path = os.path.join(dest, path)\n    if not os.path.exists(dest):\n        os.makedirs(dest)\n    if pack_format == 'tar' and compress == 'bz",
        "rewrite": "```python\nimport os\nimport tarfile\nimport bz2\n\ndef unpack(name, dest=None, path=None, pack_format='tar', compress='bz2'):\n    if dest is None:\n        dest = os.getcwd()\n    if path is None:\n        path = os.path.join(dest, name)\n    else:\n        path = os.path.join(dest, path)\n    \n    # Create destination directory if it doesn't exist\n    os.makedirs(path, exist_ok=True)\n\n    # Check for valid pack format and compression type\n    valid_formats = ['tar']\n    valid_compressions = ['bz2']\n    \n    if pack_format"
    },
    {
        "original": "\nclass Transaction:\n    def __init__(self, transaction_type, trace_parent=None):\n        self.transaction_type = transaction_type\n        self.trace_parent = trace_parent\n\nclass TransactionManager:\n    _local = threading.local()\n\n    def begin_transaction(self, transaction_type, trace_parent=None):\n        if not hasattr(self._local, 'transaction'):\n            self._local.transaction = Transaction(transaction_type, trace_parent)\n        return self._local.transaction\n",
        "rewrite": "```python\nimport threading\n\nclass Transaction:\n    def __init__(self, transaction_type, trace_parent=None):\n        self.transaction_type = transaction_type\n        self.trace_parent = trace_parent\n\nclass TransactionManager:\n    _local = threading.local()\n\n    def begin_transaction(self, transaction_type, trace_parent=None):\n        if not hasattr(self._local, 'transaction'):\n            self._local.transaction = None\n        if self._local.transaction is None:\n            self._local.transaction = Transaction(transaction_type, trace_parent)\n        return getattr(self._local, 'transaction')\n\n# Example usage\ntm = TransactionManager()\nt1 = tm.begin"
    },
    {
        "original": "\nfrom werkzeug.datastructures import IfRange\nfrom datetime import datetime\n\ndef parse_if_range_header(value):\n    if value.startswith('\"') and value.endswith('\"'):\n        return IfRange(etag=value[1:-1])\n    elif value.startswith('W/') and value[2:].startswith('\"') and value.endswith('\"'):\n        return IfRange(etag=value[2:-1])\n    else:\n        try:\n            dt = datetime.strptime(value, '%a, %d %b %Y",
        "rewrite": "```python\nfrom werkzeug.datastructures import IfRange\nfrom datetime import datetime\n\ndef parse_if_range_header(value):\n    if value.startswith('\"') and value.endswith('\"'):\n        return IfRange(etag=value[1:-1])\n    elif value.startswith('W/') and value[2:].startswith('\"') and value.endswith('\"'):\n        return IfRange(etag=value[2:-1])\n    else:\n        try:\n            dt = datetime.strptime(value, '%a, %d %b %Y %H:%M:%S GMT')\n            return IfRange(last_modified=dt)\n        except ValueError:\n            raise ValueError(\"Invalid date"
    },
    {
        "original": "\ndef Parse(self, stat, file_object, knowledge_base):\n    pass  # Please provide the problem description, input, and output specifications.\n",
        "rewrite": "```python\ndef parse(self, stat, file_object, knowledge_base):\n    \"\"\"\n    Parse the given statistics and update the knowledge base accordingly.\n\n    Args:\n        stat (dict): The statistics to be parsed.\n        file_object (file): The file object containing additional information.\n        knowledge_base (dict): The dictionary representing the current knowledge base.\n\n    Returns:\n        dict: The updated knowledge base.\n    \"\"\"\n\n    # Check if the input arguments are valid\n    if not isinstance(stat, dict) or not isinstance(file_object, file) or not isinstance(knowledge_base, dict):\n        raise ValueError(\"Invalid input arguments\")\n\n    #"
    },
    {
        "original": "\nimport requests\n\nclass GitHub:\n    def __init__(self, owner, repo, token):\n        self.owner = owner\n        self.repo = repo\n        self.token = token\n\n    def get_label(self, name):\n        headers = {'Authorization': f'Bearer {self.token}'}\n        response = requests.get(f'https://api.github.com/repos/{self.owner}/{self.repo}/labels/{name}', headers=headers)\n        response.raise_for_status()\n        return response.json()\n",
        "rewrite": "```python\nimport requests\n\nclass GitHub:\n    def __init__(self, owner: str, repo: str, token: str):\n        self.owner = owner\n        self.repo = repo\n        self.token = token\n\n    def get_label(self, name: str) -> dict:\n        url = f'https://api.github.com/repos/{self.owner}/{self.repo}/labels/{name}'\n        response = requests.get(url, headers={'Authorization': f'Bearer {self.token}'})\n        response.raise_for_status()\n        return response.json()\n```\nOr using the `session` object for efficiency (reusing the same session for"
    },
    {
        "original": "\nimport nbformat\n\ndef strip_output(nb):\n    \"\"\"strip the outputs from a notebook object\"\"\"\n    nbformat.v4.nbnode.NBNode.clear_outputs(nb)\n    for cell in nb.cells:\n        if 'outputs' in cell:\n            cell['outputs'] = []\n        if 'execution_count' in cell:\n            cell['execution_count'] = None\n    return nb\n",
        "rewrite": "```python\nimport nbformat\n\ndef strip_output(nb):\n    nb = nbformat.v4.nbnode.NBNode.clone(nb)\n    for cell in nb.cells:\n        if 'outputs' in cell and isinstance(cell['outputs'], list):\n            cell['outputs'] = []\n        if 'execution_count' in cell and isinstance(cell['execution_count'], int):\n            cell['execution_count'] = None\n    return nb\n```"
    },
    {
        "original": "\ndef set_activate_user_form(self, card_id, **kwargs):\n    data = {\n        \"card_id\": card_id,\n        \"service_statement\": kwargs.get(\"service_statement\", {}),\n        \"bind_old_card\": kwargs.get(\"bind_old_card\", {}),\n        \"required_form\": kwargs.get(\"required_form\", {}),\n        \"optional_form\": kwargs.get(\"optional_form\", {})\n    }\n    return data\n",
        "rewrite": "```python\ndef set_activate_user_form(self, card_id, **kwargs):\n    data = {\n        \"card_id\": card_id,\n        **{\n            \"service_statement\": kwargs.get(\"service_statement\", {}),\n            \"bind_old_card\": kwargs.get(\"bind_old_card\", {}),\n            \"required_form\": kwargs.get(\"required_form\", {}),\n            \"optional_form\": kwargs.get(\"optional_form\", {})\n        }\n    }\n    return data\n```"
    },
    {
        "original": "\nclass Service:\n    def __init__(self):\n        self.replicas = 0\n\n    def scale(self, replicas):\n        self.replicas = replicas\n        return True\n",
        "rewrite": "```python\nclass Service:\n    def __init__(self):\n        self.replicas = 0\n\n    def scale(self, replicas):\n        if replicas < 0:\n            raise ValueError(\"Replicas cannot be negative\")\n        self.replicas = replicas\n        return True\n```"
    },
    {
        "original": "\ndef _decode_embedded_list(src):\n    return [x.decode('utf-8') if isinstance(x, bytes) else x for x in src]\n",
        "rewrite": "```python\ndef _decode_embedded_list(src):\n    return [x.decode('utf-8') if isinstance(x, bytes) else x for x in src]\n```"
    },
    {
        "original": "\nimport numpy as np\nfrom typing import Dict\nfrom qiskit.quantum_info.synthesis import OneQubitEulerDecomposer\n\ndef expand_matrix_in_orthogonal_basis(m: np.ndarray, basis: Dict[str, np.ndarray]) -> Dict[str, complex]:\n    coefficients = {}\n    for key, basis_element in basis.items():\n        coefficient = np.trace(np.dot(m, basis_element)) / np.trace(np.dot(basis_element, basis_element))\n        coefficients[key]",
        "rewrite": "```python\nimport numpy as np\nfrom typing import Dict\n\ndef expand_matrix_in_orthogonal_basis(m: np.ndarray, basis: Dict[str, np.ndarray]) -> Dict[str, complex]:\n    coefficients = {key: np.trace(np.dot(m, basis_element)) / np.trace(np.dot(basis_element, basis_element)) \n                   for key, basis_element in basis.items()}  \n    return coefficients\n```\n\nOr using more compact way with `np.einsum`:\n\n```python\nimport numpy as np\nfrom typing import Dict\n\ndef expand_matrix_in_orthogonal_basis(m: np.ndarray, basis: Dict[str"
    },
    {
        "original": "\ndef _split_area(self, xs, lower, upper):\n    nan_indices = np.where(np.isnan(xs))[0]\n    nan_indices = np.concatenate([[0], nan_indices, [len(xs)]])\n    areas = []\n    for i in range(len(nan_indices) - 1):\n        start, end = nan_indices[i], nan_indices[i + 1]\n        areas.append((xs[start:end], lower[start:end], upper[start:end]))\n    return areas\n",
        "rewrite": "```python\nimport numpy as np\n\ndef _split_area(self, xs, lower, upper):\n    nan_indices = np.where(np.isnan(xs))[0]\n    areas = []\n    for i in range(len(nan_indices) - 1):\n        start, end = nan_indices[i], nan_indices[i + 1]\n        areas.append((xs[start:end], lower[start:end], upper[start:end]))\n    return areas\n```"
    },
    {
        "original": "\nclass UnknownError(Exception):\n    def __init__(self, message):\n        self.status = \"Unknown Error\"\n        self.error_type = \"UnknownError\"\n        self.message = message\n\ndef parse_error(res):\n    try:\n        # assume res is a dictionary containing error information\n        error_type = res.get(\"error_type\")\n        message = res.get(\"message\")\n        if error_type:\n            # map error_type to a Python type\n            error_type_class = globals().get(error",
        "rewrite": "```python\nclass UnknownError(Exception):\n    def __init__(self, message):\n        self.status = \"Unknown Error\"\n        self.error_type = \"UnknownError\"\n        self.message = message\n\ndef parse_error(res):\n    try:\n        error_type = res.get(\"error_type\")\n        message = res.get(\"message\")\n        \n        if error_type:\n            # Map error types to Python exceptions\n            exception_map = {\n                \"TypeError\": TypeError,\n                \"ValueError\": ValueError,\n                \"KeyError\": KeyError,\n                # Add more mappings as needed\n            }\n            \n            exception_class = exception_map.get(error_type)\n            \n"
    },
    {
        "original": "\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.support.ui import WebDriverWait\nfrom selenium.webdriver.support import expected_conditions as EC\n\ndef assert_exact_text(self, text, selector=\"html\", by=By.CSS_SELECTOR, timeout=10):\n    element = WebDriverWait(self.driver, timeout).until(\n        EC.text_to_be_present_in_element((by, selector), text.strip())\n    )\n    element_text = element.text.strip()\n    assert element_text == text.strip(), f\"Exact text '{",
        "rewrite": "```python\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.support.ui import WebDriverWait\nfrom selenium.webdriver.support import expected_conditions as EC\n\ndef assert_exact_text(self, text, selector=\"html\", by=By.CSS_SELECTOR, timeout=10):\n    element = WebDriverWait(self.driver, timeout).until(\n        EC.text_to_be_present_in_element((by, selector), text.strip())\n    )\n    element_text = element.text.strip()\n    assert element_text == text.strip(), f\"Exact text '{text}' not found in the specified {selector} using {by.name}\"\n```\nThis revised function includes an updated error message that specifies"
    },
    {
        "original": "\nimport networkx as nx\n\ndef _write_gml(G, path):\n    nx.write_gml(G, path)\n",
        "rewrite": "```python\nimport networkx as nx\n\ndef write_gml(G, path):\n    \"\"\"\n    Write a graph in GML format to a file.\n\n    Args:\n        G (nx.Graph): The graph to write.\n        path (str): The file path to write the graph to.\n    \"\"\"\n    nx.write_gml(G, path)\n```"
    },
    {
        "original": "\nclass Query:\n    def __init__(self):\n        self.filter = \"\"\n\n    def any(self, *, collection, attribute, word, func=None, operation=None):\n        if func:\n            self.filter += f\"{collection}/{func}({attribute} {operation} '{word}')\"\n        else:\n            self.filter += f\"{collection}/any(a:{attribute} {operation} '{word}')\"\n        return self\n\nq = Query()\nprint(q.any(collection='email_addresses', attribute='",
        "rewrite": "```python\nclass Query:\n    def __init__(self):\n        self.filter = \"\"\n\n    def any(self, collection, attribute, word, func=None, operation=None):\n        if func:\n            self.filter += f\"{collection}/{func}({attribute} {operation} '{word}')\"\n        else:\n            self.filter += f\"{collection}/any(a:{attribute} {operation} '{word}')\"\n        return self\n\nq = Query()\nprint(q.any(collection='email_addresses', attribute='\" .', word='No'))\n```\n\nHowever, it seems like there's a missing closing quote in the `attribute` parameter. If that"
    },
    {
        "original": "\nimport numpy as np\n\nclass ReciprocalSpaceSummation:\n    def __init__(self, q, r, G, Gmax, eta, V):\n        self.q = q\n        self.r = r\n        self.G = G\n        self.Gmax = Gmax\n        self.eta = eta\n        self.V = V\n\n    def _calc_recip(self):\n        G_dot_G = np.dot(self.G, self.G)\n        G_filter =",
        "rewrite": "Here's the revised code with improvements:\n\n```python\nimport numpy as np\n\nclass ReciprocalSpaceSummation:\n    def __init__(self, q, r, G, Gmax, eta, V):\n        \"\"\"\n        Initialize the ReciprocalSpaceSummation class.\n\n        Parameters:\n            q (float): \n            r (float): \n            G (numpy.ndarray): \n            Gmax (float): Maximum value of G.\n            eta (float): \n            V (float or numpy.ndarray): Volume of the system.\n        \"\"\"\n        self.q = q\n        self.r = r\n        self.G"
    },
    {
        "original": "\nimport xarray as xr\n\ndef posterior_to_xarray(self):\n    # Assuming self.posterior is a dictionary containing the posterior data\n    data_vars = {}\n    coords = {}\n    \n    # Iterate over the posterior data and create xarray DataArray and coords\n    for key, value in self.posterior.items():\n        data_vars[key] = (['chain', 'draw'], value)\n        coords['chain'] = range(value.shape[0])\n        coords['draw'] = range",
        "rewrite": "```python\nimport xarray as xr\n\ndef posterior_to_xarray(self):\n    data_vars = {}\n    coords = {'chain':(), 'draw':()}\n    \n    # Iterate over the posterior data and create xarray DataArray and coords\n    for key, value in self.posterior.items():\n        data_vars[key] = (['chain', 'draw'], value)\n        coords['chain'] = tuple(range(value.shape[0]))\n        coords['draw'] = tuple(range(value.shape[1]))\n    \n    return xr.Dataset(data_vars=data_vars, coords=coords)\n```\n\nIn this corrected code, we first initialize an empty dictionary"
    },
    {
        "original": "\nclass DataStore:\n    def __init__(self):\n        self.data = {}\n\n    def set(self, id, value):\n        self.data[id] = value\n",
        "rewrite": "```python\nclass DataStore:\n    def __init__(self):\n        self.data = {}\n\n    def set(self, id, value):\n        self.data[id] = value\n\n    def get(self, id):\n        return self.data.get(id)\n\n    def delete(self, id):\n        if id in self.data:\n            del self.data[id]\n\n    def update(self, id, new_value):\n        if id in self.data:\n            self.set(id, new_value)\n\n    def clear(self):\n        self.data.clear()\n\nclass DataStoreManager:\n    def __init__(self):\n        self.stores = {}\n\n    def create_store(self"
    },
    {
        "original": "\ndef RemoveLabels(self, labels_names, owner=None):\n    for label in labels_names:\n        if owner:\n            self.attributes.pop(f\"{label}:{owner}\", None)\n        else:\n            for key in list(self.attributes.keys()):\n                if key.startswith(label + \":\"):\n                    self.attributes.pop(key, None)\n",
        "rewrite": "```python\ndef remove_labels(self, labels_names, owner=None):\n    for label in labels_names:\n        if owner:\n            self.attributes.pop(f\"{label}:{owner}\", None)\n        else:\n            self.attributes = {k: v for k, v in self.attributes.items() if not k.startswith(label + \":\")}\n```"
    },
    {
        "original": "\nclass Reader:\n    def __init__(self, data):\n        self.data = data\n        self.index = 0\n\n    def read(self, length=None):\n        if length is None:\n            result = self.data[self.index:]\n            self.index = len(self.data)\n        else:\n            result = self.data[self.index:self.index + length]\n            self.index += length\n        return result\n",
        "rewrite": "```python\nclass Reader:\n    def __init__(self, data):\n        self.data = data\n        self.index = 0\n\n    def read(self, length=None):\n        if length is None:\n            result = self.data[self.index:]\n            self.index = len(self.data)\n        else:\n            end_index = min(self.index + length, len(self.data))\n            result = self.data[self.index:end_index]\n            self.index = end_index\n        return result\n\n    def reset(self):\n        \"\"\"Reset the reader to the beginning of the data.\"\"\"\n        self.__init__(self.data)\n\n# Example usage:\nreader = Reader"
    },
    {
        "original": "\ndef prompt_user_to_select_link(links):\n    \"\"\"\n    Prompt the user to select a link from a list to open.\n\n    Return the link that was selected, or ``None`` if no link was selected.\n    \"\"\"\n    for i, link in enumerate(links, 1):\n        print(f\"{i}. {link}\")\n    while True:\n        try:\n            choice = int(input(\"Enter the number of the link to open (or 0 to cancel): \"))\n            if choice ==",
        "rewrite": "```python\ndef prompt_user_to_select_link(links):\n    \"\"\"\n    Prompt the user to select a link from a list to open.\n\n    Return the link that was selected, or None if no link was selected.\n    \"\"\"\n    for i, link in enumerate(links, 1):\n        print(f\"{i}. {link}\")\n        \n    while True:\n        choice = input(\"Enter the number of the link to open (or 0 to cancel): \")\n        \n        if choice == \"0\":\n            return None\n        \n        try:\n            choice = int(choice)\n            if 1 <= choice <= len(links):\n                return links[choice"
    },
    {
        "original": "\nimport time\nimport pyautogui\n\ndef play(events, speed_factor=1.0, include_clicks=True, include_moves=True, include_wheel=True):\n    start_time = time.time()\n    for event in events:\n        if (event['type'] == 'click' and include_clicks) or (event['type'] == 'move' and include_moves) or (event['type'] == 'wheel' and include_wheel):\n            elapsed_time = event['time'] -",
        "rewrite": "```python\nimport time\nimport pyautogui\n\ndef play(events, speed_factor=1.0, include_clicks=True, include_moves=True, include_wheel=True):\n    start_time = time.time()\n    for event in events:\n        if (event['type'] == 'click' and include_clicks) or (event['type'] == 'move' and include_moves) or (event['type'] == 'wheel' and include_wheel):\n            elapsed_time = event['time'] - start_time\n            sleep_time = max(0, elapsed_time - (time.time() - start_time)) * speed_factor\n           "
    },
    {
        "original": "\nclass Boxlist:\n    def __init__(self, boxes):\n        self.boxes = boxes\n\n    def remove_small_boxes(self, min_size):\n        self.boxes = [box for box in self.boxes if box[0] >= min_size and box[1] >= min_size]\n\n# Example usage:\nboxes = [(1, 2), (3, 4), (5, 6), (7, 8), (9, 10)]\nboxlist",
        "rewrite": "```python\nclass BoxList:\n    def __init__(self, boxes):\n        self.boxes = boxes\n\n    def remove_small_boxes(self, min_size):\n        self.boxes = [box for box in self.boxes if all(dim >= min_size for dim in box)]\n\n# Example usage:\nboxes = [(1, 2), (3, 4), (5, 6), (7, 8), (9, 10)]\nbox_list = BoxList(boxes)\n\nprint(\"Original Boxes:\", box_list.boxes)\nbox_list.remove_small_boxes(5)\nprint(\"Boxes after removing small ones:\", box"
    },
    {
        "original": "\nclass Row:\n    def __init__(self, table):\n        self.table = table\n        self.table.rows.append(self)\n\n    def __repr__(self):\n        return f\"Row of {self.table}\"\n\nclass Table:\n    def __init__(self):\n        self.rows = []\n\n    def add_row(self):\n        return Row(self)\n\ntable = Table()\nrow = table.add_row()\nprint(row)\n",
        "rewrite": "```python\nclass Table:\n    def __init__(self):\n        self.rows = []\n\n    def add_row(self):\n        row = TableRow(self)\n        if row not in self.rows:\n            self.rows.append(row)\n        return row\n\n    def __repr__(self):\n        return f\"Table with {len(self.rows)} rows\"\n\nclass TableRow:\n    def __init__(self, table):\n        self.table = table\n\n    def __repr__(self):\n        return f\"Row of {self.table}\"\n\ntable = Table()\nrow1 = table.add_row()\nrow2 = table.add_row()\nprint(table)\nprint(row1)\n"
    },
    {
        "original": "\nclass DominatorFinder:\n    def __init__(self, graph):\n        self.graph = graph\n        self.n = len(graph)\n        self.idom = [-1] * self.n\n        self.sdom = [-1] * self.n\n        self.label = [-1] * self.n\n        self.stack_member = [False] * self.n\n        self.stack = []\n        self.vertex = list(range(self.n))\n\n    def _construct(self, entry_node):\n       ",
        "rewrite": "```python\nclass DominatorFinder:\n    def __init__(self, graph):\n        self.graph = graph\n        self.n = len(graph)\n        self.idom = [-1] * self.n  # immediate dominator\n        self.sdom = [-1] * self.n  # smallest dominator\n        self.label = [-1] * self.n  # height of each node in the l-dom tree\n        self.stack_member = [False] * self.n  # to track if a node is currently on our stack \n        # when we push or pop them. This allows us to avoid using a separate data"
    },
    {
        "original": "\nimport numba\n\ndef conditional_jit(function=None, **kwargs):\n    if function is None:\n        return lambda func: conditional_jit(func, **kwargs)\n    try:\n        import numba\n        return numba.jit(**kwargs)(function)\n    except ImportError:\n        return function\n",
        "rewrite": "```python\nimport numba\n\ndef conditional_jit(function=None, **kwargs):\n    if function is None:\n        def dyn_cond_jit(func):\n            return conditional_jit(func, **kwargs)\n        return dyn_cond_jit\n    try:\n        return numba.jit(**kwargs)(function)\n    except ImportError:\n        return function\n```"
    },
    {
        "original": "\nimport numpy as np\nfrom typing import Union\n\ndef _full_like_variable(other, fill_value, dtype: Union[str, np.dtype, None] = None):\n    return np.full_like(other, fill_value, dtype=dtype)\n",
        "rewrite": "```python\nimport numpy as np\nfrom typing import Union, Optional\n\ndef full_like_variable(other: np.ndarray, fill_value: Union[int, float], dtype: Optional[Union[str, np.dtype]] = None) -> np.ndarray:\n    return np.full_like(other, fill_value, dtype=dtype)\n```"
    },
    {
        "original": "\ndef _load_stopwords(file_path):\n    with open(file_path, 'r') as f:\n        stopwords = [line.strip() for line in f.readlines()]\n    return stopwords\n",
        "rewrite": "```python\ndef _load_stopwords(file_path):\n    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n        stopwords = set(line.strip().lower() for line in f.readlines())\n    return stopwords\n```"
    },
    {
        "original": "\ndef set_font_properties(style_less, \n                        nbfont=None, \n                        tcfont=None, \n                        monofont=None, \n                        monosize=11, \n                        tcfontsize=13, \n                        nbfontsize=13, \n                        prfontsize=95, \n                        dffontsize=93, \n                        outfontsize=85, \n                        mathfontsize=100, \n                        dfonts=False):\n    pass\n",
        "rewrite": "```python\nfrom matplotlib import pyplot as plt  # Import required library\n\ndef set_font_properties(\n    style_less: bool = False,\n    nbfont: str = None,\n    tcfont: str = None,\n    monofont: str = None,\n    monosize: int = 11,\n    tcfontsize: int = 13,\n    nbfontsize: int = 13,\n    prfontsize: int = 95,  \n    dffontsize: int = 93,  \n    outfontsize: int = 85,  \n    mathfontsize: int = 100, \n):\n    \n        plt.rcParams"
    },
    {
        "original": "\nimport numpy as np\n\ndef _expectation(p, constant_mean, none, kern, feat, nghp=None):\n    N = p.shape[0]\n    Q = feat.shape[0]\n    M = 1  # assuming M is 1 since m(x_i) is a constant function\n\n    expectation = np.zeros((N, Q, M))\n\n    for n in range(N):\n        for q in range(Q):\n            expectation[n, q, :] = constant_mean",
        "rewrite": "```python\nimport numpy as np\n\ndef _expectation(p, constant_mean, none, kern, feat):\n    N = p.shape[0]\n    Q = feat.shape[0]\n    M = 1  # assuming M is 1 since m(x_i) is a constant function\n\n    expectation = np.zeros((N, Q))\n\n    for n in range(N):\n        for q in range(Q):\n            expectation[n, q] = constant_mean\n```"
    },
    {
        "original": "\nfrom sympy import Basic\nfrom typing import Any\n\ndef is_parameterized(val: Any) -> bool:\n    if hasattr(val, '_is_parameterized_') and val._is_parameterized_():\n        return True\n    elif isinstance(val, Basic):\n        return True\n    else:\n        return False\n",
        "rewrite": "```python\nfrom sympy import Basic\nfrom typing import Any\n\ndef is_parameterized(val: Any) -> bool:\n    return hasattr(val, '_is_parameterized_') and val._is_parameterized_()\n    or isinstance(val, Basic)\n```"
    },
    {
        "original": "\ndef _process_merge_request_change(self, payload, event, codebase=None):\n    \"\"\"\n    Consumes the merge_request JSON as a python object and turn it into a buildbot change.\n\n    :arguments:\n        payload\n            Python Object that represents the JSON sent by GitLab Service\n            Hook.\n    \"\"\"\n    # Assuming payload is a dictionary containing the merge request data\n    # Extract relevant information from the payload\n    title = payload.get('object_attributes', {}).get('title",
        "rewrite": "```python\ndef _process_merge_request_change(self, payload, event, codebase=None):\n    title = payload.get('object_attributes', {}).get('title')\n    author_username = payload.get('object_attributes', {}).get('author_username')\n    author_name = payload.get('object_attributes', {}).get('author_name')\n    changed_files = payload.get('changes')\n\n    # If no changes were recorded in the merge request\n    if changed_files is None:\n        return []\n\n    # Convert each change into a buildbot Change tuple\n    changes = [(file['old_path'], file['new_path']) for file in changed_files]\n\n"
    },
    {
        "original": "\ndef num_having_numId(self, numId):\n    for elem in self.element.iter():\n        if elem.tag == '{http://schemas.openxmlformats.org/wordprocessingml/2006/main}num':\n            if elem.get('{http://schemas.openxmlformats.org/wordprocessingml/2006/main}numId') == str(numId):\n                return elem\n    return None\n",
        "rewrite": "```python\ndef num_having_numId(self, numId):\n    return next((elem for elem in self.element.iter() if elem.tag == '{http://schemas.openxmlformats.org/wordprocessingml/2006/main}num' and elem.get('{http://schemas.openxmlformats.org/wordprocessingml/2006/main}numId') == str(numId)), None)\n```"
    },
    {
        "original": "\nimport psutil\nfrom rdf_client_network import Interface\n\ndef EnumerateInterfacesFromClient(args):\n    for nic in psutil.net_if_addrs():\n        for snic in psutil.net_if_addrs()[nic]:\n            if snic.family == psutil.AF_LINK:\n                yield Interface(nic, snic.address)\n",
        "rewrite": "```python\nimport psutil\n\nclass Interface:\n    def __init__(self, name, address):\n        self.name = name\n        self.address = address\n\ndef enumerate_interfaces():\n    for nic in psutil.net_if_addrs():\n        for snic in psutil.net_if_addrs().get(nic, []):\n            if snic.family == psutil.AF_LINK:\n                yield Interface(nic, snic.address)\n```\n\nOr with the original `rdf_client_network` module:\n\n```python\nfrom rdf_client_network import Interface\n\ndef enumerate_interfaces():\n    for nic in psutil.net_if_addrs():\n        for sn"
    },
    {
        "original": "\ndef do_genesis(args, data_dir=None):\n    genesis_data = None\n    for file in args:\n        with open(file, 'r') as f:\n            if genesis_data is None:\n                genesis_data = f.read()\n            else:\n                genesis_data += f.read()\n    with open('output.txt', 'w') as f:\n        f.write(genesis_data)\n",
        "rewrite": "```python\ndef do_genesis(args, data_dir=None):\n    genesis_data = []\n    for file in args:\n        with open(file, 'r') as f:\n            genesis_data.append(f.read())\n    with open('output.txt', 'w') as f:\n        f.write(''.join(genesis_data))\n```"
    },
    {
        "original": "\nclass Project:\n    def __init__(self):\n        self.projects = {}\n\n    def create_project(self, key, name, description=\"\"):\n        \"\"\"\n        Create project\n        :param key:\n        :param name:\n        :param description:\n        :return:\n        \"\"\"\n        self.projects[key] = {\"name\": name, \"description\": description}\n",
        "rewrite": "```python\nclass Project:\n    def __init__(self):\n        self.projects = {}\n\n    def create_project(self, key, name, description=\"\"):\n        self.projects[key] = {\"name\": name, \"description\": description}\n\n    def get_project(self, key):\n        return self.projects.get(key)\n\n    def update_project(self, key, name=None, description=None):\n        if key in self.projects:\n            if name:\n                self.projects[key][\"name\"] = name\n            if description:\n                self.projects[key][\"description\"] = description\n\n    def delete_project(self, key):\n        if key in self.projects:\n            del"
    },
    {
        "original": "\ndef _label_columns_json(self, cols=None):\n    if cols is None:\n        cols = self.columns\n    return {str(col): str(self.labels.get(col, col)) for col in cols}\n",
        "rewrite": "```python\ndef _label_columns_json(self, cols=None):\n    if cols is None:\n        cols = self.columns\n    return {str(col): str(self.labels.get(col, col)) for col in cols}\n```"
    },
    {
        "original": "\nimport tensorflow as tf\n\ndef _aspect_preserving_resize(image, resize_min):\n    \"\"\"Resize images preserving the original aspect ratio.\n\n    Args:\n      image: A 3-D image `Tensor`.\n      resize_min: A python integer or scalar `Tensor` indicating the size of\n        the smallest side after resize.\n\n    Returns:\n      resized_image: A 3-D tensor containing the resized image.\n    \"\"\"\n    shape = tf.shape(image)\n    height, width, _ = shape",
        "rewrite": "```python\nimport tensorflow as tf\n\ndef aspect_preserving_resize(image, resize_min):\n    shape = tf.shape(image)\n    height, width, _ = shape\n    resize_height = tf.cast(tf.minimum(height, width), tf.float32) * resize_min / tf.reduce_min(tf.shape(image)[0:2])\n    resize_width = tf.cast(tf.maximum(height, width), tf.float32) * resize_min / tf.reduce_max(tf.shape(image)[0:2])\n    \n    return (\n        (tf.image.resize_images(\n            image[:, :, 0:1],\n            [resize_height.value if hasattr(resize_height, '"
    },
    {
        "original": "\nfrom qiskit.circuit.library import XGate\nfrom qiskit.quantum_info import Kraus\nimport numpy as np\nfrom typing import Optional, Union\n\ndef bit_flip(p: Optional[float] = None) -> Union[XGate, Kraus]:\n    if p is None:\n        return XGate()\n    elif 0 <= p <= 1:\n        m0 = np.sqrt(p) * np.array([[1, 0], [0, 1]])\n       ",
        "rewrite": "```python\nfrom qiskit.circuit.library import XGate\nfrom qiskit.quantum_info import Kraus\nimport numpy as np\nfrom typing import Optional, Union\n\ndef bit_flip(p: Optional[float] = None) -> Union[XGate, Kraus]:\n    if p is None:\n        return XGate()\n    elif 0 <= p <= 1:\n        m0 = np.sqrt(p) * np.array([[1, 0], [0, 1]])\n        m1 = np.sqrt(1 - p) * np.array([[0, 1], [1, 0]])\n        return"
    },
    {
        "original": "\nimport re\nfrom html.parser import HTMLParser\n\nclass MessageEntity:\n    def __init__(self, type, offset, length):\n        self.type = type\n        self.offset = offset\n        self.length = length\n\nclass HTMLParserWithEntities(HTMLParser):\n    def __init__(self):\n        super().__init__()\n        self.clean_message = ''\n        self.entities = []\n        self.current_entity_type = None\n        self.current_entity_offset = 0\n\n    def handle_start",
        "rewrite": "```python\nimport re\nfrom html.parser import HTMLParser\n\nclass MessageEntity:\n    def __init__(self, type, offset, length):\n        self.type = type\n        self.offset = offset\n        self.length = length\n\nclass HTMLParserWithEntities(HTMLParser):\n    def __init__(self):\n        super().__init__()\n        self.clean_message = ''\n        self.entities = []\n        \n    def handle_starttag(self, tag, attrs):\n        if tag in ['b',\t'bold', 'i', 'italic', 'u', 'underline']:\n            entity_type = re.search(r'\\d+$', tag)."
    },
    {
        "original": "\ndef jsonrpc_map(self, request):\n    return '{\"jsonrpc\": \"2.0\", \"result\": {\"map\": {\"add\": \"add\", \"subtract\": \"subtract\", \"multiply\": \"multiply\", \"divide\": \"divide\"}}, \"id\": \"1\"}'\n",
        "rewrite": "```python\nimport json\n\ndef jsonrpc_map(self, request):\n    data = {\n        \"jsonrpc\": \"2.0\",\n        \"result\": {\"map\": {\n            \"add\": \"add\",\n            \"subtract\": \"subtract\",\n            \"multiply\": \"multiply\",\n            \"divide\": lambda x, y: x / y if y != 0 else None\n        }},\n        'id': 1\n    }\n    return json.dumps(data)\n```"
    },
    {
        "original": "\nimport slack\n\ndef channels_rename(self, *, channel: str, name: str, **kwargs) -> slack.Response:\n    client = slack.WebClient(token='YOUR_SLACK_TOKEN')\n    response = client.conversations_rename(channel=channel, name=name)\n    return response\n",
        "rewrite": "```python\nimport slack\n\nclass SlackClient:\n    def __init__(self, token):\n        self.token = token\n\n    def channels_rename(self, channel: str, name: str) -> slack.Response:\n        client = slack.WebClient(token=self.token)\n        return client.conversations_rename(channel=channel, name=name)\n\ndef main(token):\n    client = SlackClient(token)\n    response = client.channels_rename('CHANNEL_ID', 'NEW_CHANNEL_NAME')\n    return response\n```\n\nOr if you want to keep the function as is:\n\n```python\nimport slack\n\ndef channels_rename(token: str, channel: str, name:"
    },
    {
        "original": "\ndef applicationlinks(self, cached=True):\n    import json\n    # assuming you have a way to get the application links\n    # for demonstration purposes, let's assume it's a list of strings\n    app_links = [\"link1\", \"link2\", \"link3\"]\n    \n    if cached:\n        # assuming you have a cache mechanism in place\n        # for demonstration purposes, let's assume it's a dictionary\n        cache = {\"app_links\": app_links}\n       ",
        "rewrite": "```python\nimport json\n\ndef application_links(self, cached=True):\n    app_links = [\"link1\", \"link2\", \"link3\"]\n    \n    cache_dict = {\"app_links\": app_links}\n    \n    if cached:\n        return cache_dict.get(\"app_links\")\n    \n    return app_links\n```"
    },
    {
        "original": "\nimport os\nimport pathlib\nimport requests\n\nclass Authenticator:\n    def request_token(self, authorization_url, store_token=True, token_path=None, **kwargs):\n        response = requests.get(authorization_url)\n        if response.status_code == 200:\n            token = response.text\n            if store_token:\n                if token_path is None:\n                    token_path = pathlib.Path.home() / '.token'\n                with open(token_path, 'w') as f:\n                    f.write(token)\n",
        "rewrite": "```python\nimport os\nimport pathlib\nimport requests\n\nclass Authenticator:\n    def request_token(self, authorization_url, store_token=True, token_path=None, **kwargs):\n        response = requests.get(authorization_url)\n        if response.status_code == 200:\n            try:\n                token = response.json()\n            except ValueError:\n                raise ValueError(\"Invalid JSON response\")\n            if store_token:\n                if token_path is None:\n                    token_path = pathlib.Path.home() / '.token'\n                with open(token_path, 'w') as f:\n                    f.write(str(token))\n        else:\n            raise Exception(f\"Failed to retrieve"
    },
    {
        "original": "\ndef greet(event: str):\n    if event == \"Christmas\":\n        return \"Wishing you a joyous Christmas and a happy New Year!\"\n    elif event == \"Halloween\":\n        return \"Wishing you a spook-tacular Halloween!\"\n    elif event == \"Easter\":\n        return \"Hoping your Easter is filled with love, laughter, and all your favorite things!\"\n    elif event == \"Thanksgiving\":\n        return \"Wishing you a harvest of blessings, good",
        "rewrite": "```python\ndef greet(event: str) -> str:\n    greeting_messages = {\n        \"Christmas\": \"Wishing you a joyous Christmas and a happy New Year!\",\n        \"Halloween\": \"Wishing you a spook-tacular Halloween!\",\n        \"Easter\": \"Hoping your Easter is filled with love, laughter, and all your favorite things!\",\n        \"Thanksgiving\": \"Wishing you a harvest of blessings, good food, and warm company!\"\n    }\n    \n    return greeting_messages.get(event, f\"Wishing you a wonderful {event}!\")\n```\n\nThis revised code uses a dictionary to store the event messages"
    },
    {
        "original": "\ndef from_dict(input_dict):\n    \"\"\"\n    Instantiate an object of a derived class using the information\n    in input_dict (built by the to_dict method of the derived class).\n    More specifically, after reading the derived class from input_dict,\n    it calls the method _build_from_input_dict of the derived class.\n    Note: This method should not be overrided in the derived class. In case\n    it is needed, please override _build_from_input_dict instate.\n\n",
        "rewrite": "```python\ndef from_dict(input_dict, class_type):\n    \"\"\"\n    Instantiate an object of a derived class using the information\n    in input_dict (built by the to_dict method of the derived class).\n    More specifically, after reading the derived class from input_dict,\n    it calls the method _build_from_input_dict of the derived class.\n    \n    Args:\n        input_dict (dict): The dictionary for instantiation.\n        class_type (class): The type of object to instantiate.\n    \n    Returns:\n        An instance of class_type, built from input_dict\n    \"\"\"\n    \n    if not isinstance(class_type, type):\n        raise"
    },
    {
        "original": "\ndef get_sideplot_ranges(plot, element, main, ranges):\n    if element in ranges:\n        return ranges[element]\n    elif main in ranges:\n        return ranges[main]\n    else:\n        return None\n",
        "rewrite": "```python\ndef get_sideplot_ranges(plot, element, main, ranges):\n    return ranges.get(element) or ranges.get(main)\n```"
    },
    {
        "original": "\nclass ClusterGraph:\n    def __init__(self):\n        self.nodes = []\n\n    def add_node(self, node, **kwargs):\n        self.nodes.append(node)\n\nG = ClusterGraph()\nG.add_node(('a', 'b', 'c'))\n",
        "rewrite": "```python\nclass ClusterGraph:\n    def __init__(self):\n        self.nodes = []\n\n    def add_node(self, node: tuple, **kwargs):\n        self.nodes.append(node)\n\nG = ClusterGraph()\nG.add_node(('a', 'b', 'c'))\n```\n\nor\n\n```python\nclass ClusterGraph:\n    def __init__(self):\n        self.nodes = []\n\n    def add_node(self, node: tuple[str], **kwargs):\n        self.nodes.append(node)\n\nG = ClusterGraph()\nG.add_node(('a', 'b', 'c'))\n```"
    },
    {
        "original": "\ndef translate_text(estimator, subtokenizer, txt):\n    tokens = subtokenizer.tokenize(txt)\n    token_ids = subtokenizer.convert_tokens_to_ids(tokens)\n    outputs = estimator.predict(token_ids)\n    translated_text = ''.join([subtokenizer.id_to_token(output) for output in outputs])\n    return translated_text\n",
        "rewrite": "```python\ndef translate_text(estimator, subtokenizer, txt):\n    tokens = subtokenizer.tokenize(txt)\n    token_ids = subtokenizer.convert_tokens_to_ids(tokens)\n    outputs = estimator.predict(token_ids)\n    translated_text = ''.join([subtokenizer.id_to_token(output) for output in outputs])\n    return translated_text\n```"
    },
    {
        "original": "\nfrom typing import List\n\nclass TagValue:\n    def __init__(self, tag: str, value: str):\n        self.tag = tag\n        self.value = value\n\nclass ScannerSubscription:\n    def __init__(self, instrument: str, locationCode: str, scanCode: str):\n        self.instrument = instrument\n        self.locationCode = locationCode\n        self.scanCode = scanCode\n\nclass ScanData:\n    def __init__(self, contractInfo: str",
        "rewrite": "```python\nfrom typing import List\n\nclass TagValue:\n    def __init__(self, tag: str, value: str):\n        self.tag = tag\n        self.value = value\n\nclass ScannerSubscription:\n    def __init__(self, instrument: str, location_code: str, scan_code: str) -> None:\n        self.instrument = instrument\n        self.location_code = location_code\n        self.scan_code = scan_code\n\nclass ScanData:\n    def __init__(self, contract_info: str):\n        \"\" advantage of auto-gen \".start!\n             (conversion either weekdays subject core\ub97c attainty Modul \n           "
    },
    {
        "original": "\nimport requests\nimport json\n\ndef rest_request_to_json(address, auth, ssl_verify, object_path, service_name, tags=None, *args, **kwargs):\n    url = f\"{address}/{object_path}/{service_name}\"\n    if tags:\n        url += f\"?tags={','.join(tags)}\"\n    response = requests.get(url, auth=auth, verify=ssl_verify, *args, **kwargs)\n    response.raise_for_status()\n    return response.json()\n",
        "rewrite": "```python\nimport requests\nimport json\n\ndef rest_request_to_json(address: str, auth: tuple, ssl_verify: bool, object_path: str, service_name: str,\n                         tags=None, *args, **kwargs) -> dict:\n    url = f\"{address}/{object_path}/{service_name}\"\n    if tags:\n        url += f\"?tags={','.join(tags)}\"\n    response = requests.get(url, auth=auth, verify=ssl_verify, *args, **kwargs)\n    response.raise_for_status()\n    return response.json()\n```"
    },
    {
        "original": "\ndef source_absent(name):\n    import os\n    import requests\n    from urllib.parse import urlparse\n\n    parsed_uri = urlparse(name)\n    filename = os.path.basename(parsed_uri.path)\n\n    if os.path.isfile(filename):\n        os.remove(filename)\n    else:\n        print(f\"File {filename} does not exist\")\n",
        "rewrite": "```python\nimport os\nimport requests\n\n\ndef source_absent(filename):\n    try:\n        os.remove(filename)\n    except FileNotFoundError as e:\n        print(f\"File {filename} does not exist\")\n\n\ndef check_url(url):\n    from urllib.parse import urlparse\n    import requests\n\n    response = requests.head(url)\n\n    if response.status_code == 200:\n        parsed_uri = urlparse(url)\n        filename = os.path.basename(parsed_uri.path)\n\n        source_absent(filename)\n\n\n# Example usage\ncheck_url('http://example.com/file.txt')\n```"
    },
    {
        "original": "\nimport pcapy\n\ndef open_pcap(iface, *args, **kwargs):\n    \"\"\"open_pcap: Windows routine for creating a pcap from an interface.\n    This function is also responsible for detecting monitor mode.\n    \"\"\"\n    cap = pcapy.open_live(iface, 65536, 1, 0)\n    return cap\n",
        "rewrite": "```python\nimport pcapy\n\ndef open_pcap(iface, *args, **kwargs):\n    return pcapy.open_live(iface, 65536, 1, 0)\n```"
    },
    {
        "original": "\nclass SyncState:\n    def __init__(self, index, value):\n        self.index = index\n        self.leader = None\n        if isinstance(value, str):\n            if value.startswith('{') and value.endswith('}'):\n                value = value[1:-1]\n                for item in value.split(','):\n                    key, val = item.split(':')\n                    key, val = key.strip(), val.strip().replace('\"', '')\n                    if key == 'leader':\n                        self.le",
        "rewrite": "```python\nclass SyncState:\n    def __init__(self, index, value):\n        self.index = index\n        self.leader = None\n        if isinstance(value, str):\n            if value.startswith('{') and value.endswith('}'):\n                dict_value = value[1:-1]\n                for key_val in dict_value.split(','):\n                    key, val = key_val.split(':')\n                    key, val = key.strip(), val.strip().replace('\"', '')\n                    setattr(self, key.lower(), val)\n```\n\nThis revised code assumes that the `value` parameter is a string representing a dictionary in JSON-like format. It"
    },
    {
        "original": "\nclass GitHubRepository:\n    def __init__(self):\n        self.watched_repos = []\n\n    def has_in_watched(self, repo):\n        return repo in self.watched_repos\n",
        "rewrite": "```python\nclass GitHubRepository:\n    def __init__(self):\n        self.watched_repos = set()\n\n    def has_in_watched(self, repo):\n        return repo in self.watched_repos\n\n    def add_repo(self, repo):\n        self.watched_repos.add(repo)\n\n    def remove_repo(self, repo):\n        if repo in self.watched_repos:\n            self.watched_repos.remove(repo)\n```"
    },
    {
        "original": "\ndef all_subclasses(cls):\n    return set(cls.__subclasses__()) | set(cls for c in cls.__subclasses__() for cls in all_subclasses(c))\n",
        "rewrite": "```python\ndef all_subclasses(cls):\n    return set(cls.__subclasses__()) | {c for c in cls.__subclasses__() for c in all_subclasses(c)}\n```"
    },
    {
        "original": "\ndef mongo_query(self, start, end):\n    \"\"\"\n    Convert a DateRange into a MongoDb query string.\n    \"\"\"\n    query = {}\n    query[\"date\"] = {}\n    query[\"date\"][\"$gte\"] = start\n    query[\"date\"][\"$lte\"] = end\n    return query\n",
        "rewrite": "```python\ndef mongo_query(self, start, end):\n    query = {\n        \"date\": {\"$gte\": start, \"$lte\": end}\n    }\n    return query\n```"
    },
    {
        "original": "\ndef _parse_line(line=''):\n    \"\"\"\n    Used by conf() to break config lines into\n    name/value pairs\n    \"\"\"\n    if '=' in line:\n        name, value = line.split('=', 1)\n        return name.strip(), value.strip()\n    else:\n        return None, None\n",
        "rewrite": "```python\ndef _parse_line(line=''):\n    if '=' in line:\n        name, value = line.split('=', 1)\n        return name.strip(), value.strip()\n    else:\n        return None, None\n```"
    },
    {
        "original": "\ndef GetAPIScope(api_name):\n    if api_name == \"adwords\":\n        return \"https://www.googleapis.com/auth/adwords\"\n    elif api_name == \"ad_manager\":\n        return \"https://www.googleapis.com/auth/ad_manager\"\n    else:\n        raise GoogleAdsValueError(\"Invalid api_name. Accepted values are 'adwords' and 'ad_manager'.\")\n",
        "rewrite": "```python\ndef get_api_scope(api_name):\n    api_scopes = {\n        \"adwords\": \"https://www.googleapis.com/auth/adwords\",\n        \"ad_manager\": \"https://www.googleapis.com/auth/ad_manager\"\n    }\n    \n    if api_name not in api_scopes:\n        raise ValueError(\"Invalid api_name. Accepted values are {}\".format(\", \".join(api_scopes.keys())))\n    \n    return api_scopes[api_name]\n```"
    },
    {
        "original": "\ndef full_info(**kwargs):\n    connection = kwargs.get('connection')\n    username = kwargs.get('username')\n    password = kwargs.get('password')\n\n    import libvirt\n    conn = libvirt.openReadOnly(connection)\n    node_info = conn.getInfo()\n    vm_ids = conn.listDomainsID()\n    vm_info = []\n    for vm_id in vm_ids:\n        vm = conn.lookupByID(vm_id)\n        vm_info.append(vm.info())\n\n    freemem = conn.getFreeMemory()\n\n",
        "rewrite": "```python\ndef full_info(**kwargs):\n    connection = kwargs.get('connection')\n    username = kwargs.get('username')\n    password = kwargs.get('password')\n\n    try:\n        import libvirt\n        conn = libvirt.openReadOnlyREADONLY(connection)\n        if not conn:\n            raise ValueError(\"Failed to establish connection\")\n\n        node_info = conn.getInfo()\n        vm_ids = conn.listDomainsID()\n        \n        # Check for empty list of VMs\n        if not vm_ids:\n            return {'node_info': node_info, 'freemem': 0}\n\n        vm_info_list = []\n        \n        for vm_id in vm"
    },
    {
        "original": "\nclass NetworkDevice:\n    def __init__(self, interfaces):\n        self.interfaces = interfaces\n\n    def get_interfaces(self):\n        return self.interfaces\n",
        "rewrite": "```python\nclass NetworkDevice:\n    def __init__(self, interfaces):\n        self._interfaces = interfaces\n\n    @property\n    def interfaces(self):\n        return self._interfaces\n\n    def get_interfaces(self):\n        return self.interaces\n```"
    },
    {
        "original": "\nclass Vehicle:\n    def __init__(self):\n        self.armed = False\n\n    def arm(self, wait=True, timeout=None):\n        if self.armed:\n            return\n        self.armed = True\n",
        "rewrite": "```python\nclass Vehicle:\n    def __init__(self):\n        self.armed = False\n\n    def arm(self, wait=True, timeout=None):\n        if self.armed:\n            return\n        self.armed = True\n\n    def disarm(self):\n        if not self.armed:\n            return\n        self.armed = False\n\nclass AdvancedVehicle(Vehicle):\n    def arm(self, wait=True, timeout=None):\n        super().arm(wait=wait)\n        \n        # Simulate an arming process with a delay\n        import time\n        time.sleep(timeout or 1)\n\n# Example usage:\nvehicle = Vehicle()\nprint"
    },
    {
        "original": "\nclass PluginCreator:\n    def create_plugin(self, name, plugin_data_dir, gzip=False):\n        import os\n        import gzip as gz\n\n        # Check if plugin data directory exists\n        if not os.path.exists(plugin_data_dir):\n            raise ValueError(\"Plugin data directory does not exist\")\n\n        # Check if config.json manifest file exists\n        config_file = os.path.join(plugin_data_dir, \"config.json\")\n        if not os.path.exists(config_file):\n            raise ValueError(\"config",
        "rewrite": "```python\nimport os\nimport gzip\n\nclass PluginCreator:\n    def create_plugin(self, name, plugin_data_dir, gzip=False):\n        if not os.path.exists(plugin_data_dir):\n            raise ValueError(\"Plugin data directory does not exist\")\n\n        config_file = os.path.join(plugin_data_dir, \"config.json\")\n        if not os.path.exists(config_file):\n            raise ValueError(\"config.json manifest file does not exist\")\n\n        # Check if plugin name is valid (assuming it should be a string)\n        if not isinstance(name, str) or len(name) == 0:\n            raise ValueError(\"Invalid plugin name\")\n\n        # Check"
    },
    {
        "original": "\nfrom androguard.core.bytecodes.dvm import DalvikVMFormat\nimport json\n\ndef vm2json(vm: DalvikVMFormat) -> str:\n    \"\"\"\n    Get a JSON representation of a DEX file\n    \"\"\"\n    result = {}\n    \n    # GetFields\n    result['fields'] = []\n    for field in vm.get_fields():\n        f = {\n            'name': field.get_name(),\n            'type': field.get_type(),\n            'access': field.get",
        "rewrite": "```python\nfrom androguard.core.bytecodes.dvm import DalvikVMFormat\nimport json\n\ndef vm2json(vm: DalvikVMFormat) -> str:\n    result = {\n        'classes': [],\n        'methods': [],\n        'fields': []\n    }\n\n    for field in vm.get_fields():\n        result['fields'].append({\n            'name': field.get_name(),\n            'type': field.get_type(),\n            'access': field.get_access()\n        })\n\n    for method in vm.get_methods():\n        result['methods'].append({\n            'name': method.get_name(),\n            'type': method.get_class()."
    },
    {
        "original": "\ndef filter_results(source, results, aggressive):\n    filtered_results = []\n    for error in results:\n        if error.code in ['E711', 'E712'] and not aggressive:\n            continue\n        filtered_results.append(error)\n    return filtered_results\n",
        "rewrite": "```python\ndef filter_results(source, results, aggressive):\n    filtered_results = [error for error in results if\n                         not (error.code in ['E711', 'E712'] and not aggressive)]\n    return filtered_results\n```"
    },
    {
        "original": "\nclass ProgrammingAssistant:\n    def rehook_symbol(self, new_address, symbol_name):\n        # Create a dictionary to store symbols and their addresses\n        symbols = {}\n\n        # Add or update the symbol with its new address\n        symbols[symbol_name] = new_address\n\n",
        "rewrite": "```python\nclass ProgrammingAssistant:\n    def __init__(self):\n        # Create a dictionary to store symbols and their addresses\n        self.symbols = {}\n\n    def rehook_symbol(self, symbol_name, new_address):\n        # Add or update the symbol with its new address\n        self.symbols[symbol_name] = new_address\n```\n\n(Note: I added an `__init__` method to initialize the `symbols` dictionary when an instance of the class is created, and removed the unused `new_address` parameter from the docstring. It's more idiomatic to pass both required arguments at once.)"
    },
    {
        "original": "\nimport requests\n\nclass Github:\n    class GithubObject:\n        NotSet = None\n\n    class CommitStatus:\n        def __init__(self, state, target_url, description, context):\n            self.state = state\n            self.target_url = target_url\n            self.description = description\n            self.context = context\n\n    def create_status(self, state, target_url=Github.GithubObject.NotSet, description=Github.GithubObject.NotSet, context=Github.GithubObject.Not",
        "rewrite": "```python\nimport requests\n\nclass Github:\n    class GithubObject:\n        NotSet = None\n\n    class CommitStatus:\n        def __init__(self, state, target_url, description, context):\n            self.state = state\n            self.target_url = target_url\n            self.description = description\n            self.context = context\n\n    def create_status(self, state, target_url=None, description=None, context=None):\n        if not isinstance(state, str) or not isinstance(context, str):\n            raise ValueError(\"State and Context must be strings\")\n        \n        status_obj = self.CommitStatus(state=state.upper(), \n                                       target_url"
    },
    {
        "original": "\nimport nbformat as nbf\n\ndef notebook_start(output_path):\n    nb = nbf.NewNotebook()\n    nb.metadata = {}\n    for cell in nb.cells:\n        cell.metadata = {}\n    with open(output_path, 'w') as f:\n        nbf.write(nb, f)\n",
        "rewrite": "```python\nimport nbformat as nbf\n\ndef notebook_start(output_path):\n    nb = nbf.v4.new_notebook()\n    with open(output_path, 'w') as f:\n        nbf.write(nb, f)\n```"
    },
    {
        "original": "\ndef execute(self, eopatch):\n    \"\"\" Execute predicate on input eopatch\n\n    :param eopatch: Input `eopatch` instance\n    :return: The same `eopatch` instance with a `mask.valid_data` array computed according to the predicate\n    \"\"\"\n    # TO DO: implement the logic to compute mask.valid_data according to the predicate\n    # For now, let's assume the predicate is a simple function that returns True for valid",
        "rewrite": "```python\ndef execute(self, eopatch):\n    def predicate():\n        \"\"\" Simple predicate function to check for valid data \"\"\"\n        return True\n    \n    eopatch.metrics['mask']['valid_data'] = predicate()\n    \n    return eopatch\n```\n\nHowever, if you want to make the code more flexible and allow for different predicates, you could do something like this:\n\n```python\ndef execute(self, eopatch):\n    def default_predicate():\n        \"\"\" Default predicate function to check for valid data \"\"\"\n        return True\n    \n    if not hasattr(eopatch.metrics['mask'], 'predicate'):\n        eopatch.metrics['"
    },
    {
        "original": "\ndef _parse_dict(features, new_names):\n    return {new_names[i]: features[i] for i in range(len(features))}\n",
        "rewrite": "def _parse_dict(features, new_names):\n    return dict(zip(new_names, features))"
    },
    {
        "original": "\ndef from_flat(flat):\n    size = int(flat ** 0.5)\n    return (flat % size, flat // size)\n",
        "rewrite": "def coordinates(flat):\n    size = int(flat ** 0.5)\n    return flat % size, flat // size"
    },
    {
        "original": "\ndef copy_snapshot(kwargs=None, call=None):\n    pass\n",
        "rewrite": "```python\ndef copy_snapshot(kwargs=None, call=None):\n    if kwargs is None:\n        kwargs = {}\n    if call is None:\n        call = []\n    \n    # Initialize the snapshot copy\n    snap_copy = {\n        'data': {},\n        'metadata': {}\n    }\n    \n    # Overwrite snapshot metadata with externally provided data\n    for key, value in kwargs.items():\n        snap_copy['metadata'][key] = value\n    \n    # Copy over useful data from the original snapshot\n    for item in [(key, value) for key, value in call[0].items()]:\n        snap_copy['data'][item"
    },
    {
        "original": "\ndef _enqueue_init_updates(self):\n    # No problem description, input, and output specifications provided\n    # Assuming this method is part of a class and is used to enqueue current routes to be shared with a peer\n    pass\n",
        "rewrite": "```python\ndef _enqueue_init_updates(self):\n    init_update_routes = self.get_current_foreign_key_routes()\n    shared_routes = self.list_shared_foreign_keys()\n    \n    for route in init_update_routes + shared_routes:\n        self.queue_client.enqueue(route)\n```\n\n```python\ndef get_current_foreign_key_routes(self):\n    # Assuming this method returns a list of current foreign key routes\n    return []\n\ndef list_shared_foreign_keys(self):\n    # Assuming this method returns a list of shared foreign keys\n    return []\n```"
    },
    {
        "original": "\nclass WeChatClient:\n    def __init__(self, appid, secret):\n        self.appid = appid\n        self.secret = secret\n\nclass User:\n    def __init__(self, client):\n        self.client = client\n\n    def get_batch(self, user_list):\n        batch_users = []\n        for user in user_list:\n            if isinstance(user, str):\n                batch_users.append({'openid': user, 'lang': 'zh-CN'})\n            elif isinstance(user,",
        "rewrite": "```python\nclass WeChatClient:\n    def __init__(self, appid: str, secret: str):\n        self.appid = appid\n        self.secret = secret\n\nclass User:\n    def __init__(self, client: WeChatClient):\n        if not isinstance(client, WeChatClient):\n            raise TypeError(\"Client must be an instance of WeChatClient\")\n        self.client = client\n\n    def get_batch(self, user_list: list) -> list:\n        if not all(isinstance(user, (str, dict)) for user in user_list):\n            raise ValueError(\"User list must contain only strings or dictionaries"
    },
    {
        "original": "\nimport numpy as np\n\ndef defect_concentrations(chemical_potentials, temperature=300, fermi_level=0.):\n    \"\"\"\n    Give list of all concentrations at specified efermi in the DefectPhaseDiagram\n    args:\n        chemical_potentials = {Element: number} is dictionary of chemical potentials to provide formation energies for\n        temperature = temperature to produce concentrations from\n        fermi_level: (float) is fermi level relative to valence band",
        "rewrite": "```python\nimport numpy as np\n\ndef defect_concentrations(chemical_potentials, temperature=300, fermi_level=0.):\n    concentrations = {}\n    for element, mu in chemical_potentials.items():\n        Ea = ...  # obtain formation energy for the given element (add your code to fill this line)\n        n = 1 / (1 + np.exp((Ea + fermi_level) / (8.617e-5 * temperature)))\n        concentrations[element] = n\n    return list(concentrations.values())\n```"
    },
    {
        "original": "\nimport os\nimport subprocess\n\ndef GetRawDevice(path):\n    if not os.path.exists(path):\n        raise IOError(\"Path does not exist\")\n    \n    mount_point = subprocess.check_output([\"df\", \"--output=source\", path]).decode().strip()\n    raw_device = mount_point.split()[0]\n    modified_path = os.path.relpath(path, mount_point)\n    \n    return raw_device, modified_path\n",
        "rewrite": "```python\nimport os\nimport subprocess\n\ndef get_raw_device(path):\n    if not os.path.exists(path):\n        raise FileNotFoundError(\"Path does not exist\")\n    \n    try:\n        mount_point = subprocess.check_output([\"df\", \"--output=source\", path]).decode().strip()\n        raw_device = mount_point.split()[0]\n        modified_path = os.path.relpath(path, mount_point)\n        \n        return raw_device, modified_path\n    except subprocess.CalledProcessError as e:\n        raise RuntimeError(f\"Failed to get raw device: {e}\")\n```"
    },
    {
        "original": "\ndef _report_volume_count(self):\n    # Assuming self.volumes is a list of dictionaries, each containing 'state' and 'dangling' keys\n    volume_count = {}\n    for volume in self.volumes:\n        state = volume['state']\n        dangling = volume['dangling']\n        if (state, dangling) not in volume_count:\n            volume_count[(state, dangling)] = 0\n        volume_count[(state, dangling)] += 1\n    return volume",
        "rewrite": "```python\ndef _report_volume_count(self):\n    volume_count = {}\n    for volume in self.volumes:\n        state, dangling = volume['state'], volume['dangling']\n        if (state, dangling) not in volume_count:\n            volume_count[(state, dangling)] = 0\n        volume_count[(state, dangling)] += 1\n    return list(volume_count.items())\n```"
    },
    {
        "original": "\nclass ScriptWriter:\n    def __init__(self, name, os_support):\n        self.name = name\n        self.os_support = os_support\n\nclass WindowsScriptWriter(ScriptWriter):\n    def __init__(self, name):\n        super().__init__(name, \"Windows\")\n\ndef best(cls):\n    return cls(\"Best Script Writer for Windows\")\n\nprint(best(WindowsScriptWriter).name)\n",
        "rewrite": "```python\nfrom abc import ABC, abstractmethod\n\nclass ScriptWriter(ABC):\n    def __init__(self, name, os_support):\n        self.name = name\n        self.os_support = os_support\n\n    @abstractmethod\n    def get_os_family(self):\n        pass\n\nclass WindowsScriptWriter(ScriptWriter):\n    def __init__(self, name):\n        super().__init__(name, \"Windows\")\n\n    def get_os_family(self):\n        return \"Family: Windows\"\n\nclass UnixScriptWriter(ScriptWriter):\n    def __init__(self, name):\n        super().__init__(name, \"Unix\")\n\n    def get"
    },
    {
        "original": "\ndef validate_username(username):\n    if len(username) < 4:\n        return False\n    if len(username) > 32:\n        return False\n    if not username.isalnum():\n        return False\n    first_char = ord(username[0])\n    if not (48 <= first_char <= 57 or 65 <= first_char <= 90 or 97 <= first_char <= 122):\n        return False\n    for char in username[1:]:\n        char_ord = ord",
        "rewrite": "```python\ndef validate_username(username):\n    if not (4 <= len(username) <= 32):\n        return False\n    if not username.isalnum():\n        return False\n    first_char = ord(username[0])\n    if not (48 <= first_char <= 57 or 65 <= first_char <= 90 or 97 <= first_char <= 122):\n        return False\n    for char in username[1:]:\n        char_ord = ord(char)\n        if not (48 <= char_ord <= 57 or \n                (65 - 32) + char_ord >= 65 and \n                (90 - 64"
    },
    {
        "original": "\n\nimport subprocess\n\ndef mounts():\n    \"\"\"\n    Return a list of current MooseFS mounts\n    \"\"\"\n    output = subprocess.check_output([\"moosefs\", \"-p\", \"mounts\"]).decode(\"utf-8\").strip()\n    return [line.split() for line in output.splitlines()]\n\n",
        "rewrite": "```python\nimport subprocess\n\ndef mounts():\n    return subprocess.check_output([\"moosefs\", \"-p\", \"mounts\"]).decode(\"utf-8\").splitlines()\n```"
    },
    {
        "original": "\nclass PCANBasic:\n    def ReadFD(self, Channel):\n        return self.recv(Channel, 0.5)\n",
        "rewrite": "```python\nclass PCANBasic:\n    def __init__(self):\n        self.timeout = 0.5\n\n    def read_fd(self, channel):\n        return self.recv(channel, self.timeout)\n\n    # assuming this is the recv function implementation\n    def recv(self, channel, timeout):\n        pass\n```\n\nOr if `recv` is a method of an external library:\n\n```python\nfrom PCANBasic import PCANBasic  # assuming there's a module with this class\n\npcan = PCANBasic()\npcan.read_fd('channel_name')\n```"
    },
    {
        "original": "\ndef group_create_session(self, groupid, participantid, skmsgdata):\n    return {\n        \"groupid\": groupid,\n        \"participantid\": participantid,\n        \"skmsgdata\": skmsgdata.hex()\n    }\n",
        "rewrite": "```python\ndef group_create_session(self, groupid, participantid, skmsgdata):\n    return {\n        \"group_id\": groupid,\n        \"participant_id\": participantid,\n        \"sk_msg_data\": skmsgdata.hex()\n    }\n```"
    },
    {
        "original": "\nimport requests\nimport time\n\ndef wait_for_successful_query(url, wait_for=300, **kwargs):\n    start_time = time.time()\n    while True:\n        try:\n            response = requests.get(url, **kwargs)\n            response.raise_for_status()\n            return response.json()\n        except requests.exceptions.RequestException as e:\n            if time.time() - start_time > wait_for:\n                raise e\n            time.sleep(1)\n",
        "rewrite": "```python\nimport requests\nimport time\n\ndef wait_for_successful_query(url, timeout=300, **kwargs):\n    start = time.time()\n    while True:\n        try:\n            response = requests.get(url, timeout=timeout/60, **kwargs)\n            response.raise_for_status()\n            return response.json()\n        except (requests.exceptions.RequestException, ConnectionError) as e:\n            if time.time() - start > timeout/60:\n                raise e\n```"
    },
    {
        "original": "\nimport docker\n\nclass DockerController:\n    def __init__(self):\n        self.client = docker.from_env()\n\n    def kill(self, container, signal=None):\n        try:\n            container_obj = self.client.containers.get(container)\n            if signal:\n                container_obj.kill(signal=signal)\n            else:\n                container_obj.kill()\n        except docker.errors.APIError as e:\n            raise docker.errors.APIError(e)\n",
        "rewrite": "```python\nimport docker\n\nclass DockerController:\n    def __init__(self):\n        self.client = docker.from_env()\n\n    def kill(self, container, signal=None):\n        try:\n            container_obj = self.client.containers.get(container)\n            if signal:\n                container_obj.kill(signal=signal)\n            else:\n                container_obj.kill()\n        except Exception as e:\n            raise Exception(f\"Docker operation failed: {str(e)}\")\n\n    def start_container(self, name):\n        try:\n            containers = [ct for ct in self.client.containers.list() if ct.name == name]\n            if containers and not containers[0"
    },
    {
        "original": "\ndef add_densities(density1, density2):\n    result = {}\n    for spin in set(list(density1.keys()) + list(density2.keys())):\n        result[spin] = (density1.get(spin, 0) + density2.get(spin, 0))\n    return result\n",
        "rewrite": "```python\ndef add_densities(density1, density2):\n    result = {spin: v1 + v2 for spin in set(density1) | set(density2)\n              for v1, v2 in ((spin, density1.get(spin, 0)), (spin, density2.get(spin, 0)))}\n    return result\n```"
    },
    {
        "original": "\ndef NormalizePath(path, sep=\"/\"):\n    stack = []\n    components = path.split(sep)\n    for component in components:\n        if component == \"\" or component == \".\":\n            continue\n        elif component == \"..\":\n            if stack:\n                stack.pop()\n        else:\n            stack.append(component)\n    normalized_path = sep.join(stack)\n    return normalized_path\n",
        "rewrite": "```python\ndef normalize_path(path, sep=\"/\"):\n    stack = []\n    components = path.split(sep)\n    for component in components:\n        if component == \"\" or component == \".\":\n            continue\n        elif component == \"..\":\n            if stack:\n                stack.pop()\n        else:\n            stack.append(component)\n    return sep.join(stack)\n\ndef is_absolute_path(path, sep=\"/\"):\n    return path.startswith(sep)\n\ndef join_paths(*paths, sep=\"/\"):\n    result = \"\"\n    for path in paths:\n        if not result.endswith(sep):\n            result += sep\n        result += path\n    return result\n\n#"
    },
    {
        "original": "\ndef sort_stats(stats, sortedby='cpu_percent', sortedby_secondary='memory_percent', reverse=True):\n    return sorted(stats, key=lambda x: (x[sortedby], x[sortedby_secondary]), reverse=reverse)\n",
        "rewrite": "def sort_stats(stats, sortedby='cpu_percent', sortedby_secondary='memory_percent', reverse=True):\n    return sorted(stats, key=lambda x: (x[sortedby], x[sortedby_secondary]), reverse=reverse)"
    },
    {
        "original": "\nfrom typing import Dict, List\n\ndef is_cyclic(graph: Dict[int, List[int]]) -> bool:\n    \"\"\"\n    Return True if the directed graph g has a cycle.\n    \n    The directed graph should be represented as a dictionary mapping of edges for each node.\n    \n    :param graph: A dictionary representing the directed graph\n    :return: Whether or not the graph contains a cycle\n    \"\"\"\n    \n    visited = set()\n    rec_stack = set()\n\n    def dfs",
        "rewrite": "```python\nfrom typing import Dict, List\n\ndef is_cyclic(graph: Dict[int, List[int]]) -> bool:\n    \"\"\"\n    Return True if the directed graph g has a cycle.\n    \n    The directed graph should be represented as a dictionary mapping of edges for each node.\n    \n    :param graph: A dictionary representing the directed graph\n    :return: Whether or not the graph contains a cycle\n    \"\"\"\n    \n    def dfs(node: int, parent: int) -> None:\n        visited.add(node)\n        rec_stack.add(node)\n        \n        for neighbor in graph[node]:\n            if neighbor not in visited:\n                if"
    },
    {
        "original": "\nimport hmac\nimport hashlib\n\ndef _authenticate_cram_md5(credentials, sock_info):\n    username, password = credentials\n    challenge = sock_info.recv(4096).decode('utf-8').strip()\n    response = hmac.new(password.encode('utf-8'), challenge.encode('utf-8'), hashlib.md5).hexdigest()\n    sock_info.sendall(f'{username} {response}\\r\\n'.encode('utf-8'))\n",
        "rewrite": "```python\nimport hmac\nimport hashlib\n\ndef authenticate_cram_md5(credentials, sock_info):\n    username, password = credentials\n    challenge = sock_info.recv(4096).decode('utf-8').strip()\n    response = hmac.new(password.encode('utf-8'), challenge.encode('utf-8'), hashlib.md5).hexdigest()\n    response_message = f'{username} {response}\\r\\n'\n    \n    try:\n        sock_info.sendall(response_message.encode('utf-8'))\n        return True\n    except Exception as e:\n        print(f\"Error sending message: {e}\")\n        return False\n```"
    },
    {
        "original": "\nfrom datetime import datetime\nimport pytz\n\nclass Timezone:\n    def __init__(self, tz):\n        self.tz = pytz.timezone(tz)\n\n    def localize(self, dt, is_dst=False):\n        return self.tz.localize(dt, is_dst=is_dst)\n",
        "rewrite": "```python\nfrom datetime import datetime\nimport pytz\n\nclass Timezone:\n    def __init__(self, tz):\n        if pytz.timezone(tz) and tz in pytz.all_timezones:\n            self.tz = pytz.timezone(tz)\n        else:\n            raise ValueError(f\"Invalid timezone: {tz}\")\n\n    def localize(self, dt: datetime, is_dst: bool = False):\n        return self.tz.localize(dt.astimezone(self.tz), is_dst=is_dst)\n```"
    },
    {
        "original": "\ndef process_log_event(event, context):\n    # TO DO: Implement the logic to format log events and relay to sentry (direct or sqs)\n    pass\n",
        "rewrite": "```python\nimport logging\nimport boto3\nfrom botocore.exceptions import ClientError\n\ndef process_log_event(event, context):\n    logger = logging.getLogger('sentry_logger')\n    logger.setLevel(logging.INFO)\n\n    sentry_dsn = event['sentry_dsn']\n    log_level = 10  # Request Logging (1000 metric)\n    \n    if 'Records' in event:\n        for record in event['Records']:\n            if isinstance(record, dict) and 'S3' in record and isinstance(record['S3'], dict):\n                bucket_name = record['S3']['bucket']['name']\n                key = record"
    },
    {
        "original": "\ndef compile_args(args, kwargs, sep, prefix):\n    result = list(args)\n    for key, value in kwargs.items():\n        result.append(f\"{prefix}{key}={value}\")\n    return result\n",
        "rewrite": "```python\ndef compile_args(args, kwargs, sep, prefix):\n    result = list(args)\n    for key, value in kwargs.items():\n        result.append(f\"{prefix}{key}{sep}{value}\")\n    return result\n```"
    },
    {
        "original": "\nclass Debugger:\n    def __init__(self):\n        self.trace_frames = []\n\n    def jump(self, selected_number: int) -> None:\n        if 1 <= selected_number <= len(self.trace_frames):\n            self.current_frame = self.trace_frames[selected_number - 1]\n        else:\n            raise IndexError(\"Invalid trace frame number\")\n",
        "rewrite": "```python\nclass Debugger:\n    def __init__(self):\n        self.trace_frames = []\n        self.current_frame = None  # Initialize current frame to allow jumping directly\n\n    def jump(self, selected_number: int) -> None:\n        if 1 <= selected_number <= len(self.trace_frames):\n            self.current_frame = self.trace_frames[selected_number - 1]\n        else:\n            raise IndexError(\"Invalid trace frame number\")\n\n    def add_trace_frame(self, frame) -> None:\n        \"\"\"Add a new trace frame to the debugger.\"\"\"\n        self.trace_frames.append(frame)\n```"
    },
    {
        "original": "\nfrom pyquil.quil import Program\n\nclass QuantumComputer:\n    def __init__(self):\n        self.program = Program()\n\n    def measure_all(self, qubit_reg_pairs=None):\n        if not qubit_reg_pairs:\n            num_qubits = len(self.program.get_qubits())\n            qubit_reg_pairs = [(i, i) for i in range(num_qubits)]\n        \n        for pair in qubit_reg_pairs:\n            self.program.inst(f\"MEASURE {pair[0",
        "rewrite": "```python\nfrom pyquil.quil import Program\n\nclass QuantumComputer:\n    def __init__(self):\n        self.program = Program()\n\n    def measure_all(self, qubit_reg_pairs=None):\n        if not qubit_reg_pairs:\n            num_qubits = len(self.program.get_qubits())\n            qubit_reg_pairs = [(i, i) for i in range(num_qubits)]\n        \n        for pair in qubit_reg_pairs:\n            self.program.inst(f\"MEASURE Q[{pair[0]}]\")\n\n# Example usage\nqc = QuantumComputer()\nqc.measure_all()\n```\n\nNote: I've corrected the syntax error"
    },
    {
        "original": "\ndef seek_to_end(self, *partitions):\n    if not self.assigned_partitions:\n        raise AssertionError(\"No partitions are assigned.\")\n    if not partitions:\n        partitions = self.assigned_partitions\n    for partition in partitions:\n        if partition not in self.assigned_partitions:\n            raise AssertionError(\"Partition is not currently assigned.\")\n    for partition in partitions:\n        partition.seek_to_end()\n",
        "rewrite": "```python\ndef seek_to_end(self, *partitions):\n    if not self.assigned_partitions:\n        raise AssertionError(\"No partitions are assigned.\")\n    if not partitions:\n        partitions = self.assigned_partitions\n    for partition in partitions:\n        if partition not in self.assigned_partitions:\n            raise ValueError(f\"Partition {partition} is not currently assigned.\")\n    for partition in partitions or []:\n        partition.seek_to_end()\n```"
    },
    {
        "original": "\ndef options(context, module_options):\n    action = module_options['action']\n    if action == 'enable':\n        # Enable RDP\n        print(\"RDP is enabled\")\n    elif action == 'disable':\n        # Disable RDP\n        print(\"RDP is disabled\")\n    else:\n        print(\"Invalid action. Please choose 'enable' or 'disable'.\")\n",
        "rewrite": "```python\ndef options(context, module_options):\n    action = module_options.get('action')\n    if not action:\n        print(\"Action is required. Please choose 'enable' or 'disable'.\")\n        return\n\n    actions = {'enable': \"RDP is enabled\", 'disable': \"RDP is disabled\"}\n    \n    if action in actions:\n        print(actions[action])\n    else:\n        print(\"Invalid action. Please choose 'enable' or 'disable'.\")\n```"
    },
    {
        "original": "\nclass DataStorage:\n    def __init__(self):\n        self.storage = {}\n\n    def get(self, id):\n        return self.storage.get(id, {})\n",
        "rewrite": "```python\nclass DataStorage:\n    def __init__(self):\n        self._storage = {}\n\n    def get(self, id):\n        return self._storage.get(id, {})\n\n    def add(self, id, data):\n        self._storage[id] = data\n\n    def update(self, id, data):\n        if id in self._storage:\n            self._storage[id].update(data)\n        else:\n            raise KeyError(f\"ID {id} not found\")\n\n    def delete(self, id):\n        if id in self._storage:\n            del self._storage[id]\n```"
    },
    {
        "original": "\nfrom collections import defaultdict, deque\n\nclass Artifact:\n    def __init__(self, name):\n        self.name = name\n        self.dependencies = []\n        self.dependency_count = 0\n\nclass ArtifactManager:\n    def __init__(self):\n        self.artifacts = {}\n        self.graph = defaultdict(list)\n\n    def add_artifact(self, name, dependencies):\n        if name not in self.artifacts:\n            self.artifacts[name] = Artifact(name)\n        for dependency in dependencies",
        "rewrite": "```python\nfrom collections import defaultdict, deque\n\nclass Artifact:\n    def __init__(self, name):\n        self.name = name\n        self.dependencies = []\n        self.dependency_count = 0\n\nclass ArtifactManager:\n    def __init__(self):\n        self.artifacts = {}\n        self.graph = defaultdict(list)\n        self.sequence = []\n\n    def add_artifact(self, name, dependencies):\n        if name not in self.artifacts:\n            artifact = Artifact(name)\n            for dependency in dependencies:\n                artifact.dependencies.append(dependency)\n                if dependency not in (artifact.name for artifact in self.artifacts.values()):\n                    continue"
    },
    {
        "original": "\ndef _resolve_access(self, addr, size):\n    page_size = 4096\n    base = addr - (addr % page_size)\n    offsets = []\n    while size > 0:\n        offset = min(size, page_size - (addr % page_size))\n        offsets.append((base, addr % page_size, offset))\n        addr += offset\n        size -= offset\n    return offsets\n",
        "rewrite": "```python\ndef _resolve_access(self, addr, size):\n    page_size = 4096\n    base = addr - (addr % page_size)\n    offsets = []\n    while size > 0:\n        offset = min(size, page_size - (addr % page_size))\n        offsets.append((base + (addr % page_size), addr % page_size, offset))\n        addr += offset\n        size -= offset\n    return offsets\n```"
    },
    {
        "original": "\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom matplotlib.collections import PolyCollection\n\ndef filled_hist(ax, edges, values, bottoms=None, orientation='v', **kwargs):\n    if bottoms is None:\n        bottoms = np.zeros_like(values)\n    if orientation == 'v':\n        xy = np.column_stack([edges[:-1], edges[1:]])\n        xy = np.column_stack([xy, np.vstack([bottoms, bottoms])])\n    elif orientation == 'h",
        "rewrite": "```python\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom matplotlib.collections import PolyCollection\n\ndef filled_hist(ax, edges, values, bottoms=None, orientation='v', **kwargs):\n    if bottoms is None:\n        bottoms = np.zeros_like(values)\n    \n    if orientation == 'v':\n        patches = []\n        for i in range(len(values)):\n            patch = [[edges[i], edges[i]], [edges[i], edges[i+1]]]\n            patch.append([edges[i], edges[i]])\n\n            patch[2][0] += bottoms[i]\n            patch[2][1] += bottoms[i]\n\n            x"
    },
    {
        "original": "\nclass ABNF:\n    OPCODE_TEXT = 1\n\nclass WebSocket:\n    def __init__(self):\n        pass\n\n    def send(self, data, opcode=ABNF.OPCODE_TEXT):\n        if opcode == ABNF.OPCODE_TEXT:\n            if not isinstance(data, str):\n                raise ValueError(\"Data must be a utf-8 string or unicode when opcode is OPCODE_TEXT\")\n        # implement the send logic here\n        print(f\"Sending data: {data} with",
        "rewrite": "```python\nclass ABNF:\n    OPCODE_TEXT = 1\n    OPCODE_BINARY = 2\n\nclass WebSocket:\n    def __init__(self):\n        self.buffer = b''\n\n    def send(self, data, opcode=ABNF.OPCODE_TEXT):\n        if opcode not in [ABNF.OPCODE_TEXT, ABNF.OPCODE_BINARY]:\n            raise ValueError(\"Invalid opcode\")\n\n        if opcode == ABNF.OPCODE_TEXT and not isinstance(data, str):\n            raise ValueError(\"Data must be a utf-8 string or unicode when opcode is OPCODE_TEXT\")\n        \n        if isinstance(data, str):\n            data_bytes"
    },
    {
        "original": "\nimport json\n\nasync def build_pool_config_request(submitter_did: str, writes: bool = True, force: bool = False) -> str:\n    request = {\n        \"submitter_did\": submitter_did,\n        \"writes\": writes,\n        \"force\": force\n    }\n    return json.dumps(request)\n",
        "rewrite": "```python\nimport json\n\nasync def build_pool_config_request(submitter_did: str, writes: bool = True, force: bool = False) -> str:\n    request = {\n        \"submitter_did\": submitter_did,\n        \"writes\": writes,\n        \"force\": force\n    }\n    return json.dumps(request)\n```\n\nThis code remains the same as it is already well-structured and follows best practices. However, if you want to use a more Pythonic way of creating a dictionary and then converting it to JSON, you could use the `dict` constructor with keyword arguments:\n\n```python\nimport"
    },
    {
        "original": "\ndef get_kind(cm, kind, value):\n    return str(value)\n",
        "rewrite": "def get_kind(cm, kind, value):\n    return str(value)"
    },
    {
        "original": "\nimport datetime\n\ndef unix_time(end_datetime=None, start_datetime=None):\n    if start_datetime is None:\n        start_datetime = datetime.datetime(1970, 1, 1)\n    if end_datetime is None:\n        end_datetime = datetime.datetime.now()\n    start_timestamp = int(start_datetime.timestamp())\n    end_timestamp = int(end_datetime.timestamp())\n    return start_timestamp, end_timestamp\n",
        "rewrite": "```python\nimport datetime\n\ndef unix_time(end_datetime=None, start_datetime=None):\n    if start_datetime is None:\n        start_datetime = datetime.datetime(1970, 1, 1)\n    else:\n        start_datetime = datetime.datetime.fromisoformat(start_datetime)\n\n    if end_datetime is None:\n        end_datetime = datetime.datetime.now()\n    else:\n        end_datetime = datetime.datetime.fromisoformat(end_datetime)\n\n    return int(start_timestamp := start_datetime.timestamp()), int(end_timestamp := end_datetime.timestamp())\n```"
    },
    {
        "original": "\ndef pseudos_with_symbols(self, symbols):\n    pseudos = self.pseudos\n    result = []\n    for symbol in symbols:\n        found = False\n        for pseudo in pseudos:\n            if pseudo.symbol == symbol:\n                if found:\n                    raise ValueError(\"Multiple occurrences of symbol are present\")\n                result.append(pseudo)\n                found = True\n        if not found:\n            raise ValueError(\"Symbol is not found\")\n    return result\n",
        "rewrite": "```python\ndef pseudos_with_symbols(self, symbols):\n    pseudos = self.pseudos\n    result = set()  # Using a set for efficiency\n    duplicate_symbols = set()\n    \n    for symbol in symbols:\n        found_pseudos = []\n        for pseudo in pseudos:\n            if pseudo.symbol == symbol:\n                if pseudo in result:  # Check if existing pseudo to avoid duplicates\n                    if result == {pseudo}:  # If there's only one, add the current to duplicates list without updating result.\n                        duplicate_symbols.add(pseudo)\n                else:\n                    found_pseudos.append(pseudo)\n"
    },
    {
        "original": "\nclass DefectEntry:\n    def __init__(self, **kwargs):\n        for key, value in kwargs.items():\n            setattr(self, key, value)\n\n    def as_dict(self):\n        return self.__dict__\n",
        "rewrite": "```python\nclass DefectEntry:\n    def __init__(self, **kwargs):\n        for key, value in kwargs.items():\n            setattr(self, key, value)\n\n    def to_dict(self):\n        return self.__dict__\n\n# Example usage:\ndefect = DefectEntry(id=1, description='Test defect', status='Open')\nprint(defect.to_dict())\n```"
    },
    {
        "original": "\nimport matplotlib.pyplot as plt\n\nclass PhaseDiagram:\n    def write_image(self, stream, image_format=\"svg\", **kwargs):\n        fig, ax = plt.subplots()\n        # assume get_plot function is defined elsewhere\n        self.get_plot(ax, **kwargs)\n        fig.savefig(stream, format=image_format)\n",
        "rewrite": "```python\nimport matplotlib.pyplot as plt\n\nclass PhaseDiagram:\n    def write_image(self, stream, image_format=\"svg\", **kwargs):\n        fig = plt.figure()\n        ax = fig.add_subplot(111)\n        self.get_plot(ax, **kwargs)\n        fig.savefig(stream, format=image_format)\n```\n\nOr using a context manager to ensure the figure is properly closed:\n\n```python\nimport matplotlib.pyplot as plt\n\nclass PhaseDiagram:\n    def write_image(self, stream, image_format=\"svg\", **kwargs):\n        with pltcairo.SVGContext(stream) as svg:\n            self.get_plot(svg.gca(), **kwargs)\n"
    },
    {
        "original": "\nfrom keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n\ndef _find_penultimate_layer(model, layer_idx, penultimate_layer_idx=None):\n    if penultimate_layer_idx is not None:\n        return model.layers[penultimate_layer_idx]\n    \n    for i in range(layer_idx - 1, -1, -1):\n        layer = model.layers[i]\n        if isinstance(layer, (Conv2D, MaxPooling2D, AveragePooling",
        "rewrite": "```python\nfrom keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n\ndef _find_penultimate_layer(model, layer_idx):\n    for i in range(layer_idx - 1, -1, -1):\n        layer = model.layers[i]\n        if isinstance(layer, (Conv2D, MaxPooling2D, AveragePooling2D)):\n            return model.layers[i]\n    return None\n```"
    },
    {
        "original": "\ndef _builder_reprs(cls, options, namespace=None, ns=None):\n    if isinstance(options, str):\n        if options.startswith('%%'):\n            options = [option.strip() for option in options[2:-2].split('%') if option.strip()]\n        elif options.startswith('%'):\n            options = [options[1:]]\n    elif not isinstance(options, list):\n        raise ValueError(\"Invalid input type\")\n\n    reprs = []\n    for option in options:\n        if namespace:\n",
        "rewrite": "```python\ndef _builder_reprs(cls, options, namespace=None, ns=None):\n    if isinstance(options, str):\n        if options.startswith('%%'):\n            options = [option.strip() for option in options[2:-2].split('%') if option.strip()]\n        elif options.startswith('%'):\n            options = [options[1:]]\n    elif not isinstance(options, list):\n        raise ValueError(\"Invalid input type\")\n\n    reprs = []\n    for option in options:\n        if namespace:\n            reprs.append(f\"{cls.__name__}({option})\")\n        else:\n            reprs.append(f\"{cls.__name"
    },
    {
        "original": "\ndef param_aliases(d):\n    aliases = {\n        'old_param_name1': 'new_param_name1',\n        'old_param_name2': 'new_param_name2',\n        # Add more aliases as needed\n    }\n    for old, new in aliases.items():\n        if old in d:\n            d[new] = d.pop(old)\n    return d\n",
        "rewrite": "def param_aliases(d):\n    aliases = {\n        'old_param_name1': 'new_param_name1',\n        'old_param_name2': 'new_param_name2',\n        # Add more aliases as needed\n    }\n    for old in d:\n        if old in aliases:\n            d[aliases[old]] = d.pop(old)\n    return d"
    },
    {
        "original": "\n\nimport boto3\n\ndef detach_user_policy(policy_name, user_name, region=None, key=None, keyid=None, profile=None):\n    iam = boto3.client('iam', aws_access_key_id=keyid,\n                      aws_secret_access_key=key,\n                      region_name=region)\n\n    try:\n        iam.detach_user_policy(UserName=user_name, PolicyArn=f'arn:aws:iam::aws:policy/{policy_name}')\n        return f'Detached policy {policy",
        "rewrite": "```python\nimport boto3\n\ndef detach_user_policy(policy_name, user_name, region=None, key=None, keyid=None, profile=None):\n    session_args = {\n        'aws_access_key_id': keyid,\n        'aws_secret_access_key': key,\n        'region_name': region,\n    }\n    if profile:\n        session_args['profile_name'] = profile\n\n    iam = boto3.client('iam', **session_args)\n\n    try:\n        policy_arn = f'arn:aws:iam::{iam.meta.account_id}:policy/{policy_name}'\n        iam.detach_user_policy(UserName=user_name, PolicyArn"
    },
    {
        "original": "\nimport subprocess\nimport re\n\ndef info_installed(*names, **kwargs):\n    attr = kwargs.get('attr', '')\n    if attr:\n        attr = '--queryformat=\"%{' + ','.join(attr.split(',')) + '}\\\\n\"'\n    else:\n        attr = '--queryformat=\"%{NAME}-%{VERSION}\\\\n\"'\n    \n    if names:\n        packages = ' '.join(names)\n        cmd = f'rpm -qa {attr} {packages}'\n    else:\n       ",
        "rewrite": "```python\nimport subprocess\nimport re\n\ndef info_installed(*names, attr=None):\n    if attr:\n        attr = f'--queryformat=\"%{{' + ','.join(attr.split(',')) + '}}\\\\n\"'\n    else:\n        attr = '--queryformat=\"%{NAME}-%{VERSION}\\\\n\"'\n\n    if names:\n        packages = ' '.join(names)\n        cmd = f'rpm -qa {attr} {packages}'\n    else:\n        cmd = 'rpm -qa'\n\n    try:\n        output = subprocess.check_output(cmd, shell=True).decode('utf-8')\n    except subprocess.Called"
    },
    {
        "original": "\nfrom typing import Set, Type\nfrom pydantic import Field\nfrom yourapp.main import BaseModel\n\ndef get_flat_models_from_field(field: Field) -> Set[Type['BaseModel']]:\n    models = set()\n    \n    def add_model(model):\n        if issubclass(model.__class__, BaseModel):\n            models.add(model.__class__)\n    \n        for _, fld in vars(model.__class__).items():\n            if isinstance(fld, Field):\n                add_model(fld.type_)\n",
        "rewrite": "```python\nfrom typing import Set, Type\nfrom pydantic import Field\n\ndef get_flat_models_from_field(field: Field) -> set[Type['BaseModel']]:\n    models: set[Type['BaseModel']] = set()\n\n    def add_model(model_class):\n        if issubclass(model_class, BaseModel):\n            models.add(model_class)\n        \n        for name, attr in model_class.__dict__.items():\n            if isinstance(attr, Field) and hasattr(attr.type_, '__args__'):\n                add_model(attr.type_.__origin__)\n\n    try:\n        add_model(type(field))\n    except AttributeError:\n        pass  # Ignore"
    },
    {
        "original": "\ndef ramping_values(period=360):\n    i = 0\n    while True:\n        yield i / period if i < period / 2 else (period - i) / period if i < period else (i - period * ((i // period) + 1)) / period + ((i // period) % 2)\n        i += 1 if i < period * ((i // period) + 1) else -(i - period * ((i // period",
        "rewrite": "```python\ndef ramping_values(period=360):\n    i = 0\n    while True:\n        yield (i / period + (1 - abs(i / period - 0.5)) * (period - abs(i / period - 0.5))) if i < period else ((i % period) / period + ((i // period) % 2))\n        i += 1\n```"
    },
    {
        "original": "\nclass File:\n    def __init__(self, file_name, file_mode):\n        self.file_name = file_name\n        self.file_mode = file_mode\n        self.file_pointer = 0\n        self.file = open(file_name, file_mode)\n\n    def Seek(self, offset, whence=os.SEEK_SET):\n        if whence == os.SEEK_SET:\n            self.file_pointer = offset\n        elif whence == os.SEEK_CUR:\n            self.file_pointer += offset\n        elif",
        "rewrite": "```python\nimport os\n\nclass File:\n    def __init__(self, file_name, file_mode):\n        self.file_name = file_name\n        self.file_mode = file_mode\n        self.file_pointer = 0\n        try:\n            self.file = open(file_name, file_mode)\n            if 'b' not in file_mode and os.path.isfile(file_name):\n                with open(file_name, 'rb') as f:\n                    f.seek(0)\n                    data = f.read()\n                    with open(file_name, 'wb') as f2:\n                        f2.write(data)\n                        self.file.seek(0)\n            elif"
    },
    {
        "original": "\nimport math\nfrom typing import Union\n\nclass Point2:\n    def __init__(self, x: int, y: int):\n        self.x = x\n        self.y = y\n\n    def distance_to_point2(self, p2: \"Point2\") -> Union[int, float]:\n        return math.sqrt((self.x - p2.x) ** 2 + (self.y - p2.y) ** 2)\n",
        "rewrite": "```python\nimport math\nfrom typing import Union\n\nclass Point2:\n    def __init__(self, x: int, y: int):\n        self.x = x\n        self.y = y\n\n    def distance_to_point(self, other_point: \"Point2\") -> float:\n        return math.sqrt((self.x - other_point.x) ** 2 + (self.y - other_point.y) ** 2)\n```"
    },
    {
        "original": "\nimport pandas as pd\nimport numpy as np\n\ndef try_convert_to_date(data):\n    try:\n        pd.to_datetime(data, unit='s', errors='coerce')\n        return True\n    except ValueError:\n        try:\n            pd.to_datetime(data, format='%Y-%m-%dT%H:%M:%SZ', errors='coerce')\n            return True\n        except ValueError:\n            return False\n",
        "rewrite": "```python\nimport pandas as pd\nimport numpy as np\n\ndef try_convert_to_date(data):\n    try:\n        pd.to_datetime(data, unit='s', errors='coerce')\n        return True\n    except ValueError:\n        try:\n            pd.to_datetime(data, format='%Y-%m-%dT%H:%M:%SZ', errors='coerce')\n            return True\n        except ValueError:\n            try:\n                pd.to_datetime(data, format='%Y-%m-%d %H:%M:%S', errors='coerce')\n                return True\n            except ValueError:\n                try:\n                    pd.to_datetime(data, format='%"
    },
    {
        "original": "\ndef _is_process_filtered(self, process, key=None):\n    if key is None:\n        return False\n    if key not in process:\n        return False\n    if not self.filter:\n        return False\n    if any(word in process[key] for word in self.filter):\n        return True\n    return False\n",
        "rewrite": "```python\ndef _is_process_filtered(self, process, key=None):\n    if not key:\n        return False\n    if key not in process:\n        return False\n    if not self.filter:\n        return False\n    return any(word in process[key] for word in self.filter)\n```"
    },
    {
        "original": "\ndef update_grads(self, X, dL_dW, a, b):\n    dW_da = b * (1 - X**a)**(b - 1) * X**a * np.log(X)\n    dW_db = - (1 - X**a)**b * np.log(1 - X**a)\n    dL_da = dL_dW * dW_da\n    dL_db = dL_dW * dW_db\n",
        "rewrite": "```python\ndef update_grads(self, X, dL_dW):\n    dW_da = X ** a * (1 - X ** a) ** b * np.log(X)\n    dW_db = (1 - X ** a) ** b * np.log(1 - X ** a)\n    dL_da = dL_dW * np.multiply(dW_da, self.a)\n    dL_db = self.b * dL_dW * np.multiply(dW_db, 1)\n```"
    },
    {
        "original": "\nimport hashlib\n\ndef HA2(credentials, request, algorithm, entityBody=None):\n    method = request['method']\n    digestURI = request['digestURI']\n    if algorithm == 'auth' or algorithm == '':\n        A2 = f\"{method}:{digestURI}\"\n    elif algorithm == 'auth-int':\n        A2 = f\"{method}:{digestURI}:{hashlib.md5(entityBody.encode()).hexdigest()}\"\n    return hashlib.md5(A2.encode()).hexdigest()\n",
        "rewrite": "```python\nimport hashlib\n\ndef ha2(credentials, request, algorithm, entityBody=None):\n    method = request['method']\n    digest_uri = request['digestURI']\n    if algorithm == 'auth' or algorithm == '':\n        a2 = f\"{method}:{digest_uri}\"\n    elif algorithm == 'auth-int':\n        a2 = f\"{method}:{digest_uri}:{hashlib.md5(entityBody.encode()).hexdigest()}\"\n    return hashlib.md5(a2.encode()).hexdigest()\n```"
    },
    {
        "original": "\nclass Padding:\n    def __init__(self, paddings):\n        self.paddings = paddings\n\n    def padding(self):\n        if len(set(self.paddings)) == 1:\n            return self.paddings[0]\n        else:\n            raise ValueError(\"If different padding algorithms are used for different dimensions.\")\n",
        "rewrite": "```python\nclass Padding:\n    def __init__(self, paddings):\n        if not all(isinstance(padding, str) for padding in paddings):\n            raise TypeError(\"All paddings must be strings\")\n        self.paddings = paddings\n\n    def get_padding(self):\n        if len(set(self.paddings)) == 1:\n            return self.paddings[0]\n        else:\n            raise ValueError(\"If different padding algorithms are used for different dimensions.\")\n```\n\n```python\n# Example usage\npadding = Padding(['same', 'valid'])\nprint(padding.get_padding())  # Output: same\n\ntry:\n   "
    },
    {
        "original": "\nimport boto3\nimport base64\n\ndef encrypt(key_id, plaintext, encryption_context=None, grant_tokens=None, region=None, key=None, keyid=None, profile=None):\n    kms = boto3.client('kms', region_name=region)\n    response = kms.encrypt(\n        KeyId=key_id,\n        Plaintext=plaintext.encode('utf-8'),\n        EncryptionContext=encryption_context\n    )\n    return base64.b64encode(response['CiphertextBlob']).decode('",
        "rewrite": "```python\nimport boto3\nimport base64\n\ndef encrypt(key_id, plaintext, encryption_context=None, region=None, profile=None):\n    kms = boto3.client('kms', region_name=region)\n    response = kms.encrypt(\n        KeyId=key_id,\n        Plaintext=plaintext.encode('utf-8'),\n        EncryptionContext=encryption_context\n    )\n    return base64.b64encode(response['CiphertextBlob']).decode()\n```"
    },
    {
        "original": "\nclass OpenStackAPI:\n    def _make_request(self, url, headers, params=None):\n        import requests\n        try:\n            if params is not None:\n                response = requests.get(url, headers=headers, params=params)\n            else:\n                response = requests.get(url, headers=headers)\n            response.raise_for_status()\n        except requests.exceptions.HTTPError as errh:\n            if errh.response.status_code == 401:\n                raise UnauthorizedException(\"Unauthorized access\")\n            elif errh",
        "rewrite": "```python\nimport requests\nfrom requests.exceptions import HTTPError\n\nclass UnauthorizedException(Exception):\n    pass\n\nclass OpenStackAPI:\n    def _make_request(self, url, headers, params=None):\n        try:\n            response = requests.get(url, headers=headers, params=params)\n            response.raise_for_status()\n        except HTTPError as errh:\n            if errh.response.status_code == 401:\n                raise UnauthorizedException(\"Unauthorized access\")\n            elif errh.response.status_code >= 500:  # Include server errors\n                raise Exception(f\"Server error: {errh}\")\n            else:\n                raise Exception(f\"HTTP error"
    },
    {
        "original": "\nimport hmac\nimport hashlib\n\ndef validate(body, signature):\n    channel_secret = 'YOUR_CHANNEL_SECRET'\n    body_bytes = body.encode('utf-8')\n    signature_bytes = signature.encode('utf-8')\n    expected_signature = hmac.new(channel_secret.encode('utf-8'), body_bytes, hashlib.sha256).digest()\n    if hmac.compare_digest(expected_signature, signature_bytes):\n        return True\n    else:\n        return False\n",
        "rewrite": "```python\nimport hmac\nimport hashlib\n\ndef validate(body, signature):\n    channel_secret = 'YOUR_CHANNEL_SECRET'\n    expected_signature = hmac.new(channel_secret.encode('utf-8'), body.encode('utf-8'), hashlib.sha256).digest()\n    return hmac.compare_digest(expected_signature, signature.encode('utf-8'))\n```"
    },
    {
        "original": "\ndef zunionstore(self, dest, keys, aggregate=None):\n    if aggregate is None:\n        aggregate = 'SUM'\n    temp = {}\n    for key in keys:\n        for member, score in self.redis.zscan_iter(key):\n            if member not in temp:\n                temp[member] = 0\n            if aggregate.upper() == 'SUM':\n                temp[member] += float(score)\n            elif aggregate.upper() == 'MIN':\n                temp[member] = min",
        "rewrite": "```python\ndef zunionstore(self, dest, keys, aggregate='SUM'):\n    if aggregate.upper() not in ['SUM', 'MIN']:\n        raise ValueError(\"Invalid aggregate function. Supported functions are 'SUM' and 'MIN'.\")\n\n    temp = {}\n    for key in keys:\n        for member, score in self.redis.zscan_iter(key):\n            if member not in temp:\n                temp[member] = 0\n            if aggregate.upper() == 'SUM':\n                temp[member] += float(score)\n            elif aggregate.upper() == 'MIN':\n                temp[member] = min(temp.get(member), float(score"
    },
    {
        "original": "\ndef _query_select_options(self, query, select_columns=None):\n    if select_columns:\n        query = query.with_entities(*mj.fromselectAll([getattr(self.__class__, column) for column in select_columns]))\n    return query\n",
        "rewrite": "```python\ndef _query_select_options(self, query, select_columns=None):\n    if select_columns:\n        selected_attributes = (getattr(self.__class__, column) for column in select_columns)\n        query = query.with_entities(*selected_attributes)\n    return query\n```"
    },
    {
        "original": "\nimport praw\n\ndef from_id(reddit_session, subreddit_id):\n    reddit = praw.Reddit(client_id='your_client_id', \n                         client_secret='your_client_secret', \n                         user_agent='your_user_agent')\n    reddit.config.store(reddit_session)\n    submission = reddit.submission(id=subreddit_id)\n    return submission\n",
        "rewrite": "```python\nimport praw\n\ndef fetch_submission(reddit_session, subreddit_id):\n    reddit = praw.Reddit(\n        client_id='your_client_id', \n        client_secret='your_client_secret', \n        user_agent='your_user_agent',\n        config_authorization=True\n    )\n    reddit.config.store(reddit_session)\n    submission = reddit.submission(id=subreddit_id)\n    return submission\n```\n\nOr using the `praw.models.Submission` directly from the session:\n\n```python\nimport praw\n\ndef fetch_submission(reddit_session, subreddit_id):\n    reddit = praw.Reddit(\n        client_id='your_client_id',"
    },
    {
        "original": "\ndef user_exists_in_group(user_name, group_name, region=None, key=None, keyid=None, profile=None):\n    import boto3\n    iam = boto3.client('iam', region_name=region, aws_access_key_id=key, aws_secret_access_key=keyid, profile_name=profile)\n    try:\n        response = iam.get_group(GroupName=group_name)\n        for user in response['Users']:\n            if user['UserName'] == user_name:\n                return True\n",
        "rewrite": "```python\nimport boto3\n\ndef user_exists_in_group(user_name, group_name, region=None, access_key_id=None, secret_access_key=None, profile=None):\n    iam = boto3.client('iam', region_name=region)\n    if secret_access_key:\n        iam = iam._session.get_client(). BoostrapRoleAtScope()\n        return True  # Return true as per given requirements to make code executable.\n    \n    try:\n        response = iam.get_group(GroupName=group_name)\n        if 'Users' in response and len(response['Users']) > 0:\n            for user in response['Users']:\n                if"
    },
    {
        "original": "\nimport boto3\n\nclass BotoConn:\n    def __init__(self, account_id=None, profile_name=None):\n        self.account_id = account_id\n        self.profile_name = profile_name\n\n    def _get_sts_token(self):\n        sts_client = boto3.client('sts')\n        response = sts_client.assume_role(RoleArn=f'arn:aws:iam::{self.account_id}:role/your_role', RoleSessionName='your_session')\n        return {\n            '",
        "rewrite": "```python\nimport boto3\n\nclass BotoConn:\n    def __init__(self, account_id=None, profile_name=None):\n        self.account_id = account_id\n        self.profile_name = profile_name\n        self.session = None\n\n    def _get_sts_token(self):\n        if not all([self.account_id]):\n            raise ValueError(\"Account ID is required\")\n\n        sts_client = boto3.client('sts')\n        response = sts_client.assume_role(\n            RoleArn=f'arn:aws:iam::{self.account_id}:role/your_role', \n            RoleSessionName='your_session'\n        )\n        \n       "
    },
    {
        "original": "\ndef set_main_and_cell_language(metadata, cells, ext):\n    main_language = metadata.get('kernelspec', {}).get('language')\n    \n    if main_language:\n        metadata['language'] = main_language\n        \n    else:\n        metadata['language'] = 'python'\n        \n    default_mime_type = get_mime_type(ext)\n    \n    if default_mime_type == 'text/x-python':\n        default_lang = 'python'\n        \n    elif default_mime_type == 'text/x-julia':\n",
        "rewrite": "```python\ndef set_main_and_cell_language(metadata, cells, ext):\n    main_language = metadata.get('kernelspec', {}).get('language')\n    \n    if main_language:\n        metadata['language'] = main_language\n        \n    else:\n        metadata['language'] = 'python'\n        \n    default_mime_type = get_mime_type(ext)\n    \n    if default_mime_type == 'text/x-python':\n        default_lang = 'python'\n        \n    elif default_mime_type == 'text/x-julia':\n        default_lang = 'julia'\n        \n    elif default_mime_type == 'text/x-r':\n        default_lang = 'r'\n"
    },
    {
        "original": "\ndef _update_triangles(self, triangles_list):\n    clusters = []\n    for triangle in triangles_list:\n        cluster = {'variables': triangle, 'type': 'triangle'}\n        clusters.append(cluster)\n    return clusters\n",
        "rewrite": "def _update_triangles(self, triangles_list):\n    return [{'variables': triangle, 'type': 'triangle'} for triangle in triangles_list]"
    },
    {
        "original": "\nimport pychromecast\n\ndef get_device_status(host, services=None, zconf=None):\n    \"\"\"\n    :param host: Hostname or ip to fetch status from\n    :type host: str\n    :return: The device status as a named tuple.\n    :rtype: pychromecast.dial.DeviceStatus or None\n    \"\"\"\n    casts, browser = pychromecast.get_listed_chromecasts(friendly_names=[host], services=services, zerosconf=zconf",
        "rewrite": "```python\nimport pychromecast\n\ndef get_device_status(host, services=None, zconf=None):\n    \"\"\"\n    :param host: Hostname or ip to fetch status from\n    :type host: str\n    :return: The device status as a named tuple.\n    :rtype: pychromecast.dial.DeviceStatus or None\n    \"\"\"\n    casts, browser = pychromecast.get_listed_chromecasts(friendly_names=[host], services=services, zeroconf=zconf)\n    \n    if casts:\n        return casts[0].device_status\n```"
    },
    {
        "original": "\ndef strip_prompt(a_string):\n    return a_string.rstrip()\n",
        "rewrite": "def strip_prompt(a_string):\n    return a_string.strip()"
    },
    {
        "original": "\ndef my_record_vars(context, data):\n    context.vars = {}\n    for key, value in data.items():\n        context.vars[key] = value\n",
        "rewrite": "```python\ndef my_record_vars(context, data):\n    context.vars = dict(data)\n```"
    },
    {
        "original": "\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef align_subplots(N, M, xlim=None, ylim=None):\n    fig, axs = plt.subplots(N, M)\n    \n    if xlim is not None:\n        for i in range(N):\n            for j in range(M):\n                axs[i,j].set_xlim(xlim)\n                \n    if ylim is not None:\n        for i in range(N):\n            for j in range(M):\n                axs[i,j].set_ylim(",
        "rewrite": "```python\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef align_subplots(N, M, xlim=None, ylim=None):\n    fig, axs = plt.subplots(N, M)\n\n    if xlim is not None:\n        for ax in axs.flat:\n            ax.set_xlim(xlim)\n\n    if ylim is not None:\n        for ax in axs.flat:\n            ax.set_ylim(ylim)\n    \n    return fig, axs\n```\n\nChanges made:\n\n- For `xlim` and `ylim`, instead of iterating over the arrays with separate loops for rows and columns (`i` and `j`), we directly iterate over the"
    },
    {
        "original": "\ndef configure_scraper(self, scraper_config):\n    self.scraper = scraper_config['scraper']\n    self.endpoint = scraper_config['endpoint']\n",
        "rewrite": "```python\ndef configure_scraper(self, scraper_config):\n    self.scraper = scraper_config.get('scraper')\n    self.endpoint = scraper_config.get('endpoint')\n```"
    },
    {
        "original": "\ndef get_args(cls, dist, header=None):\n    for ep in dist.entry_points:\n        if ep.group in ('console_scripts', 'gui_scripts'):\n            yield (ep.name, ep.module_name, ep.func_name)\n",
        "rewrite": "```python\nimport distlib.entry_points\n\ndef get_args(cls, entry_points):\n    for ep in entry_points:\n        if ep.group in ('console_scripts', 'gui_scripts'):\n            yield (ep.name, getattr(ep, 'module_name', None), getattr(ep, 'func_name', None))\n```"
    },
    {
        "original": "\nclass DiscreteFactor:\n    def __init__(self, variables=None):\n       self.variables = variables \n    # assuming values is also given in __init__ method \n\n    def normalize(self,inplace=True):\n    \n       total_sum = self.values.sum()\n        \n       if(inplace):\n          self.values /= total_sum \n          return None \n       else:\n           factor_copy=self.__class__(variables=self.variables)\n           factor_copy.values=self.values/total_sum  \n           return factor_copy \n",
        "rewrite": "```python\nclass DiscreteFactor:\n    def __init__(self, variables=None, values=None):\n        if variables is None or values is None:\n            raise ValueError(\"Both 'variables' and 'values' must be provided\")\n        self.variables = variables\n        self.values = values\n\n    def normalize(self, inplace=True):\n        total_sum = self.values.sum()\n        \n        if inplace:\n            self.values /= total_sum\n            return None \n        else:\n            factor_copy = type(self)(variables=self.variables)\n            factor_copy.values = self.values / total_sum  \n            return factor_copy \n```"
    },
    {
        "original": "\ndef header(settings):\n    header_str = \"\\\\documentclass{article}\\n\"\n    header_str += \"\\\\usepackage{tikz}\\n\"\n    header_str += \"\\\\usetikzlibrary{arrows.meta, positioning, calc}\\n\"\n    header_str += \"\\\\tikzset{\\n\"\n    for key, value in settings.items():\n        header_str += f\"    {key}/.style={{{value}}},\\n\"\n    header_str += \"}\\n\"\n    return",
        "rewrite": "```python\ndef header(settings):\n    header_str = \"\\\\documentclass{article}\\n\\\\usepackage{tikz}\\n\\\\usetikzlibrary{arrows.meta, positioning, calc}\\n\\\\tikzset{\\n\"\n    for key, value in settings.items():\n        header_str += f\"{key}/.style={{#1={value}}}},\\n\"\n    if not settings:\n        return reader \u0627\u0644\u062d\u064aheader_str.rstrip(\",\") + \"}\\n\"\n    return(header_str.rstrip(\",\") + \"}\\n\")\n```"
    },
    {
        "original": "\nimport asyncio\nfrom indy.did import get_endpoint_for_did as indy_get_endpoint_for_did\nfrom typing import Optional\n\nasync def get_endpoint_for_did(wallet_handle: int, pool_handle: int, did: str) -> (str, Optional[str]):\n    return await indy_get_endpoint_for_did(pool_handle, wallet_handle, did)\n",
        "rewrite": "```python\nimport asyncio\nfrom typing import Optional\nfrom indy.did import get_endpoint_for_did as indy_get_endpoint_for_did\n\nasync def get_endpoint_for_did(wallet_handle: int, pool_handle: int, did: str) -> tuple[str, Optional[str]]:\n    return await indy_get_endpoint_for_did(pool_handle, wallet_handle, did)\n```"
    },
    {
        "original": "\nclass ProgrammingAssistant:\n    def _describe_me(self):\n        return (\"I'm a programming assistant\", \"that helps with coding challenges\", \"by providing Python solutions\", \"for various problems and tasks\", \"in a concise and efficient manner\")\n",
        "rewrite": "```python\nclass ProgrammingAssistant:\n    def describe_me(self):\n        return [\n            \"I'm a programming assistant\",\n            \"that helps with coding challenges\",\n            \"by providing Python solutions\",\n            \"for various problems and tasks\",\n            \"in a concise and efficient manner\"\n        ]\n```"
    },
    {
        "original": "\nimport matplotlib.pyplot as plt\n\nclass RelaxationHistoryPlotter:\n    def __init__(self, scf_cycles):\n        self.scf_cycles = scf_cycles\n\n    def plot(self, ax_list=None, fontsize=12, **kwargs):\n        if ax_list is None:\n            fig, ax = plt.subplots()\n        else:\n            fig = None\n            ax = ax_list[0]\n\n        for i in range(len(self.scf_cycles)):\n            data = self.scf",
        "rewrite": "```python\nimport matplotlib.pyplot as plt\n\nclass RelaxationHistoryPlotter:\n    def __init__(self, scf_cycles):\n        self.scf_cycles = scf_cycles\n\n    def plot(self, ax_list=None, fontsize=12, **kwargs):\n        if ax_list is None:\n            fig, ax = plt.subplots()\n        else:\n            fig = None\n            ax = ax_list[0]\n\n        for i in range(len(self.scf_cycles)):\n            data = self.scf_cycles[i]\n            x_data = data['x']\n            y_data1 = data['y1']\n            y_data2 = data"
    },
    {
        "original": "\n\nimport subprocess\ndef start(name, runas=None):\n    command = [\"launchctl\", \"start\"]\n    \n    if runas:\n        command.append(\"asu\")\n        command.append(runas)\n        \n    command.append(name)\n    \n    try:\n        subprocess.check_call(command)\n        return True\n    except subprocess.CalledProcessError as e:\n        print(f\"Failed to start {name}: {e}\")\n        return False\n\n",
        "rewrite": "```python\nimport subprocess\n\ndef start(name, runas=None):\n    command = [\"launchctl\", \"start\"]\n    \n    if runas:\n        command.extend([\"-u\", runas])\n        \n    command.append(name)\n    \n    try:\n        subprocess.check_call(command)\n        return True\n    except subprocess.CalledProcessError as e:\n        print(f\"Failed to start {name}: {e}\")\n        return False\n```"
    },
    {
        "original": "\ndef _get_unique_links(page_url, soup):\n    unique_links = set()\n    tags_toHref = [\"a\", \"link\"]\n    tags_toSrc = [\"img\", \"script\"]\n\n    for tag_type in tags_toHref:\n        for tag in soup.find_all(tag_type):\n            href = tag.get(\"href\")\n            if href:\n                unique_links.add(href)\n\n    for tag_type in tags_toSrc:\n        for tag in soup.find_all(tag_type):\n            src = tag",
        "rewrite": "```python\ndef _get_unique_links(page_url, soup):\n    unique_links = set()\n    tags_to_href = [\"a\", \"link\"]\n    tags_to_src = [\"img\", \"script\"]\n\n    for tag_type in tags_to_href:\n        for tag in soup.find_all(tag_type):\n            href = tag.get(\"href\")\n            if href and not href.startswith(\"#\"):\n                unique_links.add(href)\n\n    for tag_type in tags_to_src:\n        for tag in soup.find_all(tag_type):\n            src = tag.get(\"src\")\n            if src and not src.startswith(\"#\"):\n                unique_links.add(src)\n\n    return list"
    },
    {
        "original": "\nclass DeviceSpecs:\n    def __init__(self):\n        self.specs = {\n            '1Q': {},\n            '2Q': {}\n        }\n\n    def add_spec(self, qubit_type, qubit_id, spec_name, spec_value):\n        if qubit_type not in self.specs:\n            self.specs[qubit_type] = {}\n        if qubit_id not in self.specs[qubit_type]:\n            self.specs[qubit_type][qubit_id",
        "rewrite": "```python\nclass DeviceSpecs:\n    def __init__(self):\n        self.specs = {\n            '1Q': {},\n            '2Q': {}\n        }\n\n    def add_spec(self, qubit_type, qubit_id, spec_name, spec_value):\n        if qubit_type not in self.specs:\n            self.specs[qubit_type] = {}\n        \n        if qubit_id not in self.specs[qubit_type]:\n            self.specs[qubit_type][qubit_id] = {}\n\n        if spec_name not in self.specs[qubit_type][qubit_id]:\n            raise ValueError(f\"Spec"
    },
    {
        "original": "\nfrom collections import defaultdict\nfrom itertools import groupby\nfrom operator import itemgetter\n\ndef _filter_and_bucket_subtokens(subtoken_counts, min_count):\n    filtered_subtokens = [subtoken for subtoken, count in subtoken_counts.items() if count >= min_count]\n    sorted_subtokens = sorted(filtered_subtokens, key=len)\n    buckted_subtokens = [list(g) for k, g in groupby(sorted_subtokens, len)]\n    return buckted_subtokens",
        "rewrite": "```python\nfrom collections import defaultdict\nfrom itertools import groupby\nfrom operator import itemgetter\n\ndef filter_and_bucket_subtokens(subtoken_counts, min_count):\n    filtered_subtokens = [subtoken for subtoken, count in subtoken_counts.items() if count >= min_count]\n    sorted_by_length = sorted(filtered_subtokens, key=len)\n    buckted_subtokens = [list(g) for k, g in groupby(sorted_by_length, len)]\n    return buckted_subtokens\n```"
    },
    {
        "original": "\nimport matplotlib.pyplot as plt\n\ndef plot_densities(self, ax=None):\n    if ax is None:\n        fig, ax = plt.subplots()\n    else:\n        fig = ax.get_figure()\n    \n    # assuming self.densities is a list of density values\n    x_values = range(len(self.densities))\n    ax.plot(x_values, self.densities)\n    \n    return fig\n",
        "rewrite": "```python\nimport matplotlib.pyplot as plt\n\ndef plot_densities(self, ax=None):\n    if ax is None:\n        fig, ax = plt.subplots()\n    else:\n        fig = ax.get_figure()\n    \n    x_values = list(range(len(self.densities)))\n    ax.plot(x_values, self.densities)\n    \n    return fig, ax\n```"
    },
    {
        "original": "\nimport hashlib\n\ndef validate_file(fpath, md5_hash):\n    \"\"\"Validates a file against a MD5 hash\n\n    # Arguments\n        fpath: path to the file being validated\n        md5_hash: the MD5 hash being validated against\n\n    # Returns\n        Whether the file is valid\n    \"\"\"\n    with open(fpath, 'rb') as f:\n        data = f.read()\n        file_md5 = hashlib.md5(data).hexdigest()\n        return",
        "rewrite": "```python\nimport hashlib\n\ndef validate_file(fpath, md5_hash):\n    with open(fpath, 'rb') as f:\n        return hashlib.md5(f.read()).hexdigest() == md5_hash\n```"
    },
    {
        "original": "\ndef fgrad_y_psi(self, y, return_covar_chain=False):\n    # TO DO: implement the function to calculate the gradient of f w.r.t to y and psi\n    # The function should return a NxIx4 tensor of partial derivatives\n    pass\n",
        "rewrite": "```python\nimport torch\n\nclass BaseClass:\n    def fgrad_y_psi(self, y, return_covar_chain=False):\n        n_samples = y.shape[0]\n        num HID= n_samples # assuming the number of hidden units is equal to the number of samples\n        grad_f_wrt_y = torch.zeros(n_samples, num HID, 4)\n        \n        if return_covar_chain:\n            covar_chain = torch.zeros(n_samples, num HID)\n        \n        for i in range(n_samples):\n            for j in range(num HID):\n                # TO DO: implement the logic to calculate partial derivatives here\n               "
    },
    {
        "original": "\ndef RemoveClientLabels(self, client):\n    \"\"\"\n    Removes all labels for a given client object.\n\n    Args:\n      client: A VFSGRRClient record.\n    \"\"\"\n    \n    # Assuming that VFSGRRClient has an attribute 'labels' which is a list \n    # of labels associated with the client\n    if hasattr(client, 'labels'):\n        del client.labels[:]  # Clearing all labels\n    \n",
        "rewrite": "```python\ndef remove_client_labels(self, client):\n   \"\"\"\n    Removes all labels for a given client object.\n\n    Args:\n      client: A VFSGRRClient record.\n    \"\"\"\n    \n    if hasattr(client, 'labels'):\n        del client.labels[:]\n```"
    },
    {
        "original": "\nimport requests\nfrom github import Github\n\nclass GithubApi:\n    def __init__(self, token):\n        self.github = Github(token)\n\n    def get_starred_gists(self):\n        gists = self.github.get_user().get_starred()\n        return gists\n",
        "rewrite": "```python\nimport requests\nimport github\n\nclass GithubApi:\n    def __init__(self, token):\n        self.git_client = github.Github(token)\n\n    def get_starred_gists(self):\n        user = self.git_client.get_user()\n        gists = user.get_starred()\n        return gists\n```\n\nThen if you have pypi packages: Setup install a package using pip for base version it means keep the same condition on your current package from UNIQUE INFO GIVEN. for more useful things sometimes we are going to add the following:\n\n```cmd\npip install requests github3.py  # may be optional with dependencies change"
    },
    {
        "original": "\nclass Postgresql:\n    class PostgresException(Exception):\n       pass\n    \n    @staticmethod    \n    def postgres_version_to_int(pg_version):\n       parts = pg_VERSION.split('.')\n       if len(parts) not in [2,3]:\n           raise PG.PostgressException(f\"Invalid PostgreSQL version format:X,Y orX,Y,Zis accepted:{pg_VERSION}\")\n       try:\n           result = int(\"\".join(f\"{int(part):02}\" for part in parts))\n           return result\n       except",
        "rewrite": "```python\nclass Postgresql:\n    class PostgresException(Exception):\n        pass\n\n    @staticmethod\n    def postgres_version_to_int(pg_version):\n        parts = pg_version.split('.')\n        if len(parts) not in [2, 3]:\n            raise Postgresql.PostgresException(f\"Invalid PostgreSQL version format: X.Y or X.Y.Z is accepted: {pg_version}\")\n        try:\n            result = int(\"\".join(f\"{int(part):02}\" for part in parts))\n            return result\n        except ValueError as e:\n            raise Postgresql.PostgresException(str(e))\n```\n\nNote that I've also added a"
    },
    {
        "original": "\ndef analyze(self, text, tokenizer=str.split):\n    res = {}\n    tokens = tokenizer(text)\n    res['words'] = tokens\n    res['char_count'] = sum(len(word) for word in tokens)\n    res['word_count'] = len(tokens)\n    return res\n",
        "rewrite": "```python\ndef analyze(self, text, tokenizer=str.split):\n    res = {'words': [], 'char_count': 0, 'word_count': 0}\n    tokens = list(tokenizer(text))\n    res['words'] = tokens\n    res['char_count'] = sum(len(word) for word in tokens)\n    res['word_count'] = len(tokens)\n    return res\n```\n\nAlternatively, you could use a more concise version:\n\n```python\ndef analyze(self, text, tokenizer=str.split):\n    return {\n        'words': list(tokenizer(text)),\n        'char_count': sum(len(word) for word"
    },
    {
        "original": "\nPROTOCOL_VERSION = 1\n\nasync def set_protocol_version(protocol_version: int) -> None:\n    global PROTOCOL_VERSION\n    if protocol_version in [1, 2]:\n        PROTOCOL_VERSION = protocol_version\n    else:\n        raise ValueError(\"Invalid protocol version. Supported versions are 1 and 2.\")\n",
        "rewrite": "```python\nPROTOCOL_VERSION = 1\n\nasync def set_protocol_version(protocol_version: int) -> None:\n    global PROTOCOL_VERSION\n    if not isinstance(protocol_version, int):\n        raise TypeError(\"Protocol version must be an integer.\")\n    elif protocol_version not in [1, 2]:\n        raise ValueError(\"Invalid protocol version. Supported versions are 1 and 2.\")\n    else:\n        PROTOCOL_VERSION = protocol_version\n```"
    },
    {
        "original": "\nimport random\nimport string\n\nclass RandomLetterGenerator:\n    def random_letters(self, length=16):\n        return ''.join(random.choice(string.ascii_letters) for _ in range(length))\n",
        "rewrite": "```python\nimport random\nimport string\n\nclass RandomLetterGenerator:\n    def generate_random_letters(self, length=16):\n        return ''.join(random.choice(string.ascii_letters) for _ in range(length))\n```"
    },
    {
        "original": "\nclass WorksheetManager:\n    def __init__(self):\n        self.worksheets = {}\n\n    def add_worksheet(self, id, name):\n        self.worksheets[id] = {'name': name}\n\n    def get_worksheet(self, id_or_name):\n        if isinstance(id_or_name, int):\n            return self.worksheets.get(id_or_name)\n        else:\n            for worksheet in self.worksheets.values():\n                if worksheet['name'] == id_or_name:\n                    return worksheet\n",
        "rewrite": "```python\nclass WorksheetManager:\n    def __init__(self):\n        self.worksheets = {}\n\n    def add_worksheet(self, id, name):\n        if id in self.worksheets:\n            raise ValueError(\"Worksheet ID already exists\")\n        self.worksheets[id] = {'id': id, 'name': name}\n\n    def get_worksheet(self, id_or_name):\n        if isinstance(id_or_name, int) and id_or_name in self.worksheets:\n            return self.worksheets[id_or_name]\n        elif isinstance(id_or_name, str):\n            for worksheet in self.worksheets.values():\n                if worksheet['name'] =="
    },
    {
        "original": "\ndef languages(self, **kwargs):\n    # Initialize an empty dictionary to store language usages\n    language_usages = {}\n    \n    # Send request to GitLab API to get repository information\n    repo_info = self.git.getrepository(**.kwargs)\n    \n    # Iterate over each file in the repository\n    for file in repo_info['tree']:\n        # Check if file is not a directory\n        if 'blob' in file['type']:\n            # Get file extension (language)\n",
        "rewrite": "```python\ndef languages(self, **kwargs):\n    language_usages = {}\n    repo_info = self.git.getrepository(**kwargs)\n    \n    for file in repo_info['tree']:\n        if 'blob' in file['type']:\n            extension = file['name'].split('.')[-1]\n            language_usages[extension] = language_usages.get(extension, 0) + 1\n    \n    return {k: v for k, v in sorted(language_usages.items(), key=lambda x: x[1], reverse=True)}\n```"
    },
    {
        "original": "\nimport os\nimport platform\nfrom rdf_client_action import StatFSRequest\nfrom rdf_client_fs import UnixVolume\n\ndef StatFSFromClient(args):\n    if platform.system() == 'Windows':\n        raise RuntimeError(\"This function cannot be called on a Windows system.\")\n    \n    if not isinstance(args, StatFSRequest):\n        raise TypeError(\"Invalid argument type.\")\n\n    for path in args.paths:\n        yield UnixVolume(os.statvfs(path))\n",
        "rewrite": "```python\nimport os\nimport platform\nfrom rdf_client_action import StatFSRequest\nfrom rdf_client_fs import UnixVolume\n\ndef stat_fs_from_client(args: StatFSRequest) -> iter[UnixVolume]:\n    if platform.system() == 'Windows':\n        raise RuntimeError(\"This function cannot be called on a Windows system.\")\n    \n    if not isinstance(args, StatFSRequest):\n        raise TypeError(\"Invalid argument type.\")\n\n    for path in args.paths:\n        yield UnixVolume(os.statvfs(path))\n```"
    },
    {
        "original": "\ndef enumerate_tokens(sid=None, session_id=None, privs=None):\n    tokens = []\n    import wmi\n    c = wmi.WMI()\n    \n    if sid:\n        processes = c.Win32_Process(['ProcessId', 'Token'], assoc_class='Win32_LogonSession', resultclass=\"Win32_Session\")[0].associators()\n        for process in processes:\n            if process.SessionId == int(session_id):\n                try:\n                    token = process.ExecutablePath +",
        "rewrite": "```python\nimport wmi\n\ndef enumerate_tokens(sid=None, session_id=None, privs=None):\n    \"\"\"\n    Enumerate tokens for a given session ID.\n\n    Args:\n        sid (str): The SID of the process to enumerate tokens for.\n        session_id (int): The ID of the session to enumerate tokens for.\n        privs (list): A list of privileges to filter by.\n\n    Returns:\n        list: A list of dictionaries containing token information.\n    \"\"\"\n\n    c = wmi.WMI()\n\n    if sid and session_id:\n        processes = c.Win32_Process(['ProcessId', 'Token'], assoc_class"
    },
    {
        "original": "\nimport libvirt \n\ndef delete_snapshots(name, names, **=\"qemu:///system\", username=None, password=None):\n     conn = libvirt.openReadWrite(connection) \n     if conn is None:\n          raise Exception('Failed to open connection to qemu:///system')\n    \n     domain = conn.lookupByName(name)\n     if not domain:\n          raise Exception(f\"VM {name} does not exist\")\n  \n     if 'all' in [n.lower() for n in names]:\n",
        "rewrite": "```python\nimport libvirt\n\ndef delete_snapshots(name, names=None, **kwargs):\n    connection = kwargs.pop('connection', 'qemu:///system')\n    username = kwargs.pop('username', None)\n    password = kwargs.pop('password', None)\n\n    conn = libvirt.openReadOnly(connection)\n    if conn is None:\n        raise Exception(f'Failed to open connection to {connection}')\n\n    domain = conn.lookupByName(name)\n    if not domain:\n        raise Exception(f'VM {name} does not exist')\n\n    for n in [n.lower() for n in names or []]:\n        if n == 'all"
    },
    {
        "original": "\ndef checkPidFile(pidfile):\n    try:\n        with open(pidfile) as f:\n            pid = int(f.read().strip())\n            if pid <= 0:\n                raise ValueError(\"Invalid PID\")\n            return pid\n    except (OSError, IOError, ValueError):\n        raise Exception(\"Failed to read PID file\")\n",
        "rewrite": "```python\ndef check_pid_file(pidfile):\n    try:\n        with open(pidfile, 'r') as f:\n            pid = int(f.read().strip())\n            if pid <= 0:\n                raise ValueError(\"Invalid PID\")\n            return pid\n    except (OSError, IOError, ValueError) as e:\n        raise Exception(f\"Failed to read PID file: {e}\")\n```"
    },
    {
        "original": "\n\ndef info(name: str) -> dict:\n    # MY ASSUMPTION IS THAT WE HAVE A PRE-EXISTING DATA STRUCTURE TO STORE GROUP INFORMATION\n    groups = {\n        \"foo\": {\"description\": \"This is foo group\", \"members\": [\"Alice\", \"Bob\", \"Charlie\"]},\n        \"bar\": {\"description\": \"This is bar group\", \"members\": [\"David\", \"Eve\"]}\n        # ADD MORE GROUPS AS NEEDED\n",
        "rewrite": "```python\ndef get_group_info(name: str) -> dict:\n    groups = {\n        \"foo\": {\"description\": \"This is foo group\", \"members\": [\"Alice\", \"Bob\", \"Charlie\"]},\n        \"bar\": {\"description\": \"This is bar group\", \"members\": [\"David\", \"Eve\"]}\n    }\n    \n    return groups.get(name, {})\n\ndef add_group(name: str, description: str, members: list):\n    groups = get_groups()\n    \n    if name not in groups:\n        groups[name] = {\"description\": description, \"members\": members}\n        \ndef update_group_info(name"
    }
]