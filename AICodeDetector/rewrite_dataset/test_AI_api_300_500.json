[
    {
        "original": "\ndef _get_unique_links(page_url, soup):\n    unique_links = set()\n    tags_toHref = [\"a\", \"link\"]\n    tags_toSrc = [\"img\", \"script\"]\n\n    for tag_type in tags_toHref:\n        for tag in soup.find_all(tag_type):\n            href = tag.get(\"href\")\n            if href:\n                unique_links.add(href)\n\n    for tag_type in tags_toSrc:\n        for tag in soup.find_all(tag_type):\n            src = tag",
        "rewrite": "Here is the revised code:\n\n```\ndef _get_unique_links(page_url, soup):\n    unique_links = set()\n    tags_toHref = [\"a\", \"link\"]\n    tags_toSrc = [\"img\", \"script\"]\n\n    for tag_type in tags_toHref + tags_toSrc:\n        for tag in soup.find_all(tag_type):\n            if tag_type in tags_toHref:\n                href = tag.get(\"href\")\n                if href:\n                    unique_links.add(href)\n            else:\n                src = tag.get(\"src\")\n                if src:\n                    unique_links.add(src)\n\n    return unique_links\n```"
    },
    {
        "original": "\nclass File:\n    def __init__(self, file_name, file_mode):\n        self.file_name = file_name\n        self.file_mode = file_mode\n        self.file_pointer = 0\n        self.file = open(file_name, file_mode)\n\n    def Seek(self, offset, whence=os.SEEK_SET):\n        if whence == os.SEEK_SET:\n            self.file_pointer = offset\n        elif whence == os.SEEK_CUR:\n            self.file_pointer += offset\n        elif",
        "rewrite": "Here is the revised code:\n\n```\nimport os\n\nclass File:\n    def __init__(self, file_name, file_mode):\n        self.file_name = file_name\n        self.file_mode = file_mode\n        self.file_pointer = 0\n        self.file = open(file_name, file_mode)\n\n    def seek(self, offset, whence=os.SEEK_SET):\n        if whence == os.SEEK_SET:\n            self.file.seek(offset)\n            self\tfile_pointer\t= offset\n        elif whence == os.SEEK_CUR:\n            current_position=self.tell()\n            new_position=current_position +\toffset \n           \tself.seek(new_position)\n        "
    },
    {
        "original": "\nimport matplotlib.pyplot as plt\n\nclass RelaxationHistoryPlotter:\n    def __init__(self, scf_cycles):\n        self.scf_cycles = scf_cycles\n\n    def plot(self, ax_list=None, fontsize=12, **kwargs):\n        if ax_list is None:\n            fig, ax = plt.subplots()\n        else:\n            fig = None\n            ax = ax_list[0]\n\n        for i in range(len(self.scf_cycles)):\n            data = self.scf",
        "rewrite": "Here is the revised code:\n\n```\nimport matplotlib.pyplot as plt\n\nclass RelaxationHistoryPlotter:\n    def __init__(self, scf_cycles):\n        self.scf_cycles = scf_cycles\n\n    def plot(self, ax_list=None, fontsize=12, **.kwargs):\n        if ax_list is None:\n            fig, ax = plt.subplots()\n        else:\n            fig = None\n            ax = ax_list[0]\n\n        for i in range(len(self.scf_cycles)):\n            data = [cycle[i] for cycle in self.scf_cycles]\n            label_name = f\"Iter {i+1}\"\n           "
    },
    {
        "original": "\nimport requests\nfrom github import Github\n\nclass GithubApi:\n    def __init__(self, token):\n        self.github = Github(token)\n\n    def get_starred_gists(self):\n        gists = self.github.get_user().get_starred()\n        return gists\n",
        "rewrite": "Here is the revised code:\n\n```\nimport requests\nfrom github import Github\n\nclass GithubApi:\n    def __init__(self, token):\n        self.github = Github(token)\n        self.user = self.github.get_user()\n\n    def get_starred_gists(self):\n        return self.user.get_starred_gists()\n```"
    },
    {
        "original": "\nimport praw\n\ndef from_id(reddit_session, subreddit_id):\n    reddit = praw.Reddit(client_id='your_client_id', \n                         client_secret='your_client_secret', \n                         user_agent='your_user_agent')\n    reddit.config.store(reddit_session)\n    submission = reddit.submission(id=subreddit_id)\n    return submission\n",
        "rewrite": "```\nimport praw\n\ndef from_id(reddit_session, subreddit_id):\n    reddit = praw.Reddit(client_id=\"your_client_id\", \n                         client_secret=\"your_client_secret\", \n                         user_agent=\"your_user_agent\")\n    reddit.validate_on_submit = True\n    return reddit.submission(id=subreddit_id)\n```"
    },
    {
        "original": "\ndef _query_select_options(self, query, select_columns=None):\n    if select_columns:\n        query = query.with_entities(*mj.fromselectAll([getattr(self.__class__, column) for column in select_columns]))\n    return query\n",
        "rewrite": "Here is the revised code:\n\n```\ndef _query_select_options(self, query, select_columns=None):\n    if select_columns:\n        query = query.with_entities(*(getattr(self.__class__, column) for column in select_columns))\n    return query\n```"
    },
    {
        "original": "\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef align_subplots(N, M, xlim=None, ylim=None):\n    fig, axs = plt.subplots(N, M)\n    \n    if xlim is not None:\n        for i in range(N):\n            for j in range(M):\n                axs[i,j].set_xlim(xlim)\n                \n    if ylim is not None:\n        for i in range(N):\n            for j in range(M):\n                axs[i,j].set_ylim(",
        "rewrite": "Here is the revised code:\n\n```\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef align_subplots(N, M, xlim=None, ylim=None):\n    fig, axs = plt.subplots(N, M)\n    \n    for i in range(N):\n        for j in range(M):\n            if xlim is not None:\n                axs[i,j].set_xlim(xlim)\n            if ylim is not None:\n                axs[i,j].set_ylim(ylim)\n```"
    },
    {
        "original": "\ndef fgrad_y_psi(self, y, return_covar_chain=False):\n    # TO DO: implement the function to calculate the gradient of f w.r.t to y and psi\n    # The function should return a NxIx4 tensor of partial derivatives\n    pass\n",
        "rewrite": "```\ndef fgrad_y_psi(self, y, return_covar_chain=False):\n    N, I = y.shape\n    psi_dim = self.psi_dim\n    grad = torch.zeros(N, I, psi_dim)\n\n    for n in range(N):\n        for i in range(I):\n            y_ni = y[n, i]\n            psi_ni = self.psi(y_ni)\n            f_ni = self.f(y_ni, psi_ni)\n            grad_f_y_ni = torch.autograd.grad(f_ni, y_ni, retain_graph=True)[0]\n            grad_f_psi_ni"
    },
    {
        "original": "\nclass WorksheetManager:\n    def __init__(self):\n        self.worksheets = {}\n\n    def add_worksheet(self, id, name):\n        self.worksheets[id] = {'name': name}\n\n    def get_worksheet(self, id_or_name):\n        if isinstance(id_or_name, int):\n            return self.worksheets.get(id_or_name)\n        else:\n            for worksheet in self.worksheets.values():\n                if worksheet['name'] == id_or_name:\n                    return worksheet\n",
        "rewrite": "Here is the revised code:\n\n```\nclass WorksheetManager:\n    def __init__(self):\n        self.worksheets = {}\n\n    def add_worksheet(self, id, name):\n        self.worksheets[id] = {'id': id, 'name': name}\n\n    def get_worksheet(self, id_or_name):\n        if isinstance(id_or_name, int):\n            return self.worksheets.get(id_or_name)\n        else:\n            return next((ws for ws in self.worksheets.values() if ws['name'] == id_or_name), None)\n```"
    },
    {
        "original": "\ndef languages(self, **kwargs):\n    # Initialize an empty dictionary to store language usages\n    language_usages = {}\n    \n    # Send request to GitLab API to get repository information\n    repo_info = self.git.getrepository(**.kwargs)\n    \n    # Iterate over each file in the repository\n    for file in repo_info['tree']:\n        # Check if file is not a directory\n        if 'blob' in file['type']:\n            # Get file extension (language)\n",
        "rewrite": "Here's the revised code:\n\n```\ndef languages(self, **kwargs):\n    language_usages = {}\n    repo_info = self.git.getrepository(**.kwargs)\n    \n    for file in repo_info['tree']:\n        if 'blob' in file['type']:\n            _, ext = os.path.splitext(file['path'])\n            ext = ext[1:]  # remove dot at the beginning\n            \n            if ext not in language_usages:\n                language_usages[ext] = 0\n            \n            language_usages[ext] += 1\n    \n    return language_usages\n```"
    },
    {
        "original": "\nimport hashlib\n\ndef HA2(credentials, request, algorithm, entityBody=None):\n    method = request['method']\n    digestURI = request['digestURI']\n    if algorithm == 'auth' or algorithm == '':\n        A2 = f\"{method}:{digestURI}\"\n    elif algorithm == 'auth-int':\n        A2 = f\"{method}:{digestURI}:{hashlib.md5(entityBody.encode()).hexdigest()}\"\n    return hashlib.md5(A2.encode()).hexdigest()\n",
        "rewrite": "Here is the revised code:\n\n```\nimport hashlib\n\ndef HA2(credentials, request, algorithm, entityBody=None):\n    method = request['method']\n    digestURI = request['digestURI']\n    \n    if algorithm in ['auth', '']:\n        A2 = f\"{method}:{digestURI}\"\n    elif algorithm == 'auth-int':\n        A2 = f\"{method}:{digestURI}:{hashlib.md5(entityBody.encode()).hexdigest()}\"\n    \n    return hashlib.md5(A2.encode()).hexdigest()\n```"
    },
    {
        "original": "\ndef get_args(cls, dist, header=None):\n    for ep in dist.entry_points:\n        if ep.group in ('console_scripts', 'gui_scripts'):\n            yield (ep.name, ep.module_name, ep.func_name)\n",
        "rewrite": "Here is the revised code:\n\n```\ndef get_args(cls, dist, header=None):\n    return [(ep.name, ep.module_name, ep.func_name) \n            for ep in dist.entry_points \n            if ep.group in ('console_scripts', 'gui_scripts')]\n```"
    },
    {
        "original": "\nimport matplotlib.pyplot as plt\n\ndef plot_densities(self, ax=None):\n    if ax is None:\n        fig, ax = plt.subplots()\n    else:\n        fig = ax.get_figure()\n    \n    # assuming self.densities is a list of density values\n    x_values = range(len(self.densities))\n    ax.plot(x_values, self.densities)\n    \n    return fig\n",
        "rewrite": "Here is the revised code:\n\n```\nimport matplotlib.pyplot as plt\n\ndef plot_densities(self, ax=None):\n    fig, ax = plt.subplots() if ax is None else (ax.get_figure(), ax)\n    ax.plot(range(len(self.densities)), self.densities)\n    return fig\n```"
    },
    {
        "original": "\nPROTOCOL_VERSION = 1\n\nasync def set_protocol_version(protocol_version: int) -> None:\n    global PROTOCOL_VERSION\n    if protocol_version in [1, 2]:\n        PROTOCOL_VERSION = protocol_version\n    else:\n        raise ValueError(\"Invalid protocol version. Supported versions are 1 and 2.\")\n",
        "rewrite": "Here is the revised code:\n\n```\nPROTOCOL_VERSION = 1\n\nasync def set_protocol_version(protocol_version: int) -> None:\n    global PROTOCOL_VERSION\n    if protocol_version not in (1, 2):\n        raise ValueError(\"Invalid protocol version. Supported versions are 1 and 2.\")\n    PROTOCOL_VERSION = protocol_version\n```"
    },
    {
        "original": "\ndef update_grads(self, X, dL_dW, a, b):\n    dW_da = b * (1 - X**a)**(b - 1) * X**a * np.log(X)\n    dW_db = - (1 - X**a)**b * np.log(1 - X**a)\n    dL_da = dL_dW * dW_da\n    dL_db = dL_dW * dW_db\n",
        "rewrite": "```\ndef update_grads(self, X, dL_dW, a, b):\n    da_term = (1 - X**a)**(b - 1) * X**a * np.log(X)\n    db_term = -(1 - X**a)**b * np.log(1 - X**a)\n    \n    self.da += (dL_dW * b) @ da_term\n    self.db += (dL_dW) @ db_term\n```"
    },
    {
        "original": "\nimport pychromecast\n\ndef get_device_status(host, services=None, zconf=None):\n    \"\"\"\n    :param host: Hostname or ip to fetch status from\n    :type host: str\n    :return: The device status as a named tuple.\n    :rtype: pychromecast.dial.DeviceStatus or None\n    \"\"\"\n    casts, browser = pychromecast.get_listed_chromecasts(friendly_names=[host], services=services, zerosconf=zconf",
        "rewrite": "Here is the revised code:\n\n```\nimport pychromecast\n\ndef get_device_status(host, services=None, zconf=None):\n    casts, browser = pychromecast.get_listed_chromecasts(friendly_names=[host], services=services, zerosconf=zconf)\n    if casts:\n        return casts[0].device\n    else:\n        return None\n```"
    },
    {
        "original": "\nclass DiscreteFactor:\n    def __init__(self, variables=None):\n       self.variables = variables \n    # assuming values is also given in __init__ method \n\n    def normalize(self,inplace=True):\n    \n       total_sum = self.values.sum()\n        \n       if(inplace):\n          self.values /= total_sum \n          return None \n       else:\n           factor_copy=self.__class__(variables=self.variables)\n           factor_copy.values=self.values/total_sum  \n           return factor_copy \n",
        "rewrite": "Here is the revised code:\n\n```\nclass DiscreteFactor:\n    def __init__(self, variables, values):\n        self.variables = variables\n        self.values = values\n\n    def normalize(self, inplace=True):\n        total_sum = self.values.sum()\n        if inplace:\n            self.values /= total_sum\n            return None\n        else:\n            factor_copy = self.__class__(variables=self.variables, values=self.values/total_sum)\n            return factor_copy\n```"
    },
    {
        "original": "\ndef _is_process_filtered(self, process, key=None):\n    if key is None:\n        return False\n    if key not in process:\n        return False\n    if not self.filter:\n        return False\n    if any(word in process[key] for word in self.filter):\n        return True\n    return False\n",
        "rewrite": "Here is the revised code:\n\n```\ndef _is_process_filtered(self, process, key=None):\n    if key is None or key not in process or not self.filter:\n        return False\n    return any(word in process[key] for word in self.filter)\n```"
    },
    {
        "original": "\ndef my_record_vars(context, data):\n    context.vars = {}\n    for key, value in data.items():\n        context.vars[key] = value\n",
        "rewrite": "```\ndef my_record_vars(context, data):\n    context.vars = {**: v for k, v in data.items()}\n```"
    },
    {
        "original": "\ndef _update_triangles(self, triangles_list):\n    clusters = []\n    for triangle in triangles_list:\n        cluster = {'variables': triangle, 'type': 'triangle'}\n        clusters.append(cluster)\n    return clusters\n",
        "rewrite": "```\ndef _update_triangles(self, triangles_list):\n    return [{'variables': triangle, 'type': 'triangle'} for triangle in triangles_list]\n```"
    },
    {
        "original": "\nimport random\nimport string\n\nclass RandomLetterGenerator:\n    def random_letters(self, length=16):\n        return ''.join(random.choice(string.ascii_letters) for _ in range(length))\n",
        "rewrite": "```\nimport random\nimport string\n\nclass RandomLetterGenerator:\n    def __init__(self):\n        pass\n    \n    @staticmethod\n    def generate_random_letters(length=16):\n        return ''.join(random.choice(string.ascii_letters) for _ in range(length))\n```"
    },
    {
        "original": "\nclass Padding:\n    def __init__(self, paddings):\n        self.paddings = paddings\n\n    def padding(self):\n        if len(set(self.paddings)) == 1:\n            return self.paddings[0]\n        else:\n            raise ValueError(\"If different padding algorithms are used for different dimensions.\")\n",
        "rewrite": "Here is the revised code:\n\n```\nclass Padding:\n    def __init__(self, *paddings):\n        if len(set(paddings)) == 1:\n            self.padding = paddings[0]\n        else:\n            raise ValueError(\"If different padding algorithms are used for different dimensions.\")\n```"
    },
    {
        "original": "\nimport pandas as pd\nimport numpy as np\n\ndef try_convert_to_date(data):\n    try:\n        pd.to_datetime(data, unit='s', errors='coerce')\n        return True\n    except ValueError:\n        try:\n            pd.to_datetime(data, format='%Y-%m-%dT%H:%M:%SZ', errors='coerce')\n            return True\n        except ValueError:\n            return False\n",
        "rewrite": "```\nimport pandas as pd\n\ndef try_convert_to_date(data):\n    return (pd.to_datetime(data, unit='s', errors='coerce').notnull().all() or \n            pd.to_datetime(data, format='%Y-%m-%dT%H:%M:%SZ', errors='coerce').notnull().all())\n```"
    },
    {
        "original": "\nclass ProgrammingAssistant:\n    def _describe_me(self):\n        return (\"I'm a programming assistant\", \"that helps with coding challenges\", \"by providing Python solutions\", \"for various problems and tasks\", \"in a concise and efficient manner\")\n",
        "rewrite": "class ProgrammingAssistant:\n    def describe_me(self):\n        return \"\\n\".join([\"I'm a programming assistant\",\n                          \"that helps with coding challenges\",\n                          \"by providing Python solutions\",\n                          \"for various problems and tasks\",\n                          \"in a concise and efficient manner\"])"
    },
    {
        "original": "\nclass OpenStackAPI:\n    def _make_request(self, url, headers, params=None):\n        import requests\n        try:\n            if params is not None:\n                response = requests.get(url, headers=headers, params=params)\n            else:\n                response = requests.get(url, headers=headers)\n            response.raise_for_status()\n        except requests.exceptions.HTTPError as errh:\n            if errh.response.status_code == 401:\n                raise UnauthorizedException(\"Unauthorized access\")\n            elif errh",
        "rewrite": "Here is the revised code:\n\n```\nimport requests\nfrom requests.exceptions import HTTPError\n\nclass OpenStackAPI:\n    def _make_request(self, url, headers, params=None):\n        try:\n            if params is not None:\n                response = requests.get(url, headers=headers, params=params)\n            else:\n                response = requests.get(url, headers=headers)\n            response.raise_for_status()\n        except HTTPError as errh:\n            if errh.response.status_code == 401:\n                raise UnauthorizedException(\"Unauthorized access\")\n```"
    },
    {
        "original": "\nimport libvirt \n\ndef delete_snapshots(name, names, **=\"qemu:///system\", username=None, password=None):\n     conn = libvirt.openReadWrite(connection) \n     if conn is None:\n          raise Exception('Failed to open connection to qemu:///system')\n    \n     domain = conn.lookupByName(name)\n     if not domain:\n          raise Exception(f\"VM {name} does not exist\")\n  \n     if 'all' in [n.lower() for n in names]:\n",
        "rewrite": "Here is the revised code:\n\n```\nimport libvirt\n\ndef delete_snapshots(name, names, connection=\"qemu:///system\", username=None, password=None):\n    conn = libvirt.openReadOnly(connection) if username is None else libvirt.openReadOnly(connection, readonly=True)\n    if username and password:\n        conn.login(libvirt.VIR_CRED_AUTHORIZED | libvert.VIR_CRED_NO_CREDENTIALS, [username], [password])\n    \n    if conn is None:\n        raise Exception('Failed to open connection to qemu:///system')\n    \n    domain = conn.lookupByName(name)\n    if not domain:\n        raise Exception"
    },
    {
        "original": "\nimport hmac\nimport hashlib\n\ndef validate(body, signature):\n    channel_secret = 'YOUR_CHANNEL_SECRET'\n    body_bytes = body.encode('utf-8')\n    signature_bytes = signature.encode('utf-8')\n    expected_signature = hmac.new(channel_secret.encode('utf-8'), body_bytes, hashlib.sha256).digest()\n    if hmac.compare_digest(expected_signature, signature_bytes):\n        return True\n    else:\n        return False\n",
        "rewrite": "Here is the revised code:\n\n```\nimport hmac\nimport hashlib\n\nchannel_secret = 'YOUR_CHANNEL_SECRET'\n\ndef validate(body, signature):\n    body_bytes = body.encode('utf-8')\n    signature_bytes = signature.encode('utf-8')\n    expected_signature = hmac.new(channel_secret.encode('utf-8'), body_bytes, hashlib.sha256).digest()\n    return hmac.compare_digest(expected_signature, signature_bytes)\n```"
    },
    {
        "original": "\nimport asyncio\nfrom indy.did import get_endpoint_for_did as indy_get_endpoint_for_did\nfrom typing import Optional\n\nasync def get_endpoint_for_did(wallet_handle: int, pool_handle: int, did: str) -> (str, Optional[str]):\n    return await indy_get_endpoint_for_did(pool_handle, wallet_handle, did)\n",
        "rewrite": "Here is the revised code:\n\n```\nimport asyncio\nfrom indy.did import get_endpoint_for_did as indy_get_endpoint_for_did\nfrom typing import Optional\n\nasync def get_endpoint_for_did(wallet_handle: int, pool_handle: int, did: str) -> tuple[str, Optional[str]]:\n    return await indy_get_endpoint_for_did(wallet_handle, pool_handle, did)\n```"
    },
    {
        "original": "\ndef analyze(self, text, tokenizer=str.split):\n    res = {}\n    tokens = tokenizer(text)\n    res['words'] = tokens\n    res['char_count'] = sum(len(word) for word in tokens)\n    res['word_count'] = len(tokens)\n    return res\n",
        "rewrite": "Here is the revised code:\n\n```\ndef analyze(self, text, tokenizer=str.split):\n    return {\n        'words': tokens := tokenizer(text),\n        'char_count': sum(len(word) for word in tokens),\n        'word_count': len(tokens)\n    }\n```"
    },
    {
        "original": "\ndef ramping_values(period=360):\n    i = 0\n    while True:\n        yield i / period if i < period / 2 else (period - i) / period if i < period else (i - period * ((i // period) + 1)) / period + ((i // period) % 2)\n        i += 1 if i < period * ((i // period) + 1) else -(i - period * ((i // period",
        "rewrite": "Here is the revised code:\n\n```\ndef ramping_values(period=360):\n    i = 0\n    while True:\n        yield min(i, min(period - i, (i % (period * 2)) if (i // (period * 2)) % 2 else (period - (i % (period * 2)))) ) / float(period)\n        i += 1 \n```"
    },
    {
        "original": "\nimport math\nfrom typing import Union\n\nclass Point2:\n    def __init__(self, x: int, y: int):\n        self.x = x\n        self.y = y\n\n    def distance_to_point2(self, p2: \"Point2\") -> Union[int, float]:\n        return math.sqrt((self.x - p2.x) ** 2 + (self.y - p2.y) ** 2)\n",
        "rewrite": "```\nimport math\nfrom typing import Union\n\nclass Point:\n    def __init__(self, x: int, y: int):\n        self.x = x\n        self.y = y\n\n    def distance_to(self, other: \"Point\") -> Union[int, float]:\n        return math.hypot(self.x - other.x, self.y - other.y)\n```"
    },
    {
        "original": "\n\ndef info(name: str) -> dict:\n    # MY ASSUMPTION IS THAT WE HAVE A PRE-EXISTING DATA STRUCTURE TO STORE GROUP INFORMATION\n    groups = {\n        \"foo\": {\"description\": \"This is foo group\", \"members\": [\"Alice\", \"Bob\", \"Charlie\"]},\n        \"bar\": {\"description\": \"This is bar group\", \"members\": [\"David\", \"Eve\"]}\n        # ADD MORE GROUPS AS NEEDED\n",
        "rewrite": "Here is the revised code:\n\n```\ndef info(name: str) -> dict:\n    groups = {\n        \"foo\": {\"description\": \"This is foo group\", \"members\": [\"Alice\", \"Bob\", \"Charlie\"]},\n        \"bar\": {\"description\": \"This is bar group\", \"members\": [\"David\", \"Eve\"]},\n        #\"baz\": {...},  # add more groups as needed\n    }\n    return groups.get(name, {})\n```"
    },
    {
        "original": "\ndef configure_scraper(self, scraper_config):\n    self.scraper = scraper_config['scraper']\n    self.endpoint = scraper_config['endpoint']\n",
        "rewrite": "```\ndef configure_scraper(self, scraper_config: dict) -> None:\n    self.scraper = scraper_config.get('scraper')\n    self.endpoint = scraper_config.get('endpoint')\n```"
    },
    {
        "original": "\nimport boto3\nimport base64\n\ndef encrypt(key_id, plaintext, encryption_context=None, grant_tokens=None, region=None, key=None, keyid=None, profile=None):\n    kms = boto3.client('kms', region_name=region)\n    response = kms.encrypt(\n        KeyId=key_id,\n        Plaintext=plaintext.encode('utf-8'),\n        EncryptionContext=encryption_context\n    )\n    return base64.b64encode(response['CiphertextBlob']).decode('",
        "rewrite": "Here is the revised code:\n\n```\nimport boto3\nimport base64\n\ndef encrypt(key_id: str, plaintext: str, encryption_context: dict = None, grant_tokens: list = None, region: str = None) -> str:\n    session = boto3.Session(region_name=region)\n    kms = session.client('kms')\n    response = kms.encrypt(\n        KeyId=key_id,\n        Plaintext=plaintext.encode('utf-8'),\n        EncryptionContext=encryption_context\n    )\n    return base64.b64encode(response['CiphertextBlob']).decode()\n```"
    },
    {
        "original": "\ndef zunionstore(self, dest, keys, aggregate=None):\n    if aggregate is None:\n        aggregate = 'SUM'\n    temp = {}\n    for key in keys:\n        for member, score in self.redis.zscan_iter(key):\n            if member not in temp:\n                temp[member] = 0\n            if aggregate.upper() == 'SUM':\n                temp[member] += float(score)\n            elif aggregate.upper() == 'MIN':\n                temp[member] = min",
        "rewrite": "Here is the revised code:\n\n```\ndef zunionstore(self, dest, keys, aggregate=None):\n    if aggregate is None:\n        aggregate = 'SUM'\n    temp = {}\n    for key in keys:\n        for member, score in self.redis.zscan_iter(key):\n            if member not in temp:\n                temp[member] = 0\n            if aggregate.upper() == 'SUM':\n                temp[member] += float(score)\n            elif aggregate.upper() == 'MIN':\n                temp[member] = min(temp[member], float(score))\n            elif aggregate.upper() == 'MAX':\n                temp[member] ="
    },
    {
        "original": "\nclass DeviceSpecs:\n    def __init__(self):\n        self.specs = {\n            '1Q': {},\n            '2Q': {}\n        }\n\n    def add_spec(self, qubit_type, qubit_id, spec_name, spec_value):\n        if qubit_type not in self.specs:\n            self.specs[qubit_type] = {}\n        if qubit_id not in self.specs[qubit_type]:\n            self.specs[qubit_type][qubit_id",
        "rewrite": "Here is the revised code:\n\n```\nclass DeviceSpecs:\n    def __init__(self):\n        self.specs = {\n            '1Q': {},\n            '2Q': {}\n        }\n\n    def add_spec(self, qubit_type, qubit_id, spec_name, spec_value):\n        if qubit_type not in self.specs:\n            self.specs[qubit_type] = {}\n        if qubit_id not in self.specs[qubit_type]:\n            self.specs[qubit_type][qubit_id] = {}\n        self.specs[qubit_type][qubit_id][spec_name] = spec_value\n"
    },
    {
        "original": "\ndef user_exists_in_group(user_name, group_name, region=None, key=None, keyid=None, profile=None):\n    import boto3\n    iam = boto3.client('iam', region_name=region, aws_access_key_id=key, aws_secret_access_key=keyid, profile_name=profile)\n    try:\n        response = iam.get_group(GroupName=group_name)\n        for user in response['Users']:\n            if user['UserName'] == user_name:\n                return True\n",
        "rewrite": "Here is the revised code:\n\n```\nimport boto3\n\ndef user_exists_in_group(user_name, group_name, region=None, key=None, keyid=None, profile=None):\n    iam = boto3.client('iam', region_name=region, aws_access_key_id=key, aws_secret_access_key=keyid, profile_name=profile)\n    try:\n        response = iam.get_group(GroupName=group_name)\n        return any(user['UserName'] == user_name for user in response['Users'])\n```"
    },
    {
        "original": "\ndef checkPidFile(pidfile):\n    try:\n        with open(pidfile) as f:\n            pid = int(f.read().strip())\n            if pid <= 0:\n                raise ValueError(\"Invalid PID\")\n            return pid\n    except (OSError, IOError, ValueError):\n        raise Exception(\"Failed to read PID file\")\n",
        "rewrite": "```\ndef checkPidFile(pidfile):\n    try:\n        with open(pidfile) as f:\n            pid = int(f.read().strip())\n            if pid <= 0:\n                raise ValueError(\"Invalid PID\")\n            return pid\n    except (OSError, IOError, ValueError) as e:\n        raise Exception(\"Failed to read PID file\") from e\n```"
    },
    {
        "original": "\nimport hashlib\n\ndef validate_file(fpath, md5_hash):\n    \"\"\"Validates a file against a MD5 hash\n\n    # Arguments\n        fpath: path to the file being validated\n        md5_hash: the MD5 hash being validated against\n\n    # Returns\n        Whether the file is valid\n    \"\"\"\n    with open(fpath, 'rb') as f:\n        data = f.read()\n        file_md5 = hashlib.md5(data).hexdigest()\n        return",
        "rewrite": "Here is the revised code:\n\n```\nimport hashlib\n\ndef validate_file(fpath, md5_hash):\n    with open(fpath, 'rb') as f:\n        data = f.read()\n        file_md5 = hashlib.md5(data).hexdigest()\n        return file_md5 == md5_hash\n```"
    },
    {
        "original": "\ndef RemoveClientLabels(self, client):\n    \"\"\"\n    Removes all labels for a given client object.\n\n    Args:\n      client: A VFSGRRClient record.\n    \"\"\"\n    \n    # Assuming that VFSGRRClient has an attribute 'labels' which is a list \n    # of labels associated with the client\n    if hasattr(client, 'labels'):\n        del client.labels[:]  # Clearing all labels\n    \n",
        "rewrite": "```\ndef remove_client_labels(self, client):\n    if hasattr(client, 'labels'):\n        client.labels.clear()\n```"
    },
    {
        "original": "\nimport os\nimport platform\nfrom rdf_client_action import StatFSRequest\nfrom rdf_client_fs import UnixVolume\n\ndef StatFSFromClient(args):\n    if platform.system() == 'Windows':\n        raise RuntimeError(\"This function cannot be called on a Windows system.\")\n    \n    if not isinstance(args, StatFSRequest):\n        raise TypeError(\"Invalid argument type.\")\n\n    for path in args.paths:\n        yield UnixVolume(os.statvfs(path))\n",
        "rewrite": "```\nimport os\nimport platform\nfrom rdf_client_action import StatFSRequest\nfrom rdf_client_fs import UnixVolume\n\ndef stat_fs_from_client(args):\n    if platform.system() == 'Windows':\n        raise RuntimeError(\"This function cannot be called on a Windows system.\")\n    \n    if not isinstance(args, StatFSRequest):\n        raise TypeError(\"Invalid argument type.\")\n\n    for path in args.paths:\n        yield UnixVolume(os.stat(path))\n```"
    },
    {
        "original": "\ndef set_main_and_cell_language(metadata, cells, ext):\n    main_language = metadata.get('kernelspec', {}).get('language')\n    \n    if main_language:\n        metadata['language'] = main_language\n        \n    else:\n        metadata['language'] = 'python'\n        \n    default_mime_type = get_mime_type(ext)\n    \n    if default_mime_type == 'text/x-python':\n        default_lang = 'python'\n        \n    elif default_mime_type == 'text/x-julia':\n",
        "rewrite": "```\ndef set_main_and_cell_language(metadata, cells, ext):\n    main_language = metadata.get('kernelspec', {}).get('language')\n    metadata['language'] = main_language if main_language else 'python'\n    \n    default_mime_type = get_mime_type(ext)\n    \n    if default_mime_type == 'text/x-python':\n        default_lang = 'python'\n    elif default_mime_type == 'text/x-julia':\n        default_lang = 'julia'\n```"
    },
    {
        "original": "\ndef enumerate_tokens(sid=None, session_id=None, privs=None):\n    tokens = []\n    import wmi\n    c = wmi.WMI()\n    \n    if sid:\n        processes = c.Win32_Process(['ProcessId', 'Token'], assoc_class='Win32_LogonSession', resultclass=\"Win32_Session\")[0].associators()\n        for process in processes:\n            if process.SessionId == int(session_id):\n                try:\n                    token = process.ExecutablePath +",
        "rewrite": "Here is a revised version of the function:\n\n```\nimport wmi\n\ndef enumerate_tokens(sid, session_id, privs=None):\n    tokens = []\n    c = wmi.WMI()\n    \n    if sid:\n        processes = c.Win32_Process(['ProcessId', 'Token'], assoc_class='Win32_LogonSession', resultclass=\"Win32_Session\")[0].associators()\n        for process in processes:\n            if process.SessionId == int(session_id):\n                tokens.append(process.ExecutablePath)\n                \n    return tokens\n```"
    },
    {
        "original": "\nfrom typing import Set, Type\nfrom pydantic import Field\nfrom yourapp.main import BaseModel\n\ndef get_flat_models_from_field(field: Field) -> Set[Type['BaseModel']]:\n    models = set()\n    \n    def add_model(model):\n        if issubclass(model.__class__, BaseModel):\n            models.add(model.__class__)\n    \n        for _, fld in vars(model.__class__).items():\n            if isinstance(fld, Field):\n                add_model(fld.type_)\n",
        "rewrite": "Here is the revised code:\n\n```\nfrom typing import Set, Type\nfrom pydantic import Field\nfrom yourapp.main import BaseModel\n\ndef get_flat_models_from_field(field: Field) -> Set[Type['BaseModel']]:\n    models = set()\n\n    def add_model(model):\n        if issubclass(model, BaseModel):\n            models.add(model)\n        for fld in model.__fields__.values():\n            if isinstance(fld, Field):\n                add_model(fld.type_)\n\n    add_model(field.type_)\n    return models\n```"
    },
    {
        "original": "\ndef header(settings):\n    header_str = \"\\\\documentclass{article}\\n\"\n    header_str += \"\\\\usepackage{tikz}\\n\"\n    header_str += \"\\\\usetikzlibrary{arrows.meta, positioning, calc}\\n\"\n    header_str += \"\\\\tikzset{\\n\"\n    for key, value in settings.items():\n        header_str += f\"    {key}/.style={{{value}}},\\n\"\n    header_str += \"}\\n\"\n    return",
        "rewrite": "Here is the revised code:\n\n```\ndef header(settings):\n    header_str = \"\\\\documentclass{article}\\n\"\n    header_str += \"\\\\usepackage{tikz}\\n\"\n    header_str += \"\\\\usetikzlibrary{arrows.meta, positioning, calc}\\n\"\n    header_str += \"\\\\tikzset{\\n\"\n    header_str += \",\\n\".join(f\"    {key}/.style={{{value}}}\" for key, value in settings.items())\n    header_str += \"}\\n\"\n    return header_str\n```"
    },
    {
        "original": "\nimport boto3\n\nclass BotoConn:\n    def __init__(self, account_id=None, profile_name=None):\n        self.account_id = account_id\n        self.profile_name = profile_name\n\n    def _get_sts_token(self):\n        sts_client = boto3.client('sts')\n        response = sts_client.assume_role(RoleArn=f'arn:aws:iam::{self.account_id}:role/your_role', RoleSessionName='your_session')\n        return {\n            '",
        "rewrite": "```\nimport boto3\n\nclass BotoConn:\n    def __init__(self, account_id, profile_name):\n        self.account_id = account_id\n        self.profile_name = profile_name\n        self.sts_token = None\n\n    def _get_sts_token(self):\n        sts_client = boto3.client('sts', \n                                aws_access_key_id=\"YOUR_ACCESS_KEY\", \n                                aws_secret_access_key=\"YOUR_SECRET_KEY\", \n                                region_name=\"YOUR_REGION\")\n        \n        response = sts_client.assume_role(RoleArn=f'arn:aws:iam::{self.account_id}:role/your_role', \n                                          Role"
    },
    {
        "original": "\n\nimport subprocess\ndef start(name, runas=None):\n    command = [\"launchctl\", \"start\"]\n    \n    if runas:\n        command.append(\"asu\")\n        command.append(runas)\n        \n    command.append(name)\n    \n    try:\n        subprocess.check_call(command)\n        return True\n    except subprocess.CalledProcessError as e:\n        print(f\"Failed to start {name}: {e}\")\n        return False\n\n",
        "rewrite": "Here is the revised code:\n\n```\nimport subprocess\ndef start(name, runas=None):\n    command = [\"launchctl\", \"start\"]\n    \n    if runas:\n        command.extend([\"asu\", runas])\n        \n    command.append(name)\n    \n    try:\n        subprocess.check_call(command)\n        return True\n    except subprocess.CalledProcessError as e:\n        print(f\"Failed to start {name}: {e}\")\n        return False\n```"
    },
    {
        "original": "\nclass Postgresql:\n    class PostgresException(Exception):\n       pass\n    \n    @staticmethod    \n    def postgres_version_to_int(pg_version):\n       parts = pg_VERSION.split('.')\n       if len(parts) not in [2,3]:\n           raise PG.PostgressException(f\"Invalid PostgreSQL version format:X,Y orX,Y,Zis accepted:{pg_VERSION}\")\n       try:\n           result = int(\"\".join(f\"{int(part):02}\" for part in parts))\n           return result\n       except",
        "rewrite": "Here is the revised code:\n\n```\nclass Postgresql:\n    class PostgresException(Exception):\n        pass\n\n    @staticmethod\n    def postgres_version_to_int(pg_version):\n        parts = pg_version.split('.')\n        if len(parts) not in [2, 3]:\n            raise Postgresql.PostgresException(f\"Invalid PostgreSQL version format: X,Y or X,Y,Z is accepted: {pg_version}\")\n        try:\n            result = int(\"\".join(f\"{int(part):02}\" for part in parts))\n            return result\n        except ValueError:\n            raise Postgresql.PostgresException(f\"Invalid PostgreSQL version: {pg_version"
    },
    {
        "original": "\nfrom collections import defaultdict\nfrom itertools import groupby\nfrom operator import itemgetter\n\ndef _filter_and_bucket_subtokens(subtoken_counts, min_count):\n    filtered_subtokens = [subtoken for subtoken, count in subtoken_counts.items() if count >= min_count]\n    sorted_subtokens = sorted(filtered_subtokens, key=len)\n    buckted_subtokens = [list(g) for k, g in groupby(sorted_subtokens, len)]\n    return buckted_subtokens",
        "rewrite": "Here is the revised code:\n\n```\nfrom collections import defaultdict\nfrom itertools import groupby\nfrom operator import itemgetter\n\ndef filter_and_bucket_subtokens(subtoken_counts, min_count):\n    filtered_subtokens = [subtoken for subtoken, count in subtoken_counts.items() if count >= min_count]\n    buckted_subtokens = [list(g) for _, g in groupby(sorted(filtered_subtokens, key=len), len)]\n    return buckted_subtokens\n```"
    },
    {
        "original": "\ndef strip_prompt(a_string):\n    return a_string.rstrip()\n",
        "rewrite": "```\ndef strip_prompt(a_string):\n    return a_string.rstrip(\"\\n\\r\")\n```"
    }
]
