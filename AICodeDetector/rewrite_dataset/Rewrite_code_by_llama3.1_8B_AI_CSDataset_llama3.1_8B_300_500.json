[
    {
        "original": "```python\ndef endian_swap_words(source):\n    \"\"\"\n    Endian-swap each word in 'source' bitstring\n    \"\"\"\n    \n    # Split the source string into words of 32 bits (4 bytes)\n    words = [source[i:i+32] for i in range(0, len(source), 32)]\n    \n    # Initialize an empty list to store the swapped words\n    swapped_words = []\n    \n    # Iterate over each word and swap its bytes\n    for word",
        "rewrite": "```python\ndef endian_swap_words(source):\n    words = [source[i:i+32] for i in range(0, len(source), 32)]\n    swapped_words = []\n    \n    for word in words:\n        # Convert the word to an integer\n        int_word = int(word, 2)\n        \n        # Swap the bytes of the integer\n        swapped_int_word = ((int_word & 0xFF000000) >> 24) | \n                           ((int_word & 0x00FF0000) >> 8) | \n                           ((int_word & 0x0000FF00) << "
    },
    {
        "original": "```python\n_SERVICE_MAP = {\n    'v1': 'int',\n    'v2': 'float',\n    'v3': lambda x: f\"'{x}'\",\n}\n\ndef GetValueRepresentation(cls, value, version='v1'):\n    \"\"\"\n    Converts a single python value to its PQL representation.\n\n    Args:\n      value: A python value.\n      version: A string identifying the Ad Manager version the value object\n          is compatible with.\n\n    Returns:\n      The value formatted",
        "rewrite": "```python\n_SERVICE_MAP = {\n    'v1': str,\n    'v2': float,\n    'v3': lambda x: f\"'{x}'\",\n}\n\ndef get_value_representation(cls, value, version='v1'):\n    \"\"\"\n    Converts a single python value to its PQL representation.\n\n    Args:\n        cls (type): The class of the value.\n        value: A python value.\n        version (str, optional): A string identifying the Ad Manager version the value object is compatible with. Defaults to 'v1'.\n\n    Returns:\n        str: The value formatted\n    \"\"\"\n    \n    if version not"
    },
    {
        "original": "```python\ndef calculator(prop, size):\n    \"\"\"\n    Execute the prop_to_size scaling mechanism calculator.\n    \n    :param prop: The classification rate (Proportion of votes of wining class)\n    :type prop: float\n    :param size: Initial value for marker size point (e.g. Marker's area point)\n    :type size: int or float\n    \n    :return: The scaled marker size based on the proportion of classification\n\n    \"\"\"\n    \n        # Press ctrl + d",
        "rewrite": "```python\ndef calculator(prop: float, size: int or float) -> int or float:\n    \"\"\"\n    Execute the prop_to_size scaling mechanism calculator.\n\n    This function scales the marker size based on the proportion of classification.\n\n    :param prop: The classification rate (Proportion of votes of winning class)\n    :type prop: float\n    :param size: Initial value for marker size point (e.g. Marker's area point)\n    :type size: int or float\n\n    :return: The scaled marker size based on the proportion of classification\n    \"\"\"\n    \n# Removed unexplained code segment \n\n# Scaled function"
    },
    {
        "original": "```python\nclass Solution:\n    def _to_dict(self):\n        \"\"\"\n        Return a json dictionary representing this model.\n        \n        :return: A dictionary representing the model.\n        \"\"\"\n        \n    def to_dict(self):\n        return {\n            \"model\": self.__class__.__name__,\n            \"version\": 1,\n            \"_schema_version\": 1,\n            \"_id\": str(id(self)),\n            **self._to_dict()\n        }\n```\n\nHowever, without more information about the class and",
        "rewrite": "```python\nclass ModelToJson:\n    def to_dict(self):\n        return {\n            \"model\": self.__class__.__name__,\n            \"version\": 1,\n            \"_schema_version\": 1,\n            \"_id\": id(self)\n        }\n\n\nclass Solution(ModelToJson):\n    def __init__(self, data):\n        self.data = data\n\n    def _to_dict(self):\n        return self.data\n```\n\nYou can use it like this:\n\n```python\nsolution = Solution({\"key\": \"value\"})\nprint(solution.to_dict())\n```"
    },
    {
        "original": "```python\nimport numpy as np\n\nclass Tensor:\n    def __init__(self, data):\n        self.data = np.array(data)\n\n    def __repr__(self):\n        return f'Tensor({self.data})'\n\ndef _pack(cls, tensors):\n    \"\"\"\n    Pack a list of `Tensor`s into a single, flattened, rank-1 `Tensor`.\n    \n    Args:\n        cls (class): The class of the tensor.\n        tensors (list): A list of `Tensor`",
        "rewrite": "```python\nimport numpy as np\n\nclass Tensor:\n    def __init__(self, data):\n        self.data = np.array(data)\n\n    def __repr__(self):\n        return f'Tensor({self.data})'\n\ndef pack(tensors):\n    \"\"\"\n    Pack a list of `Tensor`s into a single, flattened, rank-1 `Tensor`.\n    \n    Args:\n        tensors (list): A list of `Tensor` objects.\n    \n    Returns:\n        Tensor: A new `Tensor` object containing the packed data.\n    \"\"\"\n    return Tensor(np.concatenate([t.data for t in tensors]))\n```\n\nI made the following"
    },
    {
        "original": "```python\nimport logging\nimport subprocess\n\nclass Inspector:\n    def __init__(self):\n        self.logger = logging.getLogger(__name__)\n\n    def _build_plugins(self, format, path):\n        return {\n            \"qcow2\": self._build_qcow2,\n            \"iso\": self._build_iso,\n        }\n\n    def _build_qcow2(self, path):\n        try:\n            subprocess.run([\"kiwi\", \"create\", \"--format\", \"qcow2\", \"--output",
        "rewrite": "```python\nimport logging\nimport subprocess\n\nclass Inspector:\n    def __init__(self):\n        self.logger = logging.getLogger(__name__)\n\n    def _build_plugins(self, format, path):\n        plugins = {\n            \"qcow2\": self._build_qcow2,\n            \"iso\": self._build_iso,\n        }\n        return plugins.get(format, lambda: self.logger.warning(f\"Unsupported format: {format}\"))\n\n    def _build_qcow2(self, path):\n        try:\n            subprocess.run([\"kiwi\", \"create\", \"--format\", \"qcow2\", \"--output\", path], check=True)\n           "
    },
    {
        "original": "```python\nclass URNParser:\n    def ParseFromUnicode(self, value):\n        \"\"\"\n        Parse a string into a client URN.\n\n        Convert case so that all URNs are of the form C.[0-9a-f].\n\n        Args:\n          value: string value to parse\n        \"\"\"\n        \n        # Remove any leading or trailing whitespace from the input string\n        value = value.strip()\n        \n        # Convert the entire string to lowercase for consistency\n        value = value.lower()\n",
        "rewrite": "```python\nclass URNParser:\n    def parse_from_unicode(self, value: str) -> str:\n        value = value.strip()\n        return f\"C.[{value}]\".casefold()\n```"
    },
    {
        "original": "```python\nfrom functools import lru_cache\n\ndef get_default_locale_callable():\n    \"\"\"\n    Wrapper function so that the default mapping is only built when needed\n    \"\"\"\n    \n    @lru_cache(maxsize=None)\n    def get_default_locale(language_code):\n        # This is a placeholder for your actual logic to determine the default locale\n        # For example, you might use a dictionary or a database query to map language codes to locales\n        if language_code == 'en':\n            return '",
        "rewrite": "\n\n```python\nfrom functools import lru_cache\n\ndef get_default_locale_callable():\n    \"\"\"\n    Returns a caching function to get the default locale for a given language code.\n    \n    This function uses LRU caching to memoize the results of expensive function calls,\n    so that subsequent calls with the same arguments return immediately.\n    \n    :return: A cached function that takes a language code as input and returns the default locale.\n    \"\"\"\n    \n    @lru_cache(maxsize=None)\n    def get_default_locale(language_code):\n        # Define a dictionary mapping language codes to locales\n        locale_mapping = {\n           "
    },
    {
        "original": "```python\ndef convert_cli_table_to_dict(cli_table):\n    \"\"\"\n    Converts a TextFSM cli_table object to a list of dictionaries.\n    \n    Args:\n        cli_table (TextFSM): A TextFSM cli_table object.\n    \n    Returns:\n        list[dict]: A list of dictionaries where each dictionary represents a row in the table.\n    \"\"\"\n    \n    # Initialize an empty list to store the row dictionaries\n    rows = []\n    \n    # Check if the cli_table has",
        "rewrite": "```python\ndef convert_cli_table_to_dict(cli_table):\n    \"\"\"\n    Converts a TextFSM cli_table object to a list of dictionaries.\n    \n    Args:\n        cli_table (TextFSM): A TextFSM cli_table object.\n    \n    Returns:\n        list[dict]: A list of dictionaries where each dictionary represents a row in the table.\n    \"\"\"\n    \n    # Initialize an empty list to store the row dictionaries\n    rows = []\n    \n    # Check if the cli_table has data\n    if not cli_table.header or not cli_table.data:\n        return rows\n    \n    # Iterate over each row in the table\n"
    },
    {
        "original": "```python\nimport pymapd\nfrom time import perf_counter_ns\nfrom logging import getLogger\n\n# Get a logger instance\nlogger = getLogger('QueryExecuter')\n\ndef execute_query(**kwargs):\n    \"\"\"\n    Executes a query against the connected db using pymapd\n\n    Kwargs:\n        query_name(str): Name of query\n        query_mapdql(str): Query to run\n        iteration(int): Iteration number\n\n    Returns:\n        query_execution(dict):::\n            result_count(int",
        "rewrite": "```python\nimport pymapd\nfrom time import perf_counter_ns\nfrom logging import getLogger\n\n# Get a logger instance\nlogger = getLogger('QueryExecuter')\n\ndef execute_query(query_name: str, query_mapdql: str, iteration: int) -> dict:\n    \"\"\"\n    Executes a query against the connected db using pymapd\n\n    Args:\n        query_name (str): Name of query\n        query_mapdql (str): Query to run\n        iteration (int): Iteration number\n\n    Returns:\n        dict: A dictionary containing the result count and execution time in nanoseconds.\n    \"\"\"\n    start"
    },
    {
        "original": "```python\nclass GitHubAPI:\n    def remove_from_labels(self, label):\n        \"\"\"\n        :calls: `DELETE /repos/:owner/:repo/issues/:number/labels/:name <http://developer.github.com/v3/issues/labels>`_\n        :param label: :class:`github.Label.Label` or string\n        :rtype: None\n        \"\"\"\n        \n        # Assuming we have the repository owner, repo name and issue number.\n        \n        # We need to make a GET request to",
        "rewrite": "```python\nimport requests\n\nclass GitHubAPI:\n    def __init__(self, owner, repo, token):\n        \"\"\"\n        Initialize the GitHub API object.\n\n        :param owner: The owner of the repository.\n        :param repo: The name of the repository.\n        :param token: The GitHub API token.\n        \"\"\"\n        self.owner = owner\n        self.repo = repo\n        self.token = token\n\n    def remove_from_labels(self, issue_number, label):\n        \"\"\"\n        Remove a label from an issue.\n\n        :calls: `DELETE /repos/:owner/:repo/issues/:number/labels/:name <https://"
    },
    {
        "original": "```python\nimport requests\n\ndef detect_cadvisor(kubelet_url, cadvisor_port):\n    \"\"\"\n    Tries to connect to the cadvisor endpoint, with given params\n    :return: url if OK, raises exception if NOK\n    \"\"\"\n    \n    # Construct the cadvisor URL by appending the port to the kubelet URL\n    cadvisor_url = f\"{kubelet_url}:{cadvisor_port}\"\n    \n    try:\n        # Send a GET request to the constructed URL\n",
        "rewrite": "```python\nimport requests\n\ndef detect_cadvisor(kubelet_url, cadvisor_port):\n    cadvisor_url = f\"{kubelet_url}:{cadvisor_port}\"\n    response = requests.get(cadvisor_url)\n    response.raise_for_status()\n    return cadvisor_url\n```"
    },
    {
        "original": "```python\ndef _SignedBinaryIDFromURN(binary_urn):\n    \"\"\"\n    Converts an AFF4 URN for a signed binary to a SignedBinaryID.\n    \n    The AFF4 URN is expected to be in the format:\n    urn:aff4:signed_binary:<hash_value>\n    \n    Where <hash_value> is the hexadecimal representation of the hash value.\n    \n    The SignedBinaryID is expected to be in the format:\n    <hash_value>\n    \n    Parameters:\n   ",
        "rewrite": "```python\ndef signed_binary_id_from_urn(binary_urn):\n    urn_elements = binary_urn.split(':')\n    \n    if len(urn_elements) > 5 or len(urn_elements) < 4:\n        raise ValueError('Invalid URN format')\n        \n    return urn_elements[3]\n```"
    },
    {
        "original": "```python\ndef _validate_disallowed(self, disallowed, field, value):\n    \"\"\"\n    Readonly but with a custom error.\n\n    The rule's arguments are validated against this schema:\n    {'type': 'boolean'}\n    \n    Parameters:\n    disallowed (bool): \n        default = False\n        a variable as per instance\n    field (str): \n            the validation failed on and type of missing from here is key for instance attribute referencing referencing persmisp errolnfohigh",
        "rewrite": "```python\ndef _validate_disallowed(self, disallowed=True, field: str, value):\n    if not isinstance(disallowed, bool):\n        raise ValueError(f\"Expected boolean value for 'disallowed', got {type(disallowed).__name__}\")\n    if not isinstance(field, str):\n        raise ValueError(f\"Expected string value for 'field', got {type(field).__name__}\")\n```"
    },
    {
        "original": "```python\ndef _get_col_items(mapping):\n    \"\"\"\n    Get all column items to format, including both keys of `mapping`\n    and MultiIndex levels if any.\n    \"\"\"\n    col_items = set(mapping.keys())\n    if isinstance(mapping, dict) and any(isinstance(v, dict) for v in mapping.values()):\n        for k, v in mapping.items():\n            if isinstance(v, dict):\n                col_items.update(_get_col_items(v))\n    return col_items\n```",
        "rewrite": "```python\ndef _get_col_items(mapping):\n    col_items = set(mapping.keys())\n    if isinstance(mapping, dict) and any(isinstance(v, dict) for v in mapping.values()):\n        for k, v in mapping.items():\n            if isinstance(v, dict):\n                col_items.update(_get_col_items(v))\n    return col_items\n```"
    },
    {
        "original": "```python\nclass Solution:\n    def update_views(self):\n        \"\"\"\n        Update stats views.\n        \"\"\"\n        # Initialize a dictionary to store the views\n        views = {}\n        \n        # Initialize a variable to store the total views\n        total_views = 0\n        \n        # Initialize a variable to store the total clicks\n        total_clicks = 0\n        \n        # Initialize a variable to store the total impressions\n        total_impressions = 0\n        \n        # Initialize a variable to store the",
        "rewrite": "```python\nclass Solution:\n    def update_views(self):\n        \"\"\"\n        Update stats views.\n        \"\"\"\n        self.views = {}\n        self.total_views = 0\n        self.total_clicks = 0\n        self.total_impressions = 0\n\n    def add_view(self, view_id, clicks=0, impressions=1):\n        \"\"\"\n        Add a view to the stats.\n\n        Args:\n            view_id (str): Unique identifier for the view.\n            clicks (int, optional): Number of clicks on the view. Defaults to 0.\n            impressions (int, optional): Number of impressions for the view. Defaults"
    },
    {
        "original": "```python\nimport numpy as np\n\nclass LabelLoader:\n    def load_label(self, idx):\n        \"\"\"\n        Load label image as 1 x height x width integer array of label indices.\n        The leading singleton dimension is required by the loss.\n        The full 400 labels are translated to the 59 class task labels.\n        \"\"\"\n        # Assuming the label image is stored in a 3D numpy array with shape (height, width, 400)\n        # where each pixel is represented",
        "rewrite": "```python\nimport numpy as np\n\nclass LabelLoader:\n    def load_label(self, idx):\n        \"\"\"\n        Load label image as 1 x height x width integer array of label indices.\n        The leading singleton dimension is required by the loss.\n        The full 400 labels are translated to the 59 class task labels.\n        \"\"\"\n        \n        # Convert pixel index to (height, width) coordinates\n        height, width = np.unravel_index(idx % (2**18), (512, 1024)) # assuming size of image is 1/4 of max_idx value\n        \n        # Load corresponding label image from data"
    },
    {
        "original": "```python\nclass BuilderFilter:\n    def __init__(self, builderNames):\n        # Initialize the class with a list of configured builder names\n        self.builderNames = builderNames\n\n    def filterBuilderList(self, builderNames):\n        \"\"\"\n        Make sure that C{builderNames} is a subset of the configured\n        C{self.builderNames}, returning an empty list if not.  If\n        C{builderNames} is empty, use C{self.builderNames}.\n\n",
        "rewrite": "```python\nclass BuilderFilter:\n    def __init__(self, builder_names):\n        self.builder_names = [name.lower() for name in builder_names]\n\n    def filter_builder_list(self, builder_names):\n        if not builder_names:\n            return self.builder_names\n        return [name for name in builder_names if name.lower() in self.builder_names]\n```"
    },
    {
        "original": "```python\ndef fix_e262(self, result):\n    \"\"\"\n    Fix spacing after comment hash.\n    \n    This function takes a string as input and returns the modified string with proper spacing after a comment hash (#).\n    \n    Parameters:\n    result (str): The input string to be modified.\n    \n    Returns:\n    str: The modified string with proper spacing after a comment hash.\n    \"\"\"\n    \n    # Split the input string into lines\n    lines = result.split('\\n')\n    \n    #",
        "rewrite": "```python\ndef fix_e262(self, result):\n    \"\"\"\n    Fix spacing after comment hash.\n\n    This function takes a string as input and returns the modified string with proper spacing after a comment hash (#).\n\n    Parameters:\n    result (str): The input string to be modified.\n\n    Returns:\n    str: The modified string with proper spacing after a comment hash.\n    \"\"\"\n    \n    # Split the input string into lines\n    lines = [line.rstrip() for line in result.split('\\n')]\n    \n    # Use list comprehension to replace '# ' with '#\\n' or '#\\t' depending on whether the previous character is"
    },
    {
        "original": "```python\nimport numpy as np\n\ndef cartesian_product(arrays, flat=True, copy=False):\n    \"\"\"\n    Efficient cartesian product of a list of 1D arrays returning the\n    expanded array views for each dimensions. By default arrays are\n    flattened, which may be controlled with the flat flag. The array\n    views can be turned into regular arrays with the copy flag.\n    \"\"\"\n    \n    # Initialize result with first array in input list\n    result = np.array([array[",
        "rewrite": "```python\nimport numpy as np\n\ndef cartesian_product(arrays, flat=True, copy=False):\n    result = [arrays[0]]\n    for array in arrays[1:]:\n        if flat:\n            result = np.array(np.meshgrid(*result, array)).T.reshape(-1, len(result))\n        else:\n            if not all(hasattr(x, 'shape') for x in arrays):\n                raise ValueError(\"All arguments must have a shape attribute\")\n            result = [np.concatenate([r[:, None], a], axis=1) for r, a in zip(result, array)]\n    \n    return np.array(result[0])"
    },
    {
        "original": "```python\nimport json\n\ndef vm2json(vm):\n    \"\"\"\n    Get a JSON representation of a DEX file\n\n    :param vm: :class:`~androguard.core.bytecodes.dvm.DalvikVMFormat`\n    :return:\n    \"\"\"\n\n    # Initialize an empty dictionary to store the JSON data\n    json_data = {}\n\n    # Add the magic number to the JSON data\n    json_data['magic'] = vm.get_magic()\n\n    # Add the header size to the JSON",
        "rewrite": "```python\nimport json\n\nclass VMJSONExporter:\n    \"\"\"Helper class for exporting DalvikVMFormat to a JSON representation.\"\"\"\n\n    def __init__(self, vm):\n        \"\"\"\n        Initialize the exporter with a DalvikVMFormat instance.\n\n        :param vm: :class:`~androguard.core.bytecodes.dvm.DalvikVMFormat`\n        \"\"\"\n        self.vm = vm\n        self.json_data = {}\n\n    def add_magic(self):\n        \"\"\"Add the magic number to the JSON data.\"\"\"\n        self.json_data['magic'] = self.vm.get_magic()\n\n    def add_header_size(self):\n        \"\"\"Add the header size to"
    },
    {
        "original": "```python\nimport numpy as np\n\nclass NMR:\n    def read_cs_g0_contribution(self):\n        \"\"\"\n        Parse the G0 contribution of NMR chemical shielding.\n\n        Returns:\n        G0 contribution matrix as list of list.\n        \"\"\"\n        \n        # Assuming we have input as CSV file with 4 columns and unknown number of rows\n        # Format is like this: \\[ \\frac{1}{2} (f_{++10} + f_{+-01}) \\",
        "rewrite": "```python\nimport numpy as np\nimport pandas as pd\n\nclass NMR:\n    def read_cs_g0_contribution(self, csv_file):\n        \"\"\"\n        Parse the G0 contribution of NMR chemical shielding from a CSV file.\n\n        Args:\n            csv_file (str): Path to the CSV file containing the G0 contribution data.\n\n        Returns:\n            G0 contribution matrix as a 2D NumPy array.\n        \"\"\"\n        \n        # Read the CSV file into a pandas DataFrame\n        df = pd.read_csv(csv_file)\n        \n        # Ensure that there are exactly 4 columns in the DataFrame\n        if len(df"
    },
    {
        "original": "```python\ndef _split_arrs(array_2d, slices):\n    \"\"\"\n    Equivalent to numpy.split(array_2d, slices),\n    but avoids fancy indexing\n    \"\"\"\n    result = []\n    \n    start = 0\n    \n    for i in range(len(slices)):\n        if i == len(slices) - 1:\n            result.append(array_2d[start:])\n        else:\n            result.append(array_2d[start:slices[i]])\n        \n        start = slices[i]\n",
        "rewrite": "```python\ndef _split_arrs(array_2d, slices):\n    result = []\n    start = 0\n    \n    for end in slices:\n        result.append(array_2d[start:end])\n        start = end\n    \n    if start < len(array_2d):\n        result.append(array_2d[start:])\n\ndef split_array_with_negatives(input_array,size, steps_for_positives=1):\n    pos_split_points = list(range(0,input_array.shape[0],steps_for_positives))\n    \n    neg_split_points = []\n    \n    for i in range(len(pos_split_points)-1,-1,-1):\n       "
    },
    {
        "original": "```python\nimport os\nimport yaml\n\ndef load_from_file(swag_path, swag_type='yml', root_path=None):\n    \"\"\"\n    Load specs from YAML file\n    \"\"\"\n\n    # Check the file type and read the contents accordingly\n    if swag_type.lower() == 'yml':\n        with open(swag_path, 'r') as f:\n            specs = yaml.safe_load(f)\n    elif swag_type.lower() == 'json':\n        with open(swag",
        "rewrite": "```python\nimport os\nimport yaml\n\ndef load_from_file(swag_path, swag_type='yml', root_path=None):\n    \"\"\"\n    Load specs from file based on the given type.\n    \"\"\"\n    \n    if swag_type.lower() not in ['yml', 'json']:\n        raise ValueError(\"Invalid file type. Supported types are 'yml' and 'json'.\")\n    \n    try:\n        with open(swag_path, 'r') as f:\n            if swag_type.lower() == 'yml':\n                specs = yaml.safe_load(f)\n            elif swag_type.lower() == 'json':\n"
    },
    {
        "original": "```python\nfrom jinja2 import Template\nimport os\n\ndef render(template, dest, **kwargs):\n    \"\"\"Using jinja2, render `template` to the filename `dest`, supplying the\n\n    keyword arguments as template parameters.\n    \"\"\"\n    \n    # Read the template file\n    with open(template, 'r') as f:\n        t = Template(f.read())\n        \n        # Render the template with the given kwargs\n        rendered = t.render(**kwargs)\n        \n        # Write",
        "rewrite": "```python\nfrom jinja2 import Template\nimport os\n\ndef render(template, dest, **kwargs):\n    \"\"\"Render a Jinja2 template to a file.\n\n    Args:\n        template (str): Path to the Jinja2 template file.\n        dest (str): Destination path for the rendered file.\n        **kwargs: Keyword arguments to be used as template parameters.\n    \"\"\"\n    \n    with open(template, 'r') as f:\n        t = Template(f.read())\n        \n        rendered = t.render(**kwargs)\n        \n        with open(dest, 'w') as output_file:\n            output_file.write(rendered)\n```\n\n"
    },
    {
        "original": "```python\nimport matplotlib.pyplot as plt\n\nclass Display:\n    def imshow(self, canvas, X, extent=None, label=None, vmin=None, vmax=None, **kwargs):\n        \"\"\"\n        Show the image stored in X on the canvas.\n\n        The origin of the image show is (0,0), such that X[0,0] gets plotted at [0,0] of the image!\n\n        the kwargs are plotting library specific kwargs!\n        \"\"\"\n        \n        # assume canvas is an",
        "rewrite": "```python\nimport matplotlib.pyplot as plt\n\nclass Display:\n    def imshow(self, canvas, X, extent=None, label=None, vmin=None, vmax=None, **kwargs):\n        \"\"\"\n        Show the image stored in X on the canvas.\n\n        The origin of the image show is (0,0), such that X[0,0] gets plotted at [0,-1] of the image!\n        \n        Parameters:\n            canvas (matplotlib.axes.Axes): The axes to plot on.\n            X (numpy.ndarray): The 2D array to display.\n            extent (tuple or list): The x and y limits of the"
    },
    {
        "original": "```python\nimport numpy as np\n\ndef _probvec(r, out):\n    \"\"\"\n    Fill `out` with randomly sampled probability vectors as rows.\n\n    To be complied as a ufunc by guvectorize of Numba. The inputs must\n    have the same shape except the last axis; the length of the last\n    axis of `r` must be that of `out` minus 1, i.e., if out.shape[-1] is\n    k, then r",
        "rewrite": "```python\nimport numpy as np\nfrom numba import njit\n\n@njit(fastmath=True)\ndef _probvec(r, out):\n    rows, cols = r.shape[0], out.shape[-1]\n    for i in range(rows):\n        for j in range(cols - 1):\n            out[i, j] = np.random.rand()\n        # Normalize the last column to ensure it's a probability vector\n        out[i, -1] = 1 - sum(out[i, :-1])\n```\n\nNote that I've used Numba's `@njit` decorator to compile the function into machine"
    },
    {
        "original": "```python\nfrom typing import Dict, List\n\ndef validate(config: Dict) -> bool:\n    \"\"\"\n    Validate a config file.\n    \n    The config should be a dictionary containing the following keys:\n    - header (integer): the length of the key-value pairs in the following pairs\n    - K (integer): number of key-value pairs\n    - max_len_key (integer): maximum length of a key\n    - max_len_value (integer): maximum length of a value\n    \n    Each",
        "rewrite": "```python\nfrom typing import Dict\n\ndef validate(config: Dict[str, int]) -> bool:\n    required_keys = [\"header\", \"K\", \"max_len_key\", \"max_len_value\"]\n    \n    return all(key in config for key in required_keys) and \\\n           isinstance(config[\"header\"], int) and \\\n           isinstance(config[\"K\"], int) and \\\n           isinstance(config[\"max_len_key\"], int) and \\\n           isinstance(config[\"max_len_value\"], int)\n```"
    },
    {
        "original": "```python\nclass DataFrame:\n    def __init__(self):\n        self.columns = []\n\n    def set_last_col_idx(self, last_col_idx):\n        \"\"\"\n        Parameters\n        ----------\n        param last_col_idx : int\n            number of columns\n        \"\"\"\n        \ndef create_dataframe(n_rows, n_cols):\n    df = DataFrame()\n    \n    # Create a list of column names (assuming they are 'col_0' to 'col_(n-1)')\n    df.columns = [f'",
        "rewrite": "\n\n```python\nclass DataFrame:\n    def __init__(self):\n        self.columns = []\n        self.data = []\n\n    def set_last_col_idx(self, last_col_idx):\n        \"\"\"\n        Parameters\n        ----------\n        param last_col_idx : int\n            number of columns\n        \"\"\"\n        \n    def add_column(self, name):\n        self.columns.append(name)\n        \n    def add_row(self, row_data):\n        if len(row_data) != len(self.columns):\n            raise ValueError(\"Row data length does not match column count\")\n        \n        self.data.append(row_data)\n\ndef create_dataframe(n_rows, n_cols"
    },
    {
        "original": "```python\nimport numpy as np\n\nclass ConvolutionMatrix:\n    def __init__(self, weight_matrix):\n        self.weight_matrix = weight_matrix\n\n    def _apply_mask(self, mask):\n        \"\"\"\n        Applies the passed-in mask to the convolution matrix.\n\n        Args:\n            mask (numpy.ndarray): A 2D or 3D array representing the mask.\n\n        Returns:\n            w: A copy of the convolution matrix that has had the mask applied.\n\n        Raises:\n            ValueError:",
        "rewrite": "```python\nimport numpy as np\n\nclass ConvolutionMatrix:\n    def __init__(self, weight_matrix):\n        if not isinstance(weight_matrix, np.ndarray) or len(weight_matrix.shape) != 2:\n            raise ValueError(\"Weight matrix must be a 2D NumPy array\")\n        self.weight_matrix = weight_matrix.copy()\n\n    def _apply_mask(self, mask):\n        \"\"\"\n        Applies the passed-in mask to the convolution matrix.\n        \n        Args:\n            mask (numpy.ndarray): A 3D NumPy array representing the padded channels and spatial axes of the input.\n            \n        Returns:\n            w: A copy of"
    },
    {
        "original": "```python\nclass Coordinate:\n    def __init__(self, degrees, arcminutes, arcseconds, direction=None):\n        self.degrees = degrees\n        self.arcminutes = arcminutes\n        self.arcseconds = arcseconds\n        self.direction = direction\n\n    @classmethod\n    def parse_degrees(cls, degrees, arcminutes=0, arcseconds=0, direction=None):\n        \"\"\"\n        Parse degrees minutes seconds including direction (N, S, E, W)\n        \n        Args",
        "rewrite": "```python\nclass Coordinate:\n    def __init__(self, degrees, arcminutes=0, arcseconds=0, direction=None):\n        if not direction in ['N', 'S', 'E', 'W']:\n            raise ValueError(\"Invalid direction. Must be one of N, S, E or W\")\n        self.degrees = degrees\n        self.arcminutes = arcminutes\n        self.arcseconds = arcseconds\n        self.direction = direction\n\n    @classmethod\n    def parse(cls, value: str):\n        parts = value.split()\n        \n        if len(parts) == 1:\n            # Assuming a single number"
    },
    {
        "original": "```python\nimport time\nimport random\n\ndef _execute_with_retries(conn, function, **kwargs):\n    \"\"\"\n    Retry if we're rate limited by AWS or blocked by another call.\n    Give up and return error message if resource not found or argument is invalid.\n\n    conn\n        The connection established by the calling method via _get_conn()\n\n    function\n        The function to call on conn. i.e. create_stream\n\n    **kwargs\n        Any kwargs required by the above function",
        "rewrite": "```python\nimport time\nimport random\n\ndef _execute_with_retries(conn, function, **kwargs):\n    max_retries = 5\n    retry_delay = 1  # seconds\n    retry_backoff = 2  # seconds\n\n    for attempt in range(max_retries):\n        try:\n            return function(conn, **kwargs)\n        except Exception as e:\n            if attempt < max_retries - 1:\n                delay = retry_delay * (2 ** attempt)\n                time.sleep(delay)\n            else:\n                raise\n```"
    },
    {
        "original": "```python\nimport requests\nimport json\n\nclass GitHubAPI:\n    def __init__(self, owner, repo, token):\n        self.owner = owner\n        self.repo = repo\n        self.token = token\n        self.base_url = f'https://api.github.com/repos/{owner}/{repo}/pulls'\n\n    def get_review_requests(self, number):\n        headers = {'Authorization': f'token {self.token}'}\n        params = {'number': number}\n        response = requests.get",
        "rewrite": "```python\nimport requests\nimport json\n\nclass GitHubAPI:\n    def __init__(self, owner, repo, token):\n        self.owner = owner\n        self.repo = repo\n        self.token = token\n        self.base_url = f'https://api.github.com/repos/{owner}/{repo}/pulls'\n\n    def get_review_requests(self, number):\n        headers = {'Authorization': f'token {self.token}'}\n        params = {'number': number}\n        response = requests.get(self.base_url, headers=headers, params=params)\n        \n        if response.status_code == 200:\n            return response.json()\n        \n        else"
    },
    {
        "original": "```python\nclass Input:\n    def __init__(self, name, value, signed=False):\n        self.name = name\n        self.value = value\n        self.signed = signed\n\n    def to_dict(self):\n        \"\"\"Transforms the object to a Python dictionary.\n\n        Note:\n            If an Input hasn't been signed yet, this method returns a\n            dictionary representation.\n\n        Returns:\n            dict: The Input as an alternative serialization format.\n        \"\"\"\n        return {\n            'name",
        "rewrite": "```python\nclass Input:\n    def __init__(self, name, value, signed=False):\n        self.name = name\n        self.value = value\n        self.signed = signed\n\n    def to_dict(self):\n        return {\n            'name': self.name,\n            'value': self.value,\n            'signed': self.signed\n        }\n```\n\nNote: I've corrected the dictionary key from `'name\" `. to `'name'` to ensure it's a valid Python syntax. Also, no code comments are added as per your request."
    },
    {
        "original": "```python\nclass Callable:\n    def __init__(self, func):\n        self.func = func\n\n    def __call__(self, *args, **kwargs):\n        return self.func(*args, **kwargs)\n\n    def clone(self, callable=None, **overrides):\n        \"\"\"Clones the Callable optionally with new settings\n\n        Args:\n            callable: New callable function to wrap\n            **overrides: Parameter overrides to apply\n\n        Returns:\n            Cloned Callable object\n        \"\"\"\n        if",
        "rewrite": "```python\nclass Callable:\n    def __init__(self, func):\n        self.func = func\n\n    def __call__(self, *args, **kwargs):\n        return self.func(*args, **kwargs)\n\n    def clone(self, callable=None, **overrides):\n        if callable is not None:\n            overrides.setdefault('func', callable)\n        else:\n            overrides = {'func': self.func}\n        return type(self)(**overrides)\n```\n\nThis revised code:\n\n- Uses `setdefault` to handle the case where `callable` is provided by setting its value to the original function when creating a new instance with the same"
    },
    {
        "original": "```python\nimport mysql.connector\n\ndef user_list(**connection_args):\n    \"\"\"\n    Return a list of users on a MySQL server\n\n    CLI Example:\n\n    .. code-block:: bash\n\n        salt '*' mysql.user_list\n    \"\"\"\n\n    # Establish a connection to the MySQL server\n    cnx = mysql.connector.connect(**connection_args)\n\n    # Create a cursor object to execute SQL queries\n    cursor = cnx.cursor()\n\n    # Execute the query to get all users from the 'mysql.user",
        "rewrite": "```python\nimport mysql.connector\n\ndef user_list(**connection_args):\n    \"\"\"\n    Return a list of users on a MySQL server.\n\n    CLI Example:\n        salt '*' mysql.user_list\n\n    :param connection_args: Keyword arguments for connecting to the MySQL server.\n        Required arguments are 'host', 'user', 'password', and 'database'.\n        Optional argument is 'port' (default is 3306).\n    :return: A list of tuples containing user information.\n    \"\"\"\n\n    # Establish a connection to the MySQL server with error handling\n    try:\n        cnx = mysql.connector.connect(**connection_args)\n        cursor ="
    },
    {
        "original": "```python\nimport salt.client\n\ndef reboot(search, one=True, force=False):\n    \"\"\"\n    Reboot one or more vms\n\n    search : string\n        filter vms, see the execution module.\n    one : boolean\n        reboot only one vm\n    force : boolean\n        force reboot, faster but no graceful shutdown\n\n    .. note::\n        If the search parameter does not contain an equal (=) symbol it will be\n        assumed it will be tried as uuid, hostname",
        "rewrite": "```python\nimport salt.client\n\nclass VMRebooter:\n    def __init__(self, client):\n        self.client = client\n\n    def reboot(self,\n               search,\n               one=True,\n               force=False):\n        \"\"\"\n        Reboot one or more vms\n        :param search: string - filter vms, see the execution module.\n        :param one: boolean - reboot only one vm\n        :param force: boolean - force reboot, faster but no graceful shutdown\n        \"\"\"\n        \nresult = self.client.cmd(search)\nvm_list = result.get('vms') if isinstance(result, dict) else [result]\n\n"
    },
    {
        "original": "```python\ndef InitFromAff4Object(self, aff4_obj, aff4_cls, attr_blacklist):\n    \"\"\"\n    Initializes the current instance from an Aff4Object.\n\n    Iterates over all attributes of the Aff4Object defined by a given class\n    and adds a representation of them to the current instance.\n\n    Args:\n      aff4_obj: An Aff4Object to take the attributes from.\n      aff4_cls: A class in the inheritance hierarchy of the Aff4Object defining",
        "rewrite": "```python\ndef init_from_aff4_object(self, aff4_obj, aff4_cls, attr_blacklist):\n    for attr_name in dir(aff4_obj):\n        if not attr_name.startswith('__'):\n            aff4_attr = getattr(aff4_obj, attr_name)\n            if not isinstance(aff4_attr, type(attr_blacklist)) and attr_name not in attr_blacklist:\n                setattr(self, f\"{attr_cls.__name__}_{attr_name}\", aff4_attr)\n```"
    },
    {
        "original": "```python\ndef _gen_get_more_command(cursor_id, coll, batch_size, max_await_time_ms):\n    \"\"\"\n    Generate a getMore command document.\n    \n    :param cursor_id: The ID of the cursor.\n    :param coll: The collection name.\n    :param batch_size: The batch size.\n    :param max_await_time_ms: The maximum await time in milliseconds.\n    :return: A dictionary representing the getMore command document.\n    \"\"\"\n    get_more_command",
        "rewrite": "```python\ndef _gen_get_more_command(cursor_id, coll, batch_size, max_await_time_ms):\n    return {\n        \"getMore\": 1,\n        \"collection\": coll,\n        \"batchSize\": batch_size,\n        \"maxAwaitTimeMS\": max_await_time_ms\n    }\n```"
    },
    {
        "original": "```python\nfrom enum import Enum\n\nclass Baudrate(Enum):\n    # Define baud rate values for BTR0 and BTR1 registers\n    BAUD_100K = 0b00011000\n    BAUD_125K = 0b00011111\n    \n    # Add other baud rates as necessary\n\nclass Channel(Enum):\n    CHANNEL_CH0 = 0\n    CHANNEL_CH1 = 1\n\nclass BaudrateEx(Enum):\n    BAUD_RATE_100",
        "rewrite": "```python\nfrom enum import Enum\n\nclass Baudrate(Enum):\n    BAUD_100K = 0b00011000\n    BAUD_125K = 0b00011111\n    BAUD_9600 = 0b00000011\n    BAUD_14400 = 0b00000101\n    BAUD_19200 = 0b00000110\n    BAUD_38400 = 0b00001000\n    BAUD_57600 = 0b00001010\n    BAUD_115200 = 0b00001111\n\nclass Channel"
    },
    {
        "original": "```python\nimport cftime\n\ndef _get_day_of_month(other, day_option):\n    \"\"\"\n    Find the day in `other`'s month that satisfies a BaseCFTimeOffset's\n    onOffset policy, as described by the `day_option` argument.\n\n    Parameters\n    ----------\n    other : cftime.datetime\n    day_option : 'start', 'end'\n        'start': returns 1\n        'end': returns last day of the month\n\n    Returns\n   ",
        "rewrite": "```python\nimport cftime\n\ndef _get_day_of_month(other, day_option):\n    if day_option == 'start':\n        return 1\n    elif day_option == 'end':\n        return other.day + (31 - other.day) if other.month in [1, 3, 5, 7, 8, 10] else \\\n               other.day + (30 - other.day) if other.month in [4, 6, 9] else \\\n               other.day + (28 - other.day)\n    else:\n        raise ValueError(\"Invalid day option. Must be 'start' or 'end"
    },
    {
        "original": "```python\nclass Solution:\n    def __init__(self):\n        self.n = 0\n        self.k = 0\n        self.arr = []\n\n    def getAverages(self, arr: list[int], n: int, k: int) -> list[int]:\n        self.n = n\n        self.k = k\n        self.arr = arr\n        self.calculate_averages()\n        return self.arr\n\n    def calculate_averages(self):\n        window_size = 2",
        "rewrite": "```python\nclass Solution:\n    def __init__(self):\n        self.n = 0\n        self.k = 0\n        self.arr = []\n\n    def getAverages(self, arr: list[int], n: int, k: int) -> list[int]:\n        self.n = n\n        self.k = k\n        self.arr = arr\n\n    def calculate_averages(self):\n        window_size = 2 * (self.k + 1)\n        \n        for i in range(len(self.arr)):\n            if i < self.k or i >= len(self.arr) - self.k:\n                # If the index"
    },
    {
        "original": "```python\nimport numpy as np\n\nclass Forest:\n    def _run_and_measure(self, quil_program, qubits, trials, random_seed):\n        \"\"\"\n        Run a Forest ``run_and_measure`` job.\n\n        Users should use :py:func:`WavefunctionSimulator.run_and_measure` instead of calling\n        this directly.\n        \"\"\"\n        \n        # Initialize the random number generator with the given seed\n        np.random.seed(random_seed)\n        \n        # Initialize the result array with zeros\n",
        "rewrite": "```python\nimport numpy as np\n\nclass Forest:\n    def _run_and_measure(self, quil_program, qubits, trials, random_seed):\n        \"\"\"\n        Run a Forest ``run_and_measure`` job.\n        \"\"\"\n        \n        # Initialize the random number generator with the given seed\n        np.random.seed(random_seed)\n        \n        # Initialize the result array with zeros\n        results = np.zeros((trials,))\n        \n        # Run and measure the Quil program for each trial\n        for i in range(trials):\n            # Simulate the Quil program on a quantum computer (assuming this is implemented elsewhere)\n            measurement ="
    },
    {
        "original": "```python\ndef serialize_close(code: int, reason: str) -> bytes:\n    \"\"\"\n    Serialize the data for a close frame.\n\n    This is the reverse of :func:`parse_close`.\n\n    \"\"\"\n    # Convert the code to bytes\n    code_bytes = code.to_bytes(2, 'big')\n    \n    # Encode the reason to bytes\n    reason_bytes = reason.encode('utf-8')\n    \n    # Calculate the total length of the close frame\n    total_length = ",
        "rewrite": "\n\n```python\ndef serialize_close(code: int, reason: str) -> bytes:\n    \"\"\"\n    Serialize the data for a close frame.\n\n    This is the reverse of :func:`parse_close`.\n\n    Args:\n        code (int): The close frame code.\n        reason (str): The reason for closing.\n\n    Returns:\n        bytes: The serialized close frame data.\n    \"\"\"\n    \n    # Convert the code to bytes in big-endian byte order\n    code_bytes = code.to_bytes(2, 'big')\n    \n    # Encode the reason to UTF-8 encoded bytes\n    reason"
    },
    {
        "original": "```python\nclass Vim:\n    class HostSystem:\n        def __init__(self, name):\n            self.name = name\n\n    class Datastore:\n        def __init__(self, name):\n            self.name = name\n\n    class HostCacheConfigurationManager:\n        def __init__(self, host_system):\n            self.host_system = host_system\n\ndef configure_host_cache(host_ref, datastore_ref, swap_size_MiB, host_cache_manager=None):\n    \"\"\"\n    Configures the host ca",
        "rewrite": "```python\nclass Vim:\n    class HostSystem:\n        def __init__(self, name):\n            self.name = name\n\n    class Datastore:\n        def __init__(self, name):\n            self.name = name\n\n    class HostCacheConfigurationManager:\n        def __init__(self, host_system):\n            self.host_system = host_system\n\ndef configure_host_cache(host_ref: 'Vim.HostSystem', datastore_ref: 'Vim.Datastore', swap_size_MiB: int, \n                          host_cache_manager: 'Vim.HostCacheConfigurationManager' = None) -> None:\n    if not isinstance(host_ref,"
    },
    {
        "original": "```python\nclass InvalidFilterError(Exception):\n    pass\n\nclass Subscriber:\n    def __init__(self):\n        self.subscribers = {}\n\n    def add_subscriber(self, connection_id, subscriptions, last_known_block_id):\n        \"\"\"\n        Register the subscriber for the given event subscriptions.\n\n        Args:\n            connection_id (str): The ID of the connection.\n            subscriptions (list): A list of event filters to subscribe to.\n            last_known_block_id (int): The ID of the last block",
        "rewrite": "```python\nclass InvalidFilterError(Exception):\n    pass\n\nclass Subscriber:\n    def __init__(self):\n        self.subscribers = {}\n\n    def add_subscriber(self, connection_id: str, subscriptions: list[str], last_known_block_id: int) -> None:\n        if not all(isinstance(subscription, str) for subscription in subscriptions):\n            raise ValueError(\"All subscriptions must be strings\")\n\n        for index, subscription in enumerate(subscriptions):\n            if ' ' in subscription:\n                raise InvalidFilterError(f\"Invalid filter at index {index}: '{subscription}' contains spaces\")\n\n        self.subscribers[connection_id] = {\n           "
    },
    {
        "original": "```python\nimport xarray as xr\n\ndef assert_coordinate_consistent(obj, coords):\n    \"\"\"\n    Make sure the dimension coordinate of obj is consistent with coords.\n\n    Parameters:\n    obj (DataArray or Dataset): Input data object\n    coords (Dict-like of variables): Expected coordinates\n\n    Returns:\n    None: If the coordinates are consistent, otherwise raises an AssertionError\n    \"\"\"\n\n    # Check if obj is a DataArray or Dataset\n    if not isinstance(obj, (xr.DataArray",
        "rewrite": "```python\nimport xarray as xr\n\ndef assert_coordinate_consistent(obj, coords):\n    \"\"\"\n    Make sure the dimension coordinate of obj is consistent with coords.\n    \"\"\"\n\n    if not isinstance(obj, (xr.DataArray, xr.Dataset)):\n        raise TypeError(\"obj must be a DataArray or Dataset\")\n\n    for dim, coord in coords.items():\n        if dim not in obj.coords:\n            raise AssertionError(f\"Missing dimension: {dim}\")\n        \n        if not np.allclose(obj.coords[dim], coord):\n            raise AssertionError(f\"Inconsistent coordinate: {dim} = {obj.coords[dim]} != {coord}\")\n\n# Example usage:\n"
    },
    {
        "original": "```python\nfrom pyrogram import Client, ChatAction\n\ndef reply_chat_action(client: Client, action: Union[ChatAction, str], progress: int = 0) -> bool:\n    \"\"\"\n    Sends a chat action to the user.\n\n    Args:\n        client (Client): The Pyrogram client instance.\n        action (ChatAction | str): The type of action to broadcast.\n        progress (int, optional): Progress of the upload process. Defaults to 0.\n\n    Returns:\n",
        "rewrite": "```python\nfrom pyrogram import Client, ChatAction\nfrom typing import Union\n\ndef reply_chat_action(client: Client, action: Union[ChatAction, str], progress: int = 0) -> bool:\n    try:\n        # Check if action is a string and convert it to ChatAction if necessary\n        if isinstance(action, str):\n            action = ChatAction[action]\n        \n        # Send the chat action to the user\n        client.send_chat_action(chat_id=client.me.id, action=action)\n        \n        return True\n    \n    except Exception as e:\n        # Log or print any exceptions that occur during the execution"
    },
    {
        "original": "```python\nclass Solution:\n    def write(self, path):\n        # Create a new object with the desired output schema and write it.\n        # For simplicity, let's assume we're writing a JSON file.\n        import json\n\n        data = {\n            \"name\": \"John\",\n            \"age\": 30,\n            \"city\": \"New York\"\n        }\n\n        with open(path, 'w') as f:\n            json.dump(data, f)\n```",
        "rewrite": "```python\nimport json\n\nclass Solution:\n    def write(self, path: str) -> None:\n        data = {\"name\": \"John\", \"age\": 30, \"city\": \"New York\"}\n\n        with open(path, 'w') as f:\n            json.dump(data, f)\n```"
    },
    {
        "original": "```python\nimport math\n\nclass CpuSample:\n    def __init__(self, name, value):\n        \"\"\"\n        Args:\n          name: String identifier for the sample.\n          value: Value represented by `usercpu` or `syscpu`.\n        \"\"\"\n        self.name = name\n        self.value = value  # Latex: \\mu + \\sigma\n\n    @classmethod\n    def combined_sample(cls, user_cpu_samples, sys_cpu_samples):\n        if not user_cpu_samples and",
        "rewrite": "```python\nimport math\n\nclass CpuSample:\n    def __init__(self, name, value):\n        \"\"\"\n        Args:\n          name: String identifier for the sample.\n          value: Value represented by `usercpu` or `syscpu`.\n        \"\"\"\n        self.name = name\n        self.value = value  # Latex: \\mu + \\sigma\n\n    @classmethod\n    def combined_sample(cls, user_cpu_samples, sys_cpu_samples):\n        if not user_cpu_samples and not sys_cpu_samples:\n            return None  # Return None if both lists are empty\n        elif not user_cpu_samples:\n            return cls"
    },
    {
        "original": "```python\nimport json\nimport os\n\nCONF = {}  # Assuming CONF is a dictionary with the default API version\n\ndef load_api_specific_resource_module(resource_name, api=None):\n    \"\"\"\n    Load the module from the JSON files and return a dict, which might be empty\n    if the resource could not be loaded.\n\n    If no api version is given, the default one from the CONF dict is used.\n\n    :param resource_name: Name of the resource to load\n    :param",
        "rewrite": "```python\nimport json\nimport os\n\nCONF = {}  # store API versions here\n\ndef load_api_specific_resource_module(resource_name, api=None):\n    \"\"\"\n    Loads module from the JSON files and returns a dictionary.\n    If no API version is given, uses the default one from CONF.\n\n    :param resource_name: Name of the resource to load\n    :param api: Optional API version (default: CONF['default'])\n    \"\"\"\n    \n    if api is None:\n        api = CONF.get('default')\n    \n    if not isinstance(api, str):\n        raise ValueError(\"API must be a string\")\n    \n    try:\n"
    },
    {
        "original": "```python\nfrom typing import Tuple\n\nclass HuffmanDecoder:\n    \n    @staticmethod\n    def huffman_conv2bitstring(cls, s: str) -> Tuple[str, int]:\n        \"\"\"\n        Converts a string into its bitstring representation.\n        \n        @param str s: the bytestring to convert.\n        @return (int, int): the bitstring of s, and its bitlength.\n        @raise AssertionError\n        \"\"\"\n        \n        # Initialize an empty binary string\n        binary",
        "rewrite": "```python\nfrom typing import Tuple\n\nclass HuffmanDecoder:\n    \n    @staticmethod\n    def huffman_conv2bitstring(s: str) -> Tuple[str, int]:\n        \"\"\"\n        Converts a string into its bitstring representation.\n        \n        @param str s: the bytestring to convert.\n        @return (str, int): the bitstring of s, and its bitlength.\n        \"\"\"\n        \n        # Initialize an empty binary string\n        binary_string = ''\n        \n        # Iterate over each character in the input string\n        for char in s:\n            # Convert the character to its ASCII value and then to binary\n"
    },
    {
        "original": "```python\nclass Analysis:\n    def __init__(self, classes):\n        self.classes = classes\n\n    def get_analysis(self, current_class):\n        \"\"\"\n        Returns the :class:`~androguard.core.analysis.analysis.Analysis` object\n        which contains the `current_class`.\n\n        :param current_class: The class to search for\n        :type current_class: androguard.core.bytecodes.dvm.ClassDefItem\n        :rtype: androguard.core.analysis.analysis.Analysis\n       ",
        "rewrite": "```python\nclass Analysis:\n    def __init__(self, classes):\n        self.classes = classes\n\n    def get_analysis(self, current_class):\n        \"\"\"\n        Returns the Analysis object which contains the current_class.\n\n        :param current_class: The class to search for\n        :type current_class: androguard.core.bytecodes.dvm.ClassDefItem\n        :rtype: androguard.core.analysis.analysis.Analysis\n        \"\"\"\n        return next((cls for cls in self.classes if cls.contains(current_class)), None)\n```"
    },
    {
        "original": "```python\nclass Transformation:\n    def apply_transformation(self, structure):\n        \"\"\"\n        Returns most primitive cell for structure.\n\n        Args:\n            structure: A quadruple of two 2D arrays representing the cell in standard basis and one integer representing the translation vector, i.e., (A, B, c).\n\n        Returns:\n            The same structure in a conventional standard setting.\n        \"\"\"\n\n        # Assuming the input is a list of three lists where the first two lists are 2D arrays",
        "rewrite": "```python\nimport numpy as np\n\nclass Transformation:\n    def apply_transformation(self, structure):\n        \"\"\"\n        Returns most primitive cell for structure.\n\n        Args:\n            structure: A quadruple of two 2D arrays representing the cell in standard basis and one integer representing the translation vector, i.e., (A, B, c).\n\n        Returns:\n            The same structure in a conventional standard setting.\n        \"\"\"\n\n        A = np.array(structure[0])\n        B = np.array(structure[1])\n        \n        # Calculate the determinant of matrix AB\n        det_AB = np.linalg.det(np.dot(A, B))\n        \n"
    },
    {
        "original": "```python\ndef get_object(cont, obj, local_file=None, return_bin=False):\n    \"\"\"\n    Retrieve a file from Swift\n    \"\"\"\n    \n    # Connect to the container\n    # Here we assume 'client' is an instance of a class that has methods to interact with the Swift storage service.\n    client = container_client.Client(cont)\n    \n    # Get the object from the container\n    obj_data = client.get_object(obj)\n\n    \n# Example usage:\ncontainer_name = \"my_container",
        "rewrite": "```python\ndef get_object(container_name, object_name, local_file=None, return_binary=False):\n    \"\"\"\n    Retrieve a file from Swift\n    \"\"\"\n    \n    # Initialize the client with the container name\n    client = container_client.Client(container_name)\n    \n    # Get the object from the container as either binary or json data\n    if return_binary:\n        obj_data = client.get_object(object_name).read()\n        obj_data = obj_data.decode('utf-8') if isinstance(obj_data, bytes) else obj_data  # decode bytes to string if necessary\n        \n        # Save to local file if specified\n        if local_file"
    },
    {
        "original": "```python\nfrom typing import Iterator\nimport json\nimport requests\n\nclass InstagramAPI:\n    def __init__(self, access_token):\n        self.access_token = access_token\n\n    def get_location_posts(self, location: str) -> Iterator[Post]:\n        \"\"\"Get Posts which are listed by Instagram for a given Location.\n\n        :return:  Iterator over Posts of a location's posts\n\n        .. versionadded:: 4.2\n        \"\"\"\n        \n        url = f\"https://graph",
        "rewrite": "```python\nfrom typing import Iterator\nimport json\nimport requests\n\nclass Post:\n    def __init__(self, id: str, caption: str, media_url: str):\n        self.id = id\n        self.caption = caption\n        self.media_url = media_url\n\nclass InstagramAPI:\n    def __init__(self, access_token):\n        self.access_token = access_token\n\n    def get_location_posts(self, location_id: int) -> Iterator[Post]:\n        url = f\"https://graph.instagram.com/{location_id}/media?access_token={self.access_token}\"\n        \n        response = requests.get(url)\n        \n       "
    },
    {
        "original": "```python\nimport argparse\n\ndef add_peer_parser(subparsers, parent_parser):\n    \"\"\"\n    Adds argument parser for the peer command\n\n    Args:\n        subparsers: Add parsers to this subparser object\n        parent_parser: The parent argparse.ArgumentParser object\n    \"\"\"\n    \n    # Create a new parser for the 'peer' command\n    peer_parser = subparsers.add_parser('peer', help='Peer related operations',\n                                          parents=[parent_parser])\n    \n    # Add a required argument 'id",
        "rewrite": "```python\nimport argparse\n\ndef add_peer_parser(subparsers, parent_parser):\n    \"\"\"\n    Adds argument parser for the peer command.\n\n    Args:\n        subparsers: Add parsers to this subparser object.\n        parent_parser: The parent argparse.ArgumentParser object.\n    \"\"\"\n    \n    # Create a new parser for the 'peer' command and inherit from the parent parser\n    peer_parser = subparsers.add_parser('peer', help='Peer related operations', parents=[parent_parser])\n    \n    # Add a required argument 'id'\n    peer_group = peer_parser.add_argument_group('Peer Arguments')\n    peer_group.add_argument('-i', '--"
    },
    {
        "original": "```python\nclass LaunchFailure(Exception):\n    def __init__(self, error_code, error_message):\n        self.error_code = error_code\n        self.error_message = error_message\n        super().__init__(f\"Error Code: {error_code}, Error Message: {error_message}\")\n\n\nclass SystemMessage:\n    def _parse_launch_error(self, data):\n        \"\"\"\n        Parses a LAUNCH_ERROR message and returns a LaunchFailure object.\n\n        :type data: dict\n        :rtype:",
        "rewrite": "```python\nclass LaunchFailure(Exception):\n    \"\"\"Raised when a launch fails.\"\"\"\n    def __init__(self, error_code, error_message):\n        self.error_code = error_code\n        self.error_message = error_message\n        super().__init__(f\"Error Code: {error_code}, Error Message: {error_message}\")\n\n\nclass SystemMessage:\n    def _parse_launch_error(self, data: dict) -> LaunchFailure:\n        \"\"\"Parses a LAUNCH_ERROR message and returns a LaunchFailure object.\"\"\"\n        return LaunchFailure(data[\"error_code\"], data[\"error_message\"])\n```\n\nIn this revised code:\n\n1. I"
    },
    {
        "original": "```python\ndef validate_timeout_or_zero(option, value):\n    \"\"\"\n    Validates a timeout specified in milliseconds returning \n    a value in floating point seconds for the case where None is an error \n    and 0 is valid. Setting the timeout to nothing in the URI string is a \n    config error.\n    \n    Args:\n        option (str): The name of the option being validated.\n        value (int or None): The value of the option being validated.\n\n    Returns:\n        float:",
        "rewrite": "```python\ndef validate_timeout_or_zero(option, value):\n    if value is None:\n        raise ValueError(f\"Invalid {option} value: None\")\n    elif not isinstance(value, int) or value < 0:\n        raise ValueError(f\"Invalid {option} value: {value}\")\n    return float(value) / 1000\n```"
    },
    {
        "original": "```python\ndef list_storage_services(conn=None, call=None):\n    \"\"\"\n    This function lists VMs on the Azure account with full information.\n    \n    Parameters:\n    conn (object): Connection object \n    call (function): Function to make API calls\n    \n    Returns:\n    list: A list of dictionaries containing information about the VMs\n    \"\"\"\n    \n    # Initialize an empty list to store the results\n    results = []\n    \n    # Check if connection and call are provided\n    if",
        "rewrite": "```python\ndef list_storage_services(conn=None, call=None):\n    \"\"\"\n    Lists storage services on the Azure account with full information.\n\n    Args:\n        conn (object): Connection object\n        call (function): Function to make API calls\n\n    Returns:\n        list: A list of dictionaries containing information about the storage services\n    \"\"\"\n    \n    if not conn or not call:\n        raise ValueError(\"Both connection and call must be provided\")\n\n    results = []\n    \n    # Assuming 'call' function has a method to get storage services, \n    # we'll use it here. Replace this with actual implementation.\n    \n    # For"
    },
    {
        "original": "```python\ndef list_nodes_full(kwargs=None, call=None):\n    \"\"\"\n    All information available about all nodes should be returned in this function.\n    The fields in the list_nodes() function should also be returned,\n    even if they would not normally be provided by the cloud provider.\n\n    This is because some functions both within Salt and 3rd party will break if an expected field is not present.\n    This function is normally called with the -F option:\n    \n        salt-cloud -F\n\n",
        "rewrite": "```python\ndef list_nodes_full(kwargs=None, call=None):\n    if kwargs is None:\n        kwargs = {}\n    if call is None:\n        call = {}\n    return {\n        'node_list': [\n            # Add fields that are not normally provided by the cloud provider here\n            # For example:\n            {'id': 'node_id', 'name': 'node_name', 'provider': 'cloud_provider'}\n        ]\n    }\n```"
    },
    {
        "original": "```python\nimport random\n\nclass SentCode:\n    def __init__(self, code):\n        self.code = code\n\nclass CodeRequestSender:\n    def __init__(self):\n        self.codes = {}\n\n    async def send_code_request(self, phone, *, force_sms=False):\n        \"\"\"\n        Sends a code request to the specified phone number.\n\n        Args:\n            phone (`str` | `int`):\n                The phone to which the code will be sent.\n\n            force_sms (`bool`,",
        "rewrite": "```python\nimport random\nimport asyncio\n\nclass SentCode:\n    def __init__(self, code):\n        self.code = code\n\nclass CodeRequestSender:\n    def __init__(self):\n        self.codes = {}\n\n    async def send_code_request(self, phone: str | int, *, force_sms: bool = False) -> SentCode:\n        \"\"\"\n        Sends a code request to the specified phone number.\n\n        Args:\n            phone (str | int): The phone to which the code will be sent.\n            force_sms (bool): Whether to force sending via SMS. Defaults to False.\n\n        Returns:\n            SentCode:"
    },
    {
        "original": "```python\nclass NetworkController:\n    def _set_flow_entry(self, datapath, actions, in_port, dst, src=None):\n        \"\"\"\n        Set a flow entry.\n\n        Args:\n            datapath (str): The data path.\n            actions (list): A list of actions to be taken when the flow entry is matched.\n            in_port (int): The input port number.\n            dst (str): The destination IP address.\n            src (str, optional): The source IP address",
        "rewrite": "```python\nclass NetworkController:\n    def set_flow_entry(self, datapath, actions, in_port, dst, src=None):\n        \"\"\"\n        Set a flow entry.\n\n        Args:\n            datapath (str): The data path.\n            actions (list): A list of actions to be taken when the flow entry is matched.\n            in_port (int): The input port number.\n            dst (str): The destination IP address.\n            src (str, optional): The source IP address. Defaults to None.\n        \"\"\"\n```"
    },
    {
        "original": "```python\ndef set_xlabels(label=None, **kwargs):\n    \"\"\"\n    Label the x axis on the bottom row of the grid.\n    \n    Parameters:\n    label (str or list, optional): The x tick labels. Defaults to None.\n    **kwargs: Additional keyword arguments for matplotlib's set_xticklabels function.\n    \n    Returns:\n    matplotlib.axes.AxesLabelList: The x tick labels object.\n    \"\"\"\n\nimport matplotlib.pyplot as plt\n\ndef solve_problem():\n\u00a0\u00a0\u00a0\u00a0fig,",
        "rewrite": "```python\nimport matplotlib.pyplot as plt\n\ndef set_xlabels(label=None, **kwargs):\n    \"\"\"\n    Label the x axis on the bottom row of the grid.\n    \n    Parameters:\n    label (str or list, optional): The x tick labels. Defaults to None.\n    **kwargs: Additional keyword arguments for matplotlib's set_xticklabels function.\n    \n    Returns:\n    matplotlib.axes.AxesLabelList: The x tick labels object.\n    \"\"\"\n    \n    return plt.gca().set_xticklabels(label, **kwargs)\n\ndef solve_problem():\n    \n    import numpy as np\n    \n     # Generate sample data\n     x = np"
    },
    {
        "original": "```python\nclass Generator:\n    def __init__(self, force_generator=False):\n        self.force_generator = force_generator\n\n    def blockvisit(self, nodes, frame):\n        \"\"\"\n        Visit a list of nodes as block in a frame.  \n        If the current frame is no buffer a dummy ``if 0: yield None`` is written automatically\n        unless the force_generator parameter is set to False.\n        \n        Parameters:\n            nodes (list): A list of nodes to visit.\n           ",
        "rewrite": "```python\nclass Generator:\n    def __init__(self, force_generator=False):\n        self.force_generator = force_generator\n\n    def block_visit(self, nodes, frame):\n        if not frame.is_buffer and not self.force_generator:\n            yield from (None for _ in nodes)\n            return\n\n        for node in nodes:\n            # process the node here\n            pass  # replace with actual node processing code\n```\n\nNote: I've made the following changes:\n\n- Renamed `blockvisit` to `block_visit` to follow Python's conventional naming style.\n- Replaced the docstring with a more concise description.\n-"
    },
    {
        "original": "```\nclass DefaultValueError(Exception):\n    pass\n\nclass Renderer:\n    def __init__(self, value_class):\n        self.value_class = value_class\n\n    def BuildDefaultValue(self, value_cls):\n        \"\"\"Renders default value of a given class.\n\n        Args:\n          value_cls: Default value of this class will be rendered. This class has to\n            be (or to be a subclass of) a self.value_class (i.e. a class that this\n            renderer is capable of",
        "rewrite": "```python\nclass DefaultValueError(Exception):\n    pass\n\nclass Renderer:\n    def __init__(self, value_class):\n        self.value_class = value_class\n\n    def build_default_value(self, value_cls: type) -> object:\n        \"\"\"Builds the default value of a given class.\n\n        Args:\n            value_cls (type): The class for which to build the default value.\n\n        Raises:\n            DefaultValueError: If the given class does not match self.value_class.\n            TypeError: If an incompatible input is provided to build_default_value method.\n        \"\"\"\n        \n        if not issubclass(value_cls, self.value_class):\n            raise"
    },
    {
        "original": "```python\nfrom PIL import Image\nimport io\n\nclass Picture:\n    def add_picture(self, image_path_or_stream, width=None, height=None):\n        \"\"\"\n        Return a new picture shape added in its own paragraph at the end of\n        the document. The picture contains the image at\n        *image_path_or_stream*, scaled based on *width* and *height*. If\n        neither width nor height is specified, the picture appears at its\n        native size. If only one",
        "rewrite": "```python\nfrom PIL import Image\nimport io\n\nclass Picture:\n    def __init__(self):\n        self.pictures = []\n\n    def add_picture(self, image_path_or_stream, width=None, height=None):\n        image = Image.open(image_path_or_stream)\n        \n        if width and height:\n            image.thumbnail((width, height))\n        elif width or height:\n            if width:\n                ratio = width / image.width\n                new_width = int(image.width * ratio)\n                new_height = int(image.height * ratio)\n                image.thumbnail((new_width, new_height))\n            else:\n                ratio = height / image.height\n"
    },
    {
        "original": "```python\nimport asyncio\nfrom asgi_tools import App, Response\n\nclass WebsocketHandler:\n    async def process_request(self, path, headers):\n        app = App()  # create a new ASGI application instance\n\n        # run the ASGI application and wait for either accept or close event\n        await app(scope={\"type\": \"http\"}, receive=asyncio.UPSTREAM_CLOSED) or \\\n               await app(scope={\"type\": \"websocket\"}, receive=asyncio.WEBSOCKET",
        "rewrite": "```python\nimport asyncio\nfrom asgi_tools import App, Response\n\nclass WebsocketHandler:\n    async def process_request(self, path, headers):\n        app = App()\n\n        try:\n            await app(scope={\"type\": \"http\"}, receive=asyncio.UPSTREAM_CLOSED)\n        except Exception as e:\n            print(f\"HTTP request error: {e}\")\n\n        try:\n            await app(scope={\"type\": \"websocket\"}, receive=asyncio.WEBSOCKET_ACCEPT)\n        except Exception as e:\n            print(f\"Websocket connection error: {e}\")\n```"
    },
    {
        "original": "```python\ndef queue_instances(instances):\n    \"\"\"\n    Queue a set of instances to be provisioned later. Expects a list.\n    \n    Currently this only queries node data, and then places it in the cloud\n    cache (if configured). If the salt-cloud-reactor is being used, these\n    instances will be automatically provisioned using that.\n    \n    For more information about the salt-cloud-reactor, see:\n    \n    https://github.com/saltstack-formulas/salt",
        "rewrite": "```python\ndef queue_instances(instances):\n    \"\"\"\n    Queue a set of instances to be provisioned later.\n\n    Args:\n        instances (list): A list of instance dictionaries\n\n    Returns:\n        None\n    \"\"\"\n    if isinstance(instances, (list, tuple)):\n        node_data = []\n        for instance in instances:\n            # Assuming each instance is a dictionary with 'node' key\n            node = instance.get('node')\n            if node and 'data' in node:\n                # Assuming 'data' contains the necessary information\n                data = node['data']\n                # If the salt-cloud-reactor is being used"
    },
    {
        "original": "```python\nimport networkx as nx\nimport itertools\n\ndef add_edge_lengths(G):\n    \"\"\"\n    Add length (meters) attribute to each edge by great circle distance between\n    nodes u and v.\n\n    Parameters\n    ----------\n    G : networkx multidigraph\n\n    Returns\n    -------\n    G : networkx multidigraph\n    \"\"\"\n\n    # Get the latitude and longitude coordinates of all nodes from the graph attributes if available,\n\t# or use a default value of 0.",
        "rewrite": "```python\nimport networkx as nx\nimport math\n\ndef add_edge_lengths(G):\n    \"\"\"\n    Add length (meters) attribute to each edge by great circle distance between nodes u and v.\n    \"\"\"\n\n    for u, v in G.edges:\n        lat1, lon1 = G.nodes[u].get('lat', 0), G.nodes[u].get('lon', 0)\n        lat2, lon2 = G.nodes[v].get('lat', 0), G.nodes[v].get('lon', 0)\n\n        # Convert latitude and longitude from degrees to radians\n        lat1, lon1,"
    },
    {
        "original": "```python\ndef ProcessHuntFlowDone(flow_obj, status_msg=None):\n    \"\"\"Notifies hunt about a given hunt-induced flow completion.\"\"\"\n    \n    # Push notification to hunt - assuming we have a HuntNotification class for this\n    from app.models import HuntNotification\n    \n    # Create the notification object with the necessary data\n    notification = HuntNotification(\n        flow_id=flow_obj.id,\n        status=status_msg or \"Flow completed successfully\"\n    )\n    \n    # Save the notification to the",
        "rewrite": "```python\ndef process_hunt_flow_done(flow_obj, status_msg=None):\n    \"\"\"Notifies hunt about a given hunt-induced flow completion.\"\"\"\n    \n    from app.models import HuntNotification\n    \n    notification = HuntNotification(\n        flow_id=flow_obj.id,\n        status=status_msg or \"Flow completed successfully\"\n    )\n    \n    notification.save()\n```\n\nI made the following changes:\n\n- Renamed the function to `process_hunt_flow_done` to follow Python's conventional naming style (lowercase with underscores).\n- Removed unnecessary comments.\n- Removed the redundant comment at the end of the function.\n- Assumed that `HuntNotification"
    },
    {
        "original": "```python\nclass VersionChecker:\n    def __init__(self, current_version, latest_version):\n        self.current_version = current_version\n        self.latest_version = latest_version\n\n    def _check_update_(self):\n        \"\"\"\n        Check if the current version of the library is outdated.\n        \n        The function splits each version into its numerical parts and \n        checks if the current version is less than the latest version. \n \t\t\n \t\tParameters:\n            ----------\n            None\n        \n \t\tReturns:\n            -------\n",
        "rewrite": "```python\nclass VersionChecker:\n    def __init__(self, current_version, latest_version):\n        self.current_version = current_version\n        self.latest_version = latest_version\n\n    def check_update(self):\n        \"\"\"\n        Check if the current version of the library is outdated.\n        \n        Parameters:\n            ----------\n            None\n        \n        Returns:\n            -------\n            bool: True if the current version is outdated, False otherwise.\n        \"\"\"\n        \n        def split_versions(version):\n            return list(map(int, version.split('.')))\n        \n        return split_versions(self.current_version) < split_versions(self.latest_version)\n```\n\nThis revised code includes a helper function"
    },
    {
        "original": "```python\nimport json\nimport wx\n\nclass WxApp(wx.App):\n    \"\"\" A simple wxPython application \"\"\"\n\n    def reifyWidget(self, parent, item):\n        \"\"\"\n        Convert a JSON description of a widget into a WxObject\n        :param parent: Parent object for the widget\n        :param item: JSON description of the widget\n        :return: The corresponding WxObject instance\n        \"\"\"\n        \n        # Define dictionary to map JSON properties to their corresponding wxWidgets",
        "rewrite": "```python\nimport json\nimport wx\n\nclass WxApp(wx.App):\n    \"\"\" A simple wxPython application \"\"\"\n\n    def reifyWidget(self, parent, item):\n        \"\"\"\n        Convert a JSON description of a widget into a WxObject\n        :param parent: Parent object for the widget\n        :param item: JSON description of the widget\n        :return: The corresponding WxObject instance or None if no valid widget exists in the JSON dictionary.\n        \"\"\"\n        \n        json_dict = item\n            \n        widgets_map = {\n            \"label\": lambda parent, value: wx.StaticText(parent, label=value),\n            \""
    },
    {
        "original": "```python\nclass Solution:\n    def as_dict(self):\n        \"\"\"\n        Json-serializable dict representation.\n        \"\"\"\n        \n    def __init__(self, n: int, k: int, max_sum: int):\n        self.n = n\n        self.k = k\n        self.max_sum = max_sum\n\n    def subarraySum(self) -> List[int]:\n        # Initialize a hashmap to store the prefix sum and its frequency\n        prefix_sum_freq = {0: 1",
        "rewrite": "```python\nclass Solution:\n    def __init__(self, n: int, k: int, max_sum: int):\n        self.n = n\n        self.k = k\n        self.max_sum = max_sum\n        self.result = None  # Initialize result variable\n\n    def subarraySum(self) -> List[int]:\n        \"\"\"\n        Returns a list of all possible subarray sums.\n        \"\"\"\n        \n        # Initialize a hashmap to store the prefix sum and its frequency\n        prefix_sum_freq = {0: 1}\n        \n        current_sum = 0\n        \n        for i in range(self.n):\n            current_sum"
    },
    {
        "original": "```python\nclass GULP:\n    def library_line(self, file_name):\n        \"\"\"\n        Specifies GULP library file to read species and potential parameters.\n        \n        Args:\n            file_name: Name of GULP library file\n\n        Returns:\n            GULP input string specifying library option\n        \"\"\"\n        \n        # Check if the input is a string\n        if not isinstance(file_name, str):\n            raise TypeError(\"File name must be a string.\")\n        \n        # Return the",
        "rewrite": "```python\nclass GULP:\n    def library_line(self, file_name):\n        \"\"\"\n        Specifies GULP library file to read species and potential parameters.\n\n        Args:\n            file_name (str): Name of GULP library file\n\n        Returns:\n            str: GULP input string specifying library option\n        \"\"\"\n        \n        if not isinstance(file_name, str):\n            raise TypeError(\"File name must be a string.\")\n        \n        return f\"@library {file_name}\"\n```\n\nI made the following changes:\n\n1. Added type hints for the `file_name` parameter and the return value.\n2. Removed unnecessary comments"
    },
    {
        "original": "```python\nclass Solution:\n    def IsCloud(self, request, bios_version, services):\n        \"\"\"\n        Test to see if we're on a cloud machine.\n        \n        Parameters:\n        request (str): The incoming HTTP request.\n        bios_version (str): The version of the BIOS.\n        services (list): A list of available services.\n\n        Returns:\n        bool: True if we're on a cloud machine, False otherwise.\n        \"\"\"\n\n    # Check if the BIOS version is 'cloud",
        "rewrite": "```python\nclass Solution:\n    def is_cloud(self, request: str, bios_version: str, services: list) -> bool:\n        \"\"\"\n        Test to see if we're on a cloud machine.\n\n        Parameters:\n        request (str): The incoming HTTP request.\n        bios_version (str): The version of the BIOS.\n        services (list): A list of available services.\n\n        Returns:\n        bool: True if we're on a cloud machine, False otherwise.\n        \"\"\"\n\n    # Check if the BIOS version is 'cloud'\n    return bios_version == 'cloud'\n```\n\nI made the following changes:\n\n- Renamed"
    },
    {
        "original": "```python\nclass Host:\n    def __init__(self, hypervisor):\n        \"\"\"\n        Initialize a host with its corresponding hypervisor.\n        \n        Args:\n            hypervisor (str): The name of the hypervisor running on this host.\n        \"\"\"\n        self.hypervisor = hypervisor\n\n    def get_local_hypervisor(self):\n        \"\"\"\n        Returns the hypervisor running on this host, and assumes a 1-1 between host and hypervisor\n        \"\"\"\n        \n# Example usage",
        "rewrite": "```python\nclass Host:\n    def __init__(self, hypervisor):\n        \"\"\"\n        Initialize a host with its corresponding hypervisor.\n        \n        Args:\n            hypervisor (str): The name of the hypervisor running on this host.\n        \"\"\"\n        self.hypervisor = hypervisor\n\n    def get_local_hypervisor(self):\n        \"\"\"Returns the local hypervisor.\"\"\"\n        \n    def __repr__(self):\n        return f\"Host(hypervisor='{self.hypervisor}')\"\n\n# Example usage\nif __name__ == \"__main__\":\n    host1 = Host(\"VMware\")\n    print(host1.get_local_h"
    },
    {
        "original": "```python\nimport numpy as np\n\nclass Structure:\n    def __init__(self, size):\n        self.size = size\n\nclass Tensor:\n    def from_values_indices(cls, values, indices, populate=False,\n                            structure=None, voigt_rank=None,\n                            vsym=True, verbose=False):\n        # Check if the number of values matches the number of indices\n        if len(values) != len(indices):\n            raise ValueError(\"Number of values does not match the number of indices\")\n\n        #",
        "rewrite": "```python\nimport numpy as np\n\nclass Structure:\n    def __init__(self, size):\n        \"\"\"\n        Initializes a structure with a given size.\n\n        Args:\n        - size (int): The size of the structure.\n        \"\"\"\n        self.size = size\n\nclass Tensor:\n    @classmethod\n    def from_values_indices(cls, values, indices, populate=False,\n                            structure=None, voigt_rank=None,\n                            vsym=True, verbose=False):\n        \"\"\"\n        Creates a tensor from given values and indices.\n\n        Args:\n            - values (list or numpy array): The values of the tensor.\n            - indices (list or"
    },
    {
        "original": "```python\ndef _raise_redirect_exceptions(response):\n    \"\"\"\n    Return the new url or None if there are no redirects.\n\n    Raise exceptions if appropriate.\n    \"\"\"\n    \n    # Check if the response is a redirect\n    if response.status_code == 301 or response.status_code == 302:\n        # Get the new URL from the Location header\n        new_url = response.headers.get('Location')\n        \n        # If there's no new URL, return None\n        if not new_url:\n",
        "rewrite": "```python\ndef _raise_redirect_exceptions(response):\n    if response.status_code in [301, 302]:\n        new_url = response.headers.get('Location')\n        if not new_url:\n            return None\n        return new_url\n    raise Exception(f\"Unexpected HTTP status code: {response.status_code}\")\n```"
    },
    {
        "original": "```python\nimport asyncio\n\nclass FutureResult:\n    pass\n\nclass MyFuture:\n    def __init__(self):\n        self._done_callback = None\n        self._result = None\n\n    async def done_callback(self, callback):\n        if self._done_callback is not None:\n            raise Exception(\"Callback already set\")\n        \n        self._done_callback = callback\n        await asyncio.sleep(0)\n        \n    async def set_result(self, result):\n        if self._done_callback is None",
        "rewrite": "```python\nimport asyncio\n\nclass FutureResult:\n    pass\n\nclass MyFuture:\n    def __init__(self):\n        self._done_callback = None\n        self._result = None\n        self._is_done = False\n\n    async def done_callback(self, callback):\n        if self._done_callback is not None:\n            raise Exception(\"Callback already set\")\n        \n        self._done_callback = callback\n        await asyncio.sleep(0)\n\n    async def set_result(self, result):\n        if not isinstance(result, FutureResult):\n            raise TypeError(\"Result must be of type FutureResult\")\n        \n        if self._done_callback is"
    },
    {
        "original": "```python\nclass Node:\n    def __init__(self, value):\n        self.value = value\n        self.children = []\n\ndef ClosureTable(model_class, foreign_key=None, referencing_class=None,\n                 referencing_key=None):\n    \"\"\"\n    Model factory for the transitive closure extension.\n    \n    Args:\n        model_class (class): The class of the nodes in the graph.\n        foreign_key (str): The name of the foreign key in the model class. Defaults to None.\n        referencing_class",
        "rewrite": "```python\nclass Node:\n    def __init__(self, value):\n        self.value = value\n        self.children = []\n        self.parent = None\n\nclass ClosureTable:\n    def __init__(self, model_class, foreign_key=None, referencing_class=None,\n                 referencing_key=None):\n        \"\"\"\n        Args:\n            model_class (class): The class of the nodes in the graph.\n            foreign_key (str): The name of the foreign key in the model class. Defaults to None.\n            referencing_class (class): The class that is being referenced by a foreign key. Defaults to None.\n            referencing_key (str): The"
    },
    {
        "original": "```python\nimport os\n\ndef check_pseudo_package(path):\n    \"\"\"\n    Verifies that a fake subpackage path for assets (notebooks, svgs,\n    pngs etc) both exists and is populated with files.\n    \"\"\"\n    \n    # Check if the path exists\n    if not os.path.exists(path):\n        return False\n    \n    # Check if the path is a directory\n    if not os.path.isdir(path):\n        return False\n    \n    # Check if the directory is populated with",
        "rewrite": "```python\nimport os\n\ndef check_pseudo_package(path):\netro \"\"\"\nVerifies that a fake subpackage path for assets (notebooks, svgs,\npngs etc) both exists and is populated with files.\n\"\"\"\n    \n    # Check if the path exists\n    if not os.path.exists(path):\n        return False\n    \n    # Check if the path is a directory\n    if not os.path.isdir(path):\n        return False\n    \n    # Check if the directory is populated with files\n    return len(os.listdir(path)) > 0 and any(os.path.isfile(file) for file in os.listdir(path))\n```\n\nThis revised code"
    },
    {
        "original": "```python\nfrom pika import BasicProperties\nfrom pika.adapters.blocking_connection import BlockingChannel\n\ndef setup_exchange(self, exchange_name):\n    \"\"\"\n    Setup the exchange on RabbitMQ by invoking the Exchange.Declare RPC\n    command. When it is complete, the on_exchange_declareok method will\n    be invoked by pika.\n\n    :param str|unicode exchange_name: The name of the exchange to declare\n    \"\"\"\n\n    # Credentials for RabbitMQ server, you should replace",
        "rewrite": "```python\nfrom pika import BasicProperties, ConnectionParameters\n\nclass RabbitMQSetup:\n    def __init__(self, host='localhost', username='guest', password='guest'):\n        self.host = host\n        self.username = username\n        self.password = password\n\n    def setup_exchange(self, exchange_name):\n        \"\"\"\n        Setup the exchange on RabbitMQ by invoking the Exchange.Declare RPC command.\n        \n        :param str exchange_name: The name of the exchange to declare\n        \"\"\"\n        \n        connection_parameters = ConnectionParameters(\n            host=self.host,\n            credentials=self._get_credentials(),\n            heartbeat_interval=0  # disable"
    },
    {
        "original": "```python\nclass Solution:\n    def evaluate(self, expression):\n        \"\"\"\n        Evaluates the mathematical expression given across multiple people.\n        \n        Args:\n            expression (str): The mathematical expression as a string.\n            \n        Returns:\n            int: The result of the evaluation.\n        \"\"\"\n        \n        # Split the input string into variables and expressions\n        vars = []\n        tmp = ''\n        for char in expression:\n            if char == '(' or char == ')':\n                if tmp and '@' not",
        "rewrite": "```python\nclass Solution:\n    def evaluate(self, expression: str) -> int:\n        vars = []\n        tmp = ''\n        for char in expression:\n            if char in ['(', ')']:\n                if tmp and '@' not in tmp:\n                    vars.append(tmp)\n                    tmp = ''\n            else:\n                tmp += char\n        if tmp and '@' not in tmp:\n            vars.append(tmp)\n        \n        # Replace variables with their values\n        for i, var in enumerate(vars):\n            expression = expression.replace(var, f'#{i}')\n        \n        # Evaluate the expression\n        return eval(expression)\n```\n\nThis revised"
    },
    {
        "original": "```python\nclass ConsumerGroupManager:\n    def __init__(self):\n        # Initialize an empty dictionary to store consumer group information\n        self.consumer_groups = {}\n\n    def xgroup_setid(self, name, groupname, id):\n        \"\"\"\n        Set the consumer group last delivered ID to something else.\n        \n        Args:\n            name (str): name of the stream.\n            groupname (str): name of the consumer group.\n            id (int): ID of the last item in the",
        "rewrite": "```python\nclass ConsumerGroupManager:\n    def __init__(self):\n        self.consumer_groups = {}\n\n    def set_group_last_delivered_id(self, stream_name, group_name, last_delivered_id):\n        \"\"\"\n        Sets the last delivered ID for a consumer group in a stream.\n        \n        Args:\n            stream_name (str): Name of the stream.\n            group_name (str): Name of the consumer group.\n            last_delivered_id (int): ID of the last item delivered.\n        \"\"\"\n        if stream_name not in self.consumer_groups:\n            self.consumer_groups[stream_name] = {}\n        \n        if isinstance(last_del"
    },
    {
        "original": "```python\nfrom werkzeug.exceptions import RequestedRangeNotSatisfiable\nimport re\n\nclass RangeWrapper:\n    def __init__(self, response):\n        self.response = response\n\nclass RangeRequestHandler:\n    def _process_range_request(self, environ, complete_length=None, accept_ranges=None):\n        # Check if Accept-Ranges header is valid\n        if accept_ranges and accept_ranges.lower() != 'bytes':\n            return False\n\n        # Parse Range header\n        range_header = environ",
        "rewrite": "```python\nfrom werkzeug.exceptions import RequestedRangeNotSatisfiable\nimport re\n\nclass RangeWrapper:\n    def __init__(self, response):\n        self.response = response\n\nclass RangeRequestHandler:\n    def _process_range_request(self, environ, complete_length=None, accept_ranges=None):\n        # Check if Accept-Ranges header is valid\n        if accept_ranges and accept_ranges.lower() != 'bytes':\n            return False\n\n        # Parse Range header\n        range_header = environ.get('HTTP_RANGE', '')\n\n        # Validate and parse the range request format\n        parts = [x.strip() for x in range_header"
    },
    {
        "original": "```python\nfrom typing import List\n\nclass Solution:\n    def __init__(self):\n        pass\n\n    def combination_sum(self, candidates: List[int], target: int) -> List[List[int]]:\n        \"\"\"\n        Given an array of candidate numbers (nums) and a target number (target), \n        find all unique combinations in nums where the candidate numbers sums to target.\n        \n        The same repeated number may be chosen from nums. Note that results are not \n        required to be sorted or",
        "rewrite": "```python\nfrom typing import List\n\nclass Solution:\n    def combination_sum(self, candidates: List[int], target: int) -> List[List[int]]:\n        res = []\n        self.dfs(sorted(candidates), target, [], res)\n        return res\n\n    def dfs(self, nums: List[int], remaining: int, path: List[int], res: List[List[int]]) -> None:\n        if remaining == 0:\n            res.append(path)\n            return\n        for i in range(len(nums)):\n            if i > 0 and nums[i] == nums[i - 1]:\n                continue\n            if nums[i]"
    },
    {
        "original": "```python\nclass StatEntry:\n    def __init__(self, inode):\n        self.inode = inode\n\n\nclass TSKFile:\n    def __init__(self, inode):\n        self.inode = inode\n\n\nclass TSKAttribute:\n    def __init__(self, stream_id):\n        self.stream_id = stream_id\n\n\ndef MakeStatResponse(tsk_file, tsk_attribute=None, append_name=None):\n    \"\"\"\n    Given a TSK info object make a StatEntry.\n\n    Args",
        "rewrite": "```python\nclass StatEntry:\n    def __init__(self, inode, file_name=None):\n        self.inode = inode\n        self.file_name = file_name\n\n\nclass TSKFile:\n    def __init__(self, inode):\n        self.inode = inode\n\n\nclass TSKAttribute:\n    def __init__(self, stream_id):\n        self.stream_id = stream_id\n\n\ndef make_stat_response(tsk_file: TSKFile, tsk_attribute: TSKAttribute = None, append_name=None) -> StatEntry:\n    \"\"\"\n    Makes a StatEntry given TSK info objects.\n    \n    Args:\n    t"
    },
    {
        "original": "```python\nfrom pgmpy.factors.discrete import TabularCPD\n\nclass CPD:\n    def __init__(self, variable, num_states, values, evidence=None, evidence_card=None):\n        \"\"\"\n        Initialize the Conditional Probability Distribution (CPD).\n\n        Parameters\n        ----------\n        variable : str\n            The name of the variable.\n        num_states : int\n            The number of states for the variable.\n        values : list of lists\n            A 2D list containing",
        "rewrite": "```python\nfrom pgmpy.factors.discrete import TabularCPD\n\nclass CPD:\n    def __init__(self, variable, num_states, values, evidence=None, evidence_card=None):\n        self.variable = variable\n        self.num_states = num_states\n        self.values = values\n        if evidence is not None and evidence_card is not None:\n            self.evidence = evidence\n            self.evidence_card = evidence_card\n            if len(evidence) != len(evidence_card):\n                raise ValueError(\"Evidence and Evidence Card must have the same length\")\n            for i in range(len(evidence)):\n                if"
    },
    {
        "original": "```python\nclass TelegramChatManager:\n    def join_chat(self, chat_id: str) -> dict:\n        \"\"\"Use this method to join a group chat or channel.\n\n        Args:\n            chat_id (``str``):\n                Unique identifier for the target chat in form of a *t.me/joinchat/* link or username of the target\n                channel/supergroup (in the format @username).\n\n        Returns:\n            On success, returns a dictionary representing the result.\n\n        Raises",
        "rewrite": "```python\nclass TelegramChatManager:\n    def join_chat(self, chat_id: str) -> dict:\n        if not isinstance(chat_id, str):\n            raise ValueError(\"chat_id must be a string\")\n        if not chat_id.startswith('t.me/joinchat/') and not chat_id.startswith('@'):\n            raise ValueError(\"Invalid chat id format. It should be in the form of 't.me/joinchat/<link>' or '@<username>'\")\n\n        # Add your logic to join the chat here\n        # For example, you can use the python-telegram-bot library to send a request to join the chat\n       "
    },
    {
        "original": "```python\n# Define a dictionary that maps renderer names to their docstrings\nrenderer_docs = {\n    'cheetah': \"Cheetha Renderer\",\n    'jinja': \"Jinja Renderer\",\n    # Add more renderers as needed\n}\n\ndef renderer_doc(*args):\n    \"\"\"\n    Return the docstrings for all renderers. Optionally, specify a renderer or a function to narrow the selection.\n    \n    The strings are aggregated into a single document on the master for easy reading.\n",
        "rewrite": "```python\n# Define a dictionary that maps renderer names to their docstrings\nrenderer_docs = {\n    'cheetah': \"Cheetha Renderer\",\n    'jinja': \"Jinja Renderer\",\n}\n\ndef renderer_doc(*args):\n    if not args:\n        return '\\n\\n'.join(renderer_docs.values())\n    \n    result = []\n    \n    for arg in args:\n        if arg in renderer_docs:\n            result.append(f\"{arg}: {renderer_docs[arg]}\")\n        elif callable(arg):\n            # Check if the function has a docstring and is a renderer\n            func_name = arg.__name__\n            func_doc"
    },
    {
        "original": "```python\nclass StreamingContext:\n    def __init__(self):\n        # Initialize offset tracking variables\n        self.consumer_offset = None\n        self.high_water_mark = None\n\n    def set_initial_offsets(self, initial_consumer_offset):\n        # Set the initial offsets for the consumer and high water mark\n        self.consumer_offset = initial_consumer_offset\n        self.high_water_mark = initial_consumer_offset\n\n    def update_high_water_mark(self, new_high_water_mark):\n        # Update the high water mark",
        "rewrite": "```python\nclass StreamingContext:\n    def __init__(self):\n        self.consumer_offset = None\n        self.high_water_mark = None\n\n    def set_initial_offsets(self, initial_consumer_offset):\n        self.consumer_offset = initial_consumer_offset\n        self.high_water_mark = initial_consumer_offset\n\n    def update_high_water_mark(self, new_high_water_mark):\n        if 0 <= new_high_water_mark <= self.consumer_offset:\n            self.high_water_mark = new_high_water_mark\n\nclass ConsumerOffsetUpdater(StreamingContext):\n    # Use type hinting for better clarity on types used in function parameters or return values\n    def set_con"
    },
    {
        "original": "```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\ndef parametric_mean_function(max_iters=100, optimize=True, plot=True):\n    \"\"\"\n    A linear mean function with parameters that we'll learn alongside the kernel\n    \"\"\"\n    \n    # Define the model's parameters\n    m = 4.0  # bias term (intercept)\n    b = 2.0  # slope coefficient\n    \n   \nbasketball_players_data = {'player1': [5.0,",
        "rewrite": "```python\nimport numpy as np\nfrom scipy.optimize import minimize\nimport matplotlib.pyplot as plt\n\ndef parametric_mean_function(max_iters=100, optimize=True, plot=False):\n    # Define the model's parameters to be optimized\n    m_0 = 1.0\n    b_0 = 0.0\n    \n    def mean_function(x):\n        return m_0 * x + b_0\n    \n    # Sample data (basketball players' heights)\n    basketball_players_data = {\n        'player1': [6.10],\n        'player2': [6.11],\n        'player3': ["
    },
    {
        "original": "```python\ndef get_network_adapter_type(adapter_type):\n    \"\"\"\n    Return the network adapter type.\n\n    Args:\n        adapter_type (str): The adapter type from which to obtain the network adapter type.\n    \n    Returns:\n        str: The network adapter type.\n\n    For simplicity, we'll assume that different types of adapters have different icons.\n    This function simply returns a string-based representation of the icon for each type of adapter.\n    \n    Here's a simple mapping between some common types of adapters",
        "rewrite": "```python\ndef get_network_adapter_type(adapter_type):\n    network_adapter_types = {\n        'ETHERNET': 'LocalAreaNetwork',  # Ethernet adapter icon\n        'WIFI': 'GenericWireless',  # Wi-Fi adapter icon\n        'MOBILE_BROADBAND': 'CellularNetwork',  # Mobile broadband adapter icon\n        'VIRTUAL': 'VirtualPrivateNetwork'  # Virtual adapter icon\n    }\n    \n    return network_adapter_types.get(adapter_type.upper(), \"Unknown\")\n```"
    },
    {
        "original": "```python\nimport pickle\n\nclass PickleSaver:\n    def __init__(self, obj):\n        self.obj = obj\n\n    def pickle_dump(self):\n        \"\"\"\n        Save the status of the object in pickle format.\n        Returns 0 if success\n        \"\"\"\n        try:\n            with open('object_status.pkl', 'wb') as f:\n                pickle.dump(self.obj, f)\n            return 0\n        except Exception as e:\n            print(f\"Error: {e}\")\n",
        "rewrite": "```python\nimport pickle\n\nclass PickleSaver:\n    def __init__(self, obj):\n        self.obj = obj\n\n    def pickle_dump(self):\n        try:\n            with open('object_status.pkl', 'wb') as f:\n                pickle.dump(self.obj, f)\n            return 0\n        except Exception as e:\n            print(f\"Error: {e}\")\n            return None\n```"
    },
    {
        "original": "```\nimport time\nfrom datetime import datetime, timedelta\n\nclass TimestampConverter:\n    def _MakeTimestamp(self, start=None, end=None):\n        \"\"\"Create a timestamp using a start and end time.\n\n        Args:\n          start: Start timestamp.\n          end: End timestamp.\n\n        Returns:\n          A tuple (start, time) of converted timestamps or None for all time.\n        \"\"\"\n\n        if start is None and end is None:\n            return (None,),\ttime\n\n        if isinstance(start,",
        "rewrite": "```python\nimport time\nfrom datetime import datetime, timedelta\n\nclass TimestampConverter:\n    def make_timestamp(self, start=None, end=None):\n        \"\"\"Create a timestamp using a start and end time.\n\n        Args:\n          start: Start timestamp.\n          end: End timestamp.\n\n        Returns:\n          A tuple (start, end) of converted timestamps or None for all time.\n        \"\"\"\n\n        if start is None and end is None:\n            return (None,), time.time()\n\n        if isinstance(start, str):\n            try:\n                start = datetime.strptime(start, \"%Y-%m-%d %H:%M:%S\")\n            except"
    },
    {
        "original": "```python\nfrom typing import Iterator, TypeVar, Callable\nimport itertools\n\nT = TypeVar('T')\n\ndef loop_until(\n    self,\n    condition: Callable[[object], bool] = None,\n    timeout: float = 0) -> Iterator[T]:\n    \"\"\"\n    Iterate until condition is met, with optional timeout in seconds.\n    The yielded value is that of the object that did not meet the condition when timed out.\n\n     Args:\n         condition: Predicate function that is tested after",
        "rewrite": "```python\nfrom typing import Iterator, TypeVar, Callable\nimport itertools\n\nT = TypeVar('T')\n\ndef loop_until(\n    condition: Callable[['self, T], bool] = None,\n    timeout: float = 0) -> Iterator['self.type']:\n    def decorator(cls):\n        class LoopUntilIterator:\n            def __init__(self, cls):\n                self.cls = cls\n\n            async def __anext__(self):\n                if condition is not None:\n                    obj = await self.next_Object()\n                    while not condition(obj):\n                        if timeout != 0 and (await self.timeout_ts()) > timeout:\n                           "
    },
    {
        "original": "```python\nimport math\n\ndef _calc_taud(w, aod700, p):\n    \"\"\"\n    Calculate the taud coefficient.\n    \n    Parameters:\n    w (float): The wind speed in m/s.\n    aod700 (float): The aerosol optical depth at 700 nm.\n    p (float): The pressure in hPa.\n    \n    Returns:\n    float: The taud coefficient value.\n    \n    Formula:\n        \\tau_{d} = 0.0009",
        "rewrite": "```python\nimport math\n\ndef calc_taud(w, aod700, p):\n    \"\"\"\n    Calculate the taud coefficient.\n    \n    Parameters:\n    w (float): The wind speed in m/s.\n    aod700 (float): The aerosol optical depth at 700 nm.\n    p (float): The pressure in hPa.\n    \n    Returns:\n    float: The taud coefficient value.\n     \"\"\"\n    \n   return 0.0009 \n```"
    },
    {
        "original": "```python\nclass Chunk:\n    \"\"\" Represents a chunk of data. \"\"\"\n\n    def __init__(self, data, offset):\n        self.data = data\n        self.offset = offset\n\n\nclass Storage:\n    \"\"\" Toy disk storage sidecar object for file system operations in Hypre implementations. \"\"\"\n\n    def __init__(self):\n        self.files = {}\n\n    def create_file(self, name, size):\n        \"\"\" Creates a new file with the given name and size.\n\n        Args:\n          name (",
        "rewrite": "\n\n```python\nclass Chunk:\n    \"\"\"Represents a chunk of data with its offset.\"\"\"\n\n    def __init__(self, data: bytes, offset: int):\n        \"\"\"\n        Initializes a new Chunk instance.\n\n        Args:\n            data (bytes): The chunk's data.\n            offset (int): The chunk's offset.\n        \"\"\"\n        self.data = data\n        self.offset = offset\n\n\nclass Storage:\n    \"\"\"A toy disk storage sidecar object for file system operations.\"\"\"\n\n    def __init__(self):\n        \"\"\"\n        Initializes a new Storage instance.\n\n"
    },
    {
        "original": "```python\nimport math\n\ndef pointer_gate(num_qubits, U):\n    \"\"\"\n    Make a pointer gate on `num_qubits`. The one-qubit gate U will act on the\n    qubit addressed by the pointer qubits interpreted as an unsigned binary\n    integer.\n\n    There are P = floor(lg(num_qubits)) pointer qubits, and qubits numbered\n\n        N - 1\n        N - 2\n        ...\n        N - P\n\n    are those",
        "rewrite": "```python\nimport math\nimport numpy as np\n\ndef pointer_gate(num_qubits, U):\n    if not isinstance(U, np.ndarray) or U.shape != (2, 2):\n        raise ValueError(\"U must be a 2x2 numpy array\")\n\n    P = math.floor(math.log(num_qubits, 2))\n    if num_qubits < 2**P:\n        raise ValueError(\"num_qubits must be at least 2^P\")\n\n    pointer_qubits = num_qubits - P - 1\n    target_index = int(''.join(map(str, range(pointer_qubits))), 2)\n\n"
    },
    {
        "original": "```python\nimport time\nimport subprocess\n\ndef delete(name, timeout=90):\n    \"\"\"\n    Delete the named service\n\n    Args:\n\n        name (str): The name of the service to delete\n\n        timeout (int):\n            The time in seconds to wait for the service to be deleted before\n            returning. This is necessary because a service must be stopped\n            before it can be deleted. Default is 90 seconds\n\n            .. versionadded:: 2017.7.9,",
        "rewrite": "```python\nimport time\nimport subprocess\n\ndef delete_service(name, timeout=90):\n    try:\n        # Stop the service\n        subprocess.run(f\"sudo service {name} stop\", shell=True, check=True)\n        \n        # Wait for the service to be stopped before deleting it\n        start_time = time.time()\n        while True:\n            if not subprocess.run(f\"sudo systemctl is-active {name}\", shell=True, stdout=subprocess.DEVNULL).returncode:\n                if time.time() - start_time < timeout:\n                    time.sleep(1)\n                else:\n                    raise TimeoutError(f\"Service {name} did not"
    },
    {
        "original": "```python\nimport json\n\ndef _parse_canonical_int32(doc):\n    \"\"\"\n    Decode a JSON int32 to python int.\n    \n    :param doc: A JSON string representing an int32 value.\n    :return: The decoded integer value.\n    \"\"\"\n    \n    # Load the JSON string into a Python object\n    obj = json.loads(doc)\n    \n    # Check if the object is an integer\n    if isinstance(obj, int):\n        return obj\n    \n    # If not, check",
        "rewrite": "```python\nimport json\n\ndef _parse_canonical_int32(doc):\n    \"\"\"\n    Decode a JSON int32 to python int.\n    \n    :param doc: A JSON string representing an int32 value.\n    :return: The decoded integer value.\n    \"\"\"\n    \n    return json.loads(doc) if isinstance(json.loads(doc), int) else None\n```"
    },
    {
        "original": "```python\nfrom math import sqrt\n\nclass Solution:\n    def keep_path(self, path):\n        \"\"\"\n        Given a path, returns True if the path should be kept, False if it should be cut.\n        \n        The decision to keep or cut a path is based on the following rules:\n        - If the length of the path is less than 2, it should be kept.\n        - If the length of the path is greater than or equal to 2 and less than or equal to",
        "rewrite": "```python\nfrom math import sqrt\n\nclass Solution:\n    def keep_path(self, path):\n        return len(path) < 2 or (2 <= len(path) <= 5 and all(1 <= x <= 10 for x in path))\n```\n\nNote: Since the problem statement contains a range error (\"less than or equal to\" is missing an upper bound), I've assumed the upper bound to be 5 based on the context. If this is incorrect, please provide more information about the problem."
    },
    {
        "original": "```python\ndef get_metric_value_by_labels(messages, _metric, _m, metric_suffix):\n    \"\"\"\n    :param messages: dictionary as metric_name: {labels: {}, value: 10}\n    :param _metric: dictionary as {labels: {le: '0.001', 'custom': 'value'}}\n    :param _m: str as metric name\n    :param metric_suffix: str must be in (count or sum)\n    :return: value of the metric",
        "rewrite": "```python\ndef get_metric_value_by_labels(messages, metric, m, metric_suffix):\n    if metric_suffix not in ['count', 'sum']:\n        raise ValueError(\"metric_suffix must be either 'count' or 'sum'\")\n\n    labels = metric.get(m)\n    if labels is None:\n        raise KeyError(f\"Metric '{m}' not found in the dictionary\")\n\n    value = messages.get(m)\n    if value is None:\n        raise KeyError(f\"Metric '{m}' not found in the messages dictionary\")\n\n    return value['value']\n```"
    },
    {
        "original": "```python\nfrom math import gcd\n\nclass Solution:\n    def nthMagpie(self, n, k):\n        lcm = lambda x, y: x * y // gcd(x, y)\n        min_val = (n // k) * lcm(k, n % k)\n        max_val = (n - 1) // (k - 1) * lcm(k - 1, n % (k - 1)) + lcm(k - 1, max(0,n%(",
        "rewrite": "```python\nfrom math import gcd\n\nclass Solution:\n    def nthMagpie(self, n, k):\n        lcm = lambda x, y: x * y // gcd(x, y)\n        min_val = (n // k) * lcm(k, n % k)\n        max_val = (n - 1) // (k - 1) * lcm(k - 1, n % (k - 1)) + lcm(k - 1, max(0,n % k))\n        return min_val + ((max_val - min_val) // k + bool((max_val - min_val) % k))"
    },
    {
        "original": "```python\nclass TransactionLink:\n    def __init__(self, txid, output):\n        self.txid = txid\n        self.output = output\n\nclass CodexProcessor:\n    def get_outputs_filtered(self, owner, spent=None):\n        # This is a placeholder for the actual data retrieval logic.\n        # In a real-world scenario, this would likely involve interacting with a database or API.\n        if spent is None:\n            # Return all outputs by default\n            return [\n               ",
        "rewrite": "\n\n```python\nclass TransactionOutput:\n    \"\"\"Represents a transaction output.\"\"\"\n    def __init__(self, output_id):\n        self.output_id = output_id\n\nclass TransactionLink:\n    \"\"\"Represents a link between a transaction ID and an output.\"\"\"\n    def __init__(self, txid: str, output: TransactionOutput):\n        \"\"\"\n        Initializes a new instance of the TransactionLink class.\n\n        Args:\n            txid (str): The transaction ID.\n            output (TransactionOutput): The associated transaction output.\n        \"\"\"\n        self"
    },
    {
        "original": "```python\nclass Api:\n    def __init__(self, name):\n        self.name = name\n        self.endpoints = {}\n\n    def add_endpoint(self, endpoint_name):\n        if endpoint_name not in self.endpoints:\n            self.endpoints[endpoint_name] = True\n\n    def owns_endpoint(self, endpoint):\n        \"\"\"Tests if an endpoint name (not path) belongs to this Api.  Takes\n        in to account the Blueprint name part of the endpoint name.\n\n        :param",
        "rewrite": "```python\nclass Api:\n    def __init__(self, name):\n        self.name = name\n        self.endpoints = {}\n\n    def add_endpoint(self, endpoint_name):\n        if endpoint_name not in self.endpoints:\n            self.endpoints[endpoint_name] = True\n\n    def owns_endpoint(self, endpoint):\n        return endpoint.startswith(self.name + '.')\n```\n\nThis revised code simplifies the `owns_endpoint` method to directly check if the given `endpoint` starts with the current API's name followed by a dot. This approach is more efficient and accurate than checking for each part of the blueprint name."
    },
    {
        "original": "```python\nclass VersionManager:\n    def __init__(self):\n        # Initialize an empty dictionary to store versions for each symbol\n        self.versions = {}\n\n    def list_versions(self, symbol=None, snapshot=None, latest_only=False):\n        \"\"\"\n        Return a list of versions filtered by the passed in parameters.\n\n        Parameters\n        ----------\n        symbol : `str`\n            Symbol to return versions for.  If None returns versions across all\n            symbols in the library.\n        snapshot : `",
        "rewrite": "```python\nclass VersionManager:\n    def __init__(self):\n        # Initialize an empty dictionary to store versions for each symbol\n        self.versions = {}\n\n    def add_version(self, symbol, snapshot, version):\n        \"\"\"Add a version for a symbol\"\"\"\n        if symbol not in self.versions:\n            self.versions[symbol] = []\n        self.versions[symbol].append((snapshot, version))\n\n    def get_version(self, symbol=None):\n        \"\"\"Return all versions or the versions of a specific symbol\"\"\"\n        if symbol is None:\n            return self.versions\n        return self.versions.get(symbol, [])\n\n"
    },
    {
        "original": "```python\nclass Group:\n    def __init__(self, jid):\n        self.jid = jid\n        self.chats = []\n\n    def add_chat(self, chat):\n        self.chats.append(chat)\n\n\nclass Chat:\n    def __init__(self, cid):\n        self.cid = cid\n        self.users = []\n\n\n    def add_user(self, user_id):\n        self.users.append(user_id)\n\n\nclass InfoSystem:\n    def __init__(self):\n        # data structure to",
        "rewrite": "```python\nclass Group:\n    def __init__(self, jid):\n        \"\"\"\n        Initialize a Group object.\n\n        Args:\n            jid (str): The JID (Jabber ID) of the group.\n        \"\"\"\n        self.jid = jid\n        self.chats = []\n\n    def add_chat(self, chat):\n        \"\"\"\n        Add a chat to the group.\n\n        Args:\n            chat (Chat): The chat to be added.\n        \"\"\"\n        self.chats.append(chat)\n\n\nclass Chat:\n    def __init__(self, cid):\n        \"\"\"\n        Initialize a Chat object.\n\n        Args:\n            cid"
    },
    {
        "original": "```python\nfrom abc import ABC, abstractmethod\n\nclass ScriptWriter(ABC):\n    @abstractmethod\n    def __str__(self):\n        pass\n\n    def efficiency(self):\n        pass\n\n\nclass WriterA(ScriptWriter):\n    def __str__(self):\n        return \"ScriptWriter A\"\n\n    def efficiency(self):\n        return 10\n\n\nclass WriterB(ScriptWriter):\n    def __str__(self):\n        return \"ScriptWriter B\"\n\n    def efficiency(self):\n        return 8",
        "rewrite": "```python\nfrom abc import ABC, abstractmethod\n\nclass ScriptWriter(ABC):\n    @abstractmethod\n    def __str__(self) -> str:\n        pass\n\n    @abstractmethod\n    def efficiency(self) -> float:\n        pass\n\n\nclass WriterA(ScriptWriter):\n    def __str__(self) -> str:\n        return \"ScriptWriter A\"\n\n    def efficiency(self) -> float:\n        return 10.0\n\n\nclass WriterB(ScriptWriter):\n    def __str__(self) -> str:\n        return \"ScriptWriter B\"\n\n    def efficiency(self) -> float:\n        return 8.0\n``"
    },
    {
        "original": "```python\nfrom contextlib import contextmanager\n\n@contextmanager\ndef pre_periodic_filtered(values, block, repeat_after):\n    \"\"\"\n    Blocks the first *block* items from *values*, repeating the block after\n    every *repeat_after* items, if *repeat_after* is non-zero.\n    \n    :param values: Generator or iterator of values to be filtered.\n    :param int block: Number of items to skip in a cycle.\n    :param int repeat_after: Number",
        "rewrite": "```python\nfrom contextlib import contextmanager\nimport itertools\n\n@contextmanager\ndef pre_periodic_filtered(values, block, repeat_after):\n    if not isinstance(block, int) or not isinstance(repeat_after, int):\n        raise TypeError(\"block and repeat_after must be integers\")\n    if block < 0 or repeat_after < 0:\n        raise ValueError(\"block and repeat_after must be non-negative\")\n\n    values = iter(values)\n    cycle = itertools.islice(values, block)\n    while True:\n        yield from cycle\n        try:\n            next(itertools.islice(values, repeat_after))\n            cycle = itertools.is"
    },
    {
        "original": "```python\ndef skip_format_url(format_, url):\n    \"\"\"\n    Checks whether a give format/url should be skipped and not downloaded.\n\n    @param format_: Filename format (extension).\n    @type format_: str (e.g. html, txt, zip, pdf)\n\n    @param url: URL.\n    @type url: str\n\n    @return: True if format/url should be skipped, False otherwise.\n    @rtype bool\n    \"\"\"\n\n# List of formats that should be skipped\n",
        "rewrite": "```python\ndef skip_format_url(format_, url):\n    \"\"\"\n    Checks whether a given format/url should be skipped and not downloaded.\n\n    @param format_: Filename format (extension).\n    @type format_: str (e.g. html, txt, zip, pdf)\n\n    @param url: URL.\n    @type url: str\n\n    @return: True if format/url should be skipped, False otherwise.\n    @rtype bool\n    \"\"\"\n\n# List of formats that should be skipped\nSKIPPED_FORMATS = ['html', 'txt', 'zip']\n\ndef is_skipped(format_):\n    \"\"\"Checks if a given"
    },
    {
        "original": "```python\nimport numpy as np\n\nclass LikelihoodCalculator:\n    def dlogpdf_link_dr(self, inv_link_f, y, Y_metadata=None):\n        \"\"\"\n        Gradient of the log-likelihood function at y given f, w.r.t shape parameter\n\n        .. math::\n\n        :param inv_link_f: latent variables link(f)\n        :type inv_link_f: Nx1 array\n        :param y: data\n        :type y: Nx1 array\n        :param Y",
        "rewrite": "```python\nimport numpy as np\n\nclass LikelihoodCalculator:\n    def dlogpdf_link_dr(self, inv_link_f: np.ndarray, y: np.ndarray, Y_metadata=None) -> np.ndarray:\n        return (inv_link_f - y) / (1 - inv_link_f)\n```\n\nNote that I've made the following assumptions:\n\n- The `dlogpdf_link_dr` function returns a numpy array.\n- The `inv_link_f` and `y` parameters are numpy arrays with shape `(N,)`.\n- The `/` operator is used for element-wise division.\n\nIf these assumptions are incorrect, please provide more information"
    },
    {
        "original": "```python\nimport numpy as np\nfrom scipy.stats import mannwhitneyu as mw\n\nclass Solution:\n    def get_p_vals(self, X=None):\n        \"\"\"\n        Parameters\n        ----------\n        X : np.array\n            Array of word counts, shape (N, 2) where N is the vocab size.  \n            X[:,0] is the positive class, while X[:,1] is the negative class. None by default\n\n        Returns\n        -------\n        np.array of",
        "rewrite": "```python\nimport numpy as np\nfrom scipy.stats import mannwhitneyu\n\nclass Solution:\n    def get_p_vals(self, X=None):\n        if X is not None:\n            if len(X.shape) != 2 or X.shape[1] != 2:\n                raise ValueError(\"Array X must be 2D and have shape (N, 2)\")\n        p_vals = np.full(len(X) if X is not None else 0, np.nan)\n        \n        for i in range(len(X)):\n            if X is not None and i < len(X):\n                _, p_idx = mannwhitney"
    },
    {
        "original": "```python\ndef __convertRlocToRouterId(self, xRloc16):\n    \"\"\"\n    mapping Rloc16 to router id\n\n    Args:\n        xRloc16: hex rloc16 short address\n\n    Returns:\n        actual router id allocated by leader\n    \"\"\"\n    \n    # Convert the hexadecimal string to an integer\n    xRloc = int(xRloc16, 16)\n    \n    # Extract the last 32 bits of the integer (assuming it's a",
        "rewrite": "```python\ndef convert_rloc_to_router_id(self, xRloc16: str) -> int:\n    \"\"\"\n    Maps Rloc16 to router ID.\n\n    Args:\n        xRloc16: A hexadecimal string representing the Rloc16.\n\n    Returns:\n        The actual router ID allocated by the leader.\n    \"\"\"\n\n    # Convert the hexadecimal string to an integer and reorder bytes if needed\n    xRloc = int.from_bytes(bytes.fromhex(xRloc16.ljust(32, '0')), byteorder='big')\n    \n    # Return the last 32-bit value (assuming it's in network byte order)\n"
    },
    {
        "original": "```\ndef _get_connect_kwargs(self, host, port, user, password, database_url):\n    \"\"\"\n    Get the params to pass to psycopg2.connect() based on passed-in vals\n    from yaml settings file\n    \"\"\"\n    \n    # Unpack the database URL into its components\n    import urllib.parse as urlparse\n    \n    parsed_database_url = urlparse.urlparse(database_url)\n    \n    # Extract the host and port from the parsed URL (if they exist)\n    kwargs_host = getattr(parsed",
        "rewrite": "```python\ndef _get_connect_kwargs(self, host, port, user, password, database_url):\n    import urllib.parse as urlparse\n\n    parsed_database_url = urlparse.urlparse(database_url)\n\n    kwargs_host = getattr(parsed_database_url, 'hostname', host)\n    kwargs_port = getattr(parsed_database_url, 'port', port)\n\n    return {\n        'host': kwargs_host,\n        'port': kwargs_port,\n        'user': user,\n        'password': password,\n        # Assuming the database name is in the path of the URL\n        # If it's in a query parameter or fragment instead, you'll need to adjust"
    },
    {
        "original": "```python\ndef get_valid_salt_views():\n    \"\"\"\n    This function returns a list of valid salt views.\n    It can be customized or found using external sources.\n    \"\"\"\n    # For the purpose of this exercise, assume we have the following valid salt views\n    return [\n        {\"view\": \"starburst\", \"base\": 2, \"exponent\": 0},\n        {\"view\": \"ring\", \"base\": 3, \"exponent\": 1},\n        {\"view",
        "rewrite": "```python\ndef get_valid_salt_views():\n    return [\n        {\"view\": \"starburst\", \"base\": 2, \"exponent\": 0},\n        {\"view\": \"ring\", \"base\": 3, \"exponent\": 1},\n        {\"view\": \"tree\", \"base\": 4, \"exponent\": -1},\n    ]\n```"
    },
    {
        "original": "```python\nimport time\nimport threading\n\nclass Node:\n    def __init__(self):\n        self.is_sync_standby = False\n        self.dcs_connection_active = True\n\n    def while_not_sync_standby(self, func):\n        # Tag us as not allowed to be a sync standby\n        if self.is_sync_standby:\n            print(\"Currently assigned as synchronous standby, waiting for leader to notice and pick an alternative one.\")\n            while self.is_sync_standby:\n                time.sleep",
        "rewrite": "```python\nimport time\nimport threading\n\nclass Node:\n    def __init__(self):\n        self.is_sync_standby = False\n        self.dcs_connection_active = True\n\n    def while_not_sync_standby(self, func):\n        # Check if we are in sync standby mode, and if so wait for it to finish\n        while self.is_sync_standby:\n            time.sleep(1)  # sleep for 1 second to avoid excessive CPU usage\n\n    def perform_task_while_not_sync_standby(self, func):\n        # Tag us as not allowed to be a sync standby\n        self.is_sync_standby ="
    },
    {
        "original": "```python\nimport os\n\ndef _cleanup():\n    \"\"\"\n    Make sure that any terminal processes still running when __del__ was called\n    to the waited and cleaned up.\n    \"\"\"\n    \n    # Iterate over the current process id\n    for pid in os.listdir('/proc'):\n        try:\n            # Try to get the information of each process\n            pinfo = int(pid)\n            \n            # Skip system processes with pid less than 1000 \n            if pinfo < 1000",
        "rewrite": "```python\nimport os\n\ndef _cleanup():\n    for pid in os.listdir('/proc'):\n        try:\n            pinfo = int(pid)\n            if pinfo < 1000:\n                continue\n            try:\n                os.kill(pinfo, 0)\n            except OSError:\n                pass\n            try:\n                os.waitpid(pinfo, 0)\n            except OSError:\n                pass\n        except ValueError:\n            pass\n```"
    },
    {
        "original": "```python\ndef GWCalcTyp(self):\n    \"\"\"\n    GWRTYP is an integer input variable that holds the type of the equation (Common, Forced, Sequence Equation),\n    and other types determined by some specific application functions.  In most applications\n    when GWCALCTYP is JPAREN = &quot;NS&quot; or GPAREN = &quot;,J&quot; this routine will return Sequence.\n    \n    Returns:\n        str: A string indicating the type of equation.\n    \"\"\"\n",
        "rewrite": "```python\ndef gw_calc_typ(self):\n    gparen = self.gparen\n    jparen = self.jparen\n    if gparen == \"NS\" or jparen == \"J\":\n        return \"Sequence\"\n    # For now, just a placeholder. Actual logic depends on the specific application.\n    return f\"Unknown Equation Type {gparen}, {jparen}\"\n```"
    },
    {
        "original": "```python\nimport tensorflow as tf\n\nclass Model:\n    def __init__(self, data_format):\n        self.data_format = data_format\n\n    def _apply_conv(self, inputs, w):\n        \"\"\"\n        Apply a separable_conv2d operation on `inputs` using `w`.\n\n        Args:\n          inputs: A Tensor of shape `data_format` and of type \n                  `tf.float16`, `tf.bfloat16` or `tf.float32`.\n          w: A tuple",
        "rewrite": "```python\nimport tensorflow as tf\n\nclass ConvModel:\n    def __init__(self, data_format):\n        \"\"\"\n        Initializes a model with the specified data format.\n\n        Args:\n          data_format (str): The data format for the model.\n        \"\"\"\n        self.data_format = data_format\n\n    def _apply_conv(self, inputs, weights):\n        \"\"\"\n        Applies a 1D convolution operation.\n\n        Args:\n          inputs (tf.Tensor): The input to the convolution.\n          weights (tuple): A tuple containing the filter and dilation factors.\n\n        Returns:\n          tf.Tensor: The output of the convolution operation.\n       \"\"\"\n       "
    },
    {
        "original": "```python\nclass Document:\n    def __init__(self):\n        self.headings = []\n\n    def add_heading(self, text=\"\", level=1):\n        \"\"\"Return a heading paragraph newly added to the end of the document.\n\n        The heading paragraph will contain *text* and have its paragraph style\n        determined by *level*. If *level* is 0, the style is set to `Title`. If *level*\n        is 1 (or omitted), `Heading 1`",
        "rewrite": "```python\nclass Document:\n    def __init__(self):\n        self.headings = []\n        self.style_map = {0: 'Title', 1: 'Heading 1'}\n\n    def add_heading(self, text=\"\", level=1):\n        heading = {\n            'text': text,\n            'level': level,\n            'style': self.style_map.get(level, self.style_map[1])\n        }\n        self.headings.append(heading)\n        return heading\n```"
    },
    {
        "original": "```python\nclass FlowProcessingHandler:\n    def __init__(self):\n        self.handlers = []\n\n    def _RegisterFlowProcessingHandler(self, handler):\n        \"\"\"Registers a handler to receive flow processing messages.\"\"\"\n        self.handlers.append(handler)\n\n\nclass FlowProcessor:\n    def __init__(self):\n        self.handler_manager = FlowProcessingHandler()\n\n    def process_flow(self, data: str) -> str:\n        if not data:\n            return 'Invalid input'\n\n        for handler in self.handler_manager.handlers",
        "rewrite": "```python\nclass FlowProcessingHandler:\n    def __init__(self):\n        self.handlers = []\n\n    def register_flow_processing_handler(self, handler):\n        \"\"\"Registers a handler to receive flow processing messages.\"\"\"\n        self.handlers.append(handler)\n\n    def get_handlers(self):\n        return self.handlers\n\n\nclass FlowProcessor:\n    def __init__(self):\n        self.handler_manager = FlowProcessingHandler()\n\n    def process_flow(self, data: str) -> str:\n        if not data:\n            return 'Invalid input'\n\n        for handler in self.handler_manager.get_handlers():\n            result = handler.process(data)\n            if result is not None:\n                return"
    }
]
