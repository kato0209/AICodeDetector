[
    {
        "original": "```python\nfrom kafka import KafkaConsumer\n\ndef beginning_offsets(partitions):\n    consumer = KafkaConsumer()\n    offsets = {}\n    for p in partitions:\n        topic_partition = p.topic, p.partition\n        try:\n            offset = consumer.beginning_offset(topic_partition)\n            offsets[p] = offset\n        except Exception as e:\n            if isinstance(e, UnsupportedVersionError) or isinstance(e, KafkaTimeoutError):\n                raise e\n    return offsets\n```",
        "rewrite": "Here is the revised code:\n```\nfrom kafka import KafkaConsumer\nfrom kafka.errors import UnsupportedVersionError, KafkaTimeoutError\n\ndef beginning_offsets(partitions):\n    consumer = KafkaConsumer()\n    offsets = {}\n    for p in partitions:\n        topic_partition = p.topic, p.partition\n        try:\n            offset = consumer.beginning_offsets([topic_partition])[topic_partition]\n            offsets[p] = offset\n        except (UnsupportedVersionError, KafkaTimeoutError) as e:\n            raise e\n    return offsets\n```"
    },
    {
        "original": "```\ndef _get_values(cls, diff_dict, type='new'):\n    return {key: value[0] if type == 'new' else value[1] for key, value in diff_dict.items() if len(value) == 2}\n```",
        "rewrite": "```\ndef _get_values(cls, diff_dict, type='new'):\n    return {key: value[0] if type == 'new' else value[1] for key, value in diff_dict.items() if len(value) == 2 and isinstance(value, list)}\n```"
    },
    {
        "original": "```\ndef get_ref(cls, state, obj_alloc_id, field_class_name, field_name, field_type):\n    \"\"\"\n    Resolve the field within the given state.\n    \"\"\"\n    obj = state[obj_alloc_id]\n    if not hasattr(obj, field_class_name):\n        raise AttributeError(f\"Object {obj_alloc_id} does not have class {field_class_name}\")\n    field_cls = getattr(obj, field_class_name)\n    if not hasattr(field_cls, field_name):\n        raise AttributeError(f\"",
        "rewrite": "Here is the revised code:\n\n```\ndef get_ref(cls, state, obj_alloc_id, field_class_name, field-name):\n    obj = state[obj_alloc_id]\n    if not hasattr(obj, field_class_name):\n        raise AttributeError(f\"Object {obj_alloc_id} does not have class {field_class_name}\")\n    return getattr(getattr(obj,\tfield_class_name),\tfield-name)\n```"
    },
    {
        "original": "```\ndef pd_coords(self, comp):\n    n_elements = len(comp)\n    coords = [0] * (n_elements - 1)\n    sum_comp = sum(comp)\n    \n    for i in range(n_elements - 1):\n        coords[i] = comp[i] / sum_comp\n    \n    return coords\n```",
        "rewrite": "```\ndef pd_coords(self, comp):\n    return [(i/sum(comp)) for i in comp[:-1]]\n```"
    },
    {
        "original": "```\ndef relative_ref(self, baseURI):\n    base_path = baseURI.split('/')\n    target_path = self.path.split('/')\n    i = 0\n    while i < len(base_path) and i < len(target_path) and base_path[i] == target_path[i]:\n        i += 1\n    rel_ref = '../' * (len(base_path) - i) + '/'.join(target_path[i:])\n    return rel_ref if rel_ref else '.'\n```",
        "rewrite": "```\ndef relative_ref(self, baseURI):\n    base_path = baseURI.split('/')\n    target_path = self.path.split('/')\n    i = 0\n    while i < len(base_path) and i < len(target_path) and base_path[i] == target_path[i]:\n        i += 1\n    rel_ref = '../' * (len(base_path) - i) + '/'.join(target_path[i:])\n    return rel_ref if rel_ref != '' else '.'\n```"
    },
    {
        "original": "```\ndef is_enhanced_rr_cap_valid(self):\n    open_messages_sent = self.open_messages_sent\n    open_messages_received = self.open_messages_received\n\n    if open_messages_sent and open_messages_received:\n        return 'enhanced-route-refresh-capability' in open_messages_sent and 'enhanced-route-refresh-capability' in open_messages_received\n    else:\n        return False\n```",
        "rewrite": "```\ndef is_enhanced_rr_cap_valid(self):\n    return ('enhanced-route-refresh-capability' in self.open_messages_sent and \n            'enhanced-route-refresh-capability' in self.open_messages_received) if (self.open_messages_sent and self.open_messages_received) else False"
    },
    {
        "original": "```\ndef parse_osm_nodes_paths(osm_data):\n    nodes = {}\n    paths = {}\n\n    if 'elements' in osm_data:\n        for element in osm_data['elements']:\n            if element['type'] == 'node':\n                nodes[element['id']] = element\n            elif element['type'] == 'way':\n                way_id = element['id']\n                ways_tags = {k: v for k, v in element.items() if k != 'nodes' and k !=",
        "rewrite": "Here is the revised code:\n\n```\ndef parse_osm_nodes_paths(osm_data):\n    nodes = {}\n    paths = {}\n\n    if 'elements' in osm_data:\n        for element in osm_data['elements']:\n            if element['type'] == 'node':\n                nodes[element['id']] = element\n            elif element['type'] == 'way':\n                way_id = element['id']\n                ways_tags = {k: v for k, v in element.items() if k not in ['nodes', 'id', 'type']}\n                paths[way_id] = {'tags': ways_tags, 'nodes': element.get"
    },
    {
        "original": "```python\nfrom pymatgen import Molecule as MoleculeClass\nfrom itertools import permutations\n\ndef get_best_electronegativity_anonymous_mapping(struct1, struct2):\n    # Get all possible permutations of mapping between species of two structures\n    perms = list(permutations(range(len(struct2.species)), len(struct1.species)))\n\n    # Initialize minimum difference in electronegativity and best mapping\n    min_diff = float('inf')\n    best_mapping = None\n\n    # Iterate over",
        "rewrite": "Here is the revised code:\n```\nfrom pymatgen import Molecule as MoleculeClass\nfrom itertools import permutations\n\ndef get_best_electronegativity_anonymous_mapping(struct1, struct2):\n    perms = list(permutations(range(len(struct2.species)), len(struct1.species)))\n    \n    min_diff = float('inf')\n    best_mapping = None\n    \n    for perm in perms:\n        diff = sum(abs(species.electronegativity - struct2.species[i].electronegativity) \n                   for species, i in zip(struct1.species, perm))\n        \n        if diff < min_diff:\n            min_diff"
    },
    {
        "original": "```\nfrom typing import Callable, Tuple\n\nclass HPackHeaders:\n    pass\n\nclass HPackIndexedHdr(HPackHeaders):\n    pass\n\nclass HPackLitHdrFldWithoutIndexing(HPackHeaders):\n    pass\n\nclass HPackLitHdrFldWithIncrIndexing(HPackHeaders):\n    pass\n\n\ndef _convert_a_header_to_a_h2_header(\n    hdr_name: str,\n    hdr_value: str,\n    is_sensitive: Callable[[str, str], bool",
        "rewrite": "Here is the revised code:\n\n```\nfrom typing import Callable, Tuple\nfrom http import headers  # added missing import statement\n\nclass HpackHeaders:\n    pass\n\nclass HpackIndexedHdr(HpackHeaders):\n    pass  \n\nclass HpackLitHdrFldWithoutIndexing(HpackHeaders):\n    pass  \n\nclass HpackLitHdrFldWithIncrIndexing(HpackHeaders):\n    pass\n\n\ndef convert_a_header_to_a_h2_header(hdr_name: str, hdr_value: str, is_sensitive: Callable[[str, str], bool]) -> Tuple[bytes, bytes]:\n    raise NotImplementedError(\"This method is not implemented\")\n```"
    },
    {
        "original": "```python\nclass BigchainTransactionCreator:\n    def create(cls, tx_signers, recipients, metadata=None, asset=None):\n        from bigchaindb.common.transaction import Transaction\n        \n        # Initialize an empty transaction object \n        transaction = Transaction()\n\n        # Set transaction type to 'CREATE'\n        transaction.operation = 'CREATE'\n\n        # Add signers to transaction inputs \n        for signer in tx_signers:\n            transaction.add_input(signer)\n\n        # Add recipients and amounts to transaction outputs \n       ",
        "rewrite": "Here is the revised code:\n\n```python\nclass BigchainTransactionCreator:\n    def create(cls, tx_signers, recipients, metadata=None, asset=None):\n        from bigchaindb.common.transaction import Transaction\n        transaction = Transaction()\n        transaction.operation = 'CREATE'\n        \n        for signer in tx_signers:\n            transaction.add_input(signer)\n        \n        for recipient in recipients:\n            if isinstance(recipient, dict):\n                address = recipient.get('address')\n                amount = recipient.get('amount')\n                meta = recipient.get('metadata', {})\n                if metadata:\n                    meta.update(metadata)\n                if asset:\n                    meta['asset_id"
    },
    {
        "original": "```\nfrom datetime import datetime\nimport pytz\n\ndef utc_dt_to_local_dt(dtm):\n    utc_dt = datetime.strptime(dtm, '%Y-%m-%d %H:%M:%S')\n    utc_dt = utc_dt.replace(tzinfo=pytz.UTC)\n    local_dt = utc_dt.astimezone()\n    return local_dt.strftime('%Y-%m-%d %H:%M:%S %Z%z')\n```",
        "rewrite": "```\nfrom datetime import datetime\nimport pytz\n\ndef utcDtTolocaleDt(utcDtStr, timeZone):\n   .utcDt = datetime.strptime(utcDtStr, '%Y-%m-%d %H:%M:%S').replace(tzinfo=pytz.UTC)\n    return .utcDt.astimezone(timeZone).strftime('%Y-%m-%d %H:%M:%S %Z%z')\n```"
    },
    {
        "original": "```\ndef _getScriptSettingsFrom IniFile(policy_info):\n    # Open and read the file\n    with open(policy_info, 'r') as f:\n        content = f.read()\n\n    # Initialize variables\n    scripts = {}\n    current_script = None\n\n    # Parse lines\n    for line in content.splitlines():\n        line = line.strip()\n        \n        if line.startswith('[') and ']' in line:\n            # Section header found, extract script name\n            start_br",
        "rewrite": "Here is the revised code:\n\n```\ndef get_script_settings_from_file(policy_info):\n    with open(policy_info, 'r') as f:\n        content = f.read()\n\n    scripts = {}\n    current_script = None\n\n    for line in content.splitlines():\n        line = line.strip()\n        \n        if '[' in line and ']' in line:\n            script_name_start = line.find('[')\n            script_name_end = line.find(']')\n            script_name = line[script_name_start + 1:script_name_end]\n            scripts[script_name] = []\n            current_script = script_name\n        elif current_script is not"
    },
    {
        "original": "```\ndef _get_triplet_scores(self, triangles_list):\n    scores = {}\n    for triangle in triangles_list:\n        triangle_set = frozenset(triangle)\n        # assuming the score calculation is a placeholder, replace with actual logic\n        score = len(triangle) * 2.0\n        scores[triangle_set] = score\n    return scores\n```",
        "rewrite": "Here is the revised code:\n```\ndef _get_triplet_scores(self, triangles_list):\n    return {frozenset(triangle): len(triangle) * 2.0 for triangle in triangles_list}\n```"
    },
    {
        "original": "```\nasync def vcx_messages_update_status(msg_json: str):\n    import json\n    import asyncio\n    from aiohttp import ClientSession\n\n    async with ClientSession() as session:\n        msg_data = json.loads(msg_json)\n        connection_id = msg_data['connection_id']\n        messages = msg_data['messages']\n\n        for message in messages:\n            url = f'https://example.com/update_message_status/{connection_id}'\n            data = {'message_id': message['uid'], 'status",
        "rewrite": "```\nasync def vcx_messages_update_status(msg_json: str):\n    import json\n    import asyncio\n    from aiohttp import ClientSession\n\n    async with ClientSession() as session:\n        msg_data = json.loads(msg_json)\n        connection_id = msg_data['connection_id']\n        messages = msg_data['messages']\n\n        for message in messages:\n            url = f'https://example.com/update_message_status/{connection_id}'\n            data = {'message_id': message['uid'], 'status': 'read'}\n            async with session.post(url, json=data) as response:\n                if response.status != 200:\n                    print(f"
    },
    {
        "original": "```\nimport socket\nimport time\n\nclass IsoTPSocket:\n    def __init__(self):\n        self.receive_buffer = b''\n\n    def recv_with_timeout(self, timeout=1):\n        start_time = time.time()\n        while True:\n            if self.receive_buffer:\n                return self.receive_buffer.pop(0)\n            elif time.time() - start_time > timeout:\n                return None\n```",
        "rewrite": "```\nimport socket\nimport time\nfrom collections import deque\n\nclass IsoTPSocket:\n    def __init__(self):\n        self.receive_buffer = deque()\n\n    def recv_with_timeout(self, timeout=1):\n        start_time = time.time()\n        while True:\n            if self.receive_buffer:\n                return self.receive_buffer.popleft()\n            elif time.time() - start_time > timeout:\n                return None\n```"
    },
    {
        "original": "```\nimport math\n\ndef carmichael_of_factorized(f_list):\n    lambda_val = 1\n    for p, e in f_list:\n        lambda_val = lcm(lambda_val, (p-1) * (p**(e-1)))\n    return lambda_val\n\ndef gcd(a, b):\n    while b:\n        a, b = b, a % b\n    return a\n\ndef lcm(a, b):\n    return a * b // gcd(a, b)\n```",
        "rewrite": "Here is the revised code:\n\n```\nimport math\nimport functools\n\ndef carmichael_of_factorized(f_list):\n    def lcm(a, b):\n        return a * b // math.gcd(a, b)\n    return functools.reduce(lcm, [(p-1) * (p**(e-1)) for p, e in f_list], 1)\n```"
    },
    {
        "original": "```\nimport requests\n\ndef absent(name, profile=\"splunk\"):\n    url = f\"https://{profile}.com/api/services/search/jobs/{name}\"\n    response = requests.delete(url, auth=(\"username\", \"password\"))\n    if response.status_code == 200:\n        return True\n    else:\n        return False\n```",
        "rewrite": "Here is the revised code:\n\n```\nimport requests\n\ndef delete_job(name, profile=\"splunk\", username=\"username\", password=\"password\"):\n    url = f\"https://{profile}.com/api/services/search/jobs/{name}\"\n    response = requests.delete(url, auth=(username, password))\n    return response.status_code == 200\n```"
    },
    {
        "original": "```\ndef GetNotificationsForAllShards(self, queue):\n    notifications = []\n    for shard in self.GetShardNames(queue):\n        notifications.extend(self.GetNotificationsForShard(queue, shard))\n    return notifications\n```",
        "rewrite": "```\ndef GetNotificationsForAllShards(self, queue):\n    return [n for shard in self.GetShardNames(queue) for n in self.GetNotificationsForShard(queue, shard)]\n```"
    },
    {
        "original": "```\nfrom sympy import symbols, Eq, solve\n\nclass FunctionMatcher:\n    def __init__(self, functions):\n        self.functions = functions\n\n    def differing_functions_with_consts(self):\n        matches = []\n        for i in range(len(self.functions)):\n            for j in range(i + 1, len(self.functions)):\n                x = symbols('x')\n                eq1 = Eq(eval(self.functions[i]), 0)\n                eq2 = Eq(eval(self.functions[j]), 0)\n               ",
        "rewrite": "Here is the revised code:\n\n```\nfrom sympy import symbols, Eq, solve\n\nclass FunctionMatcher:\n    def __init__(self, functions):\n        self.functions = functions\n\n    def differing_functions_with_consts(self):\n        matches = []\n        for i in range(len(self.functions)):\n            for j in range(i + 1, len(self.functions)):\n                x = symbols('x')\n                eq1 = Eq(eval(self.functions[i]), 0)\n                eq2 = Eq(eval(self.functions[j]), 0)\n                consts_eq1 = solve(eq1, x)\n                consts_eq2 = solve(eq2, x)\n               "
    },
    {
        "original": "```\nclass EOPatchSaver:\n    def save(self, eopatch, use_tmp=True):\n        if use_tmp:\n            # Save to temporary file\n            with open(\"temp.eopatch\", \"wb\") as f:\n                pickle.dump(eopatch, f)\n        else:\n            # Save to intended location\n            with open(\"eopatch.eopatch\", \"wb\") as f:\n                pickle.dump(eopatch, f)\n```",
        "rewrite": "```\nimport os\nimport pickle\n\nclass EOPatchSaver:\n    def __init__(self, tmp_filename='temp.eopatch', filename='eopatch.eopatch'):\n        self.tmp_filename = tmp_filename\n        self.filename = filename\n\n    def save(self, eopatch, use_tmp=True):\n        filename = self.tmp_filename if use_tmp else self.filename\n        with open(filename, \"wb\") as f:\n            pickle.dump(eopatch, f)\n```"
    },
    {
        "original": "```\nclass StateTrie:\n    def __init__(self):\n        self.trie = {}\n\n    def _addAttr(self, txn, isCommitted=False) -> None:\n        did, attribute_name, data_type, data = txn\n        if data_type == 'RAW':\n            key = f\"{did}{attribute_name}\"\n            self.trie[key] = hash(data)\n        elif data_type == 'ENC':\n            key = f\"{did}{hash(attribute_name)}\"\n            self.tr",
        "rewrite": "Here is the revised code:\n\n```\nclass StateTrie:\n    def __init__(self):\n        self.trie = {}\n\n    def _addAttr(self, txn, isCommitted=False) -> None:\n        did, attribute_name, data_type, data = txn\n        if data_type == 'RAW':\n            key = f\"{did}{attribute_name}\"\n            self.trie[key] = hash(data)\n        elif data_type == 'ENC':\n            key = f\"{did}{hash(attribute_name)}\"\n            self.trie[key] = hash(data)\n```"
    },
    {
        "original": "```\nimport os\nimport zipfile\nimport xml.etree.ElementTree as ET\n\ndef _find_packages(root):\n    for subdir, dirs, files in os.walk(root):\n        for file in files:\n            if file.endswith('.zip'):\n                zf = zipfile.ZipFile(os.path.join(subdir, file))\n                pkg_xml = ET.parse(zf.open('package.xml')).getroot()\n                yield (pkg_xml, zf, os.path.relpath(subdir, root))\n```",
        "rewrite": "Here is the revised code:\n\n```\nimport os\nimport zipfile\nimport xml.etree.ElementTree as ET\n\ndef find_packages(root):\n    for subdir, dirs, files in os.walk(root):\n        for file in files:\n            if file.endswith('.zip'):\n                zip_file_path = os.path.join(subdir, file)\n                with zipfile.ZipFile(zip_file_path) as zf:\n                    pkg_xml = ET.parse(zf.open('package.xml')).getroot()\n                    yield pkg_xml, zf, os.path.relpath(subdir, root)\n```"
    },
    {
        "original": "```\nimport bluetooth\n\ndef srbt1(bt_address, pkts, *_args={}, **_kargs={}):\n    sock = bluetoothAMP.get_socket()\n    sock.connect((bt_address, 1))\n    sock.send(pkts)\n    data = sock.recv(1024)\n    return data\n```",
        "rewrite": "Here is the revised code:\n```\nimport bluetooth\n\ndef srbt1(bt_address, pkts, *args, **kwargs):\n    with bluetooth.bluetooth_socket(bluetooth.RFCOMM) as sock:\n        sock.connect((bt_address, 1))\n        sock.send(pkts)\n        data = sock.recv(1024)\n    return data\n```"
    },
    {
        "original": "```\nimport socket\nimport netifaces\n\nclass NetworkInterface:\n    def GetIPAddresses(self):\n        ip_array = []\n        for interface in netifaces.interfaces():\n            if interface == 'lo':  # ignore loopback interface\n                continue\n            lst = netifaces.ifaddresses(interface)\n            teste = {}\n            for item in lst:\n                if(item == 2): # AF_INET \n                    for thing in lst[item]:\n                        teste={\n                            \"iname\":interface,\n                           ",
        "rewrite": "Here is the revised code:\n```\nimport socket\nimport netifaces\n\nclass NetworkInterface:\n    def get_ip_addresses(self):\n        ip_array = []\n        for interface in netifaces.interfaces():\n            if interface == 'lo':\n                continue\n            lst = netifaces.ifaddresses(interface)\n            for item in lst.get(2, []):\n                ip_array.append({\n                    \"iname\": interface,\n                    \"ipaddr\": item[\"addr\"],\n                    \"netmask\": item[\"netmask\"],\n                    \"broadcast\": item.get(\"broadcast\")\n                })\n        return ip_array\n```"
    },
    {
        "original": "```\ndef operate(self, point):\n    # Assuming operate function is defined elsewhere\n    pass\n\ndef are_symmetrically_related(self, point_a, point_b, tol=0.001):\n    \"\"\"\n    Checks if two points are symmetrically related.\n\n    Args:\n        point_a (3x1 array): First point.\n        point_b (3x1 array): Second point.\n        tol (float): Absolute tolerance for checking distance.\n\n    Returns:\n        True if self.operate(point",
        "rewrite": "Here is the revised code:\n\n```\ndef operate(self, point):\n    raise NotImplementedError(\"operate function must be implemented\")\n\ndef are_symmetrically_related(self, point_a, point_b, tol=0.001):\n    return np.allclose(self.operate(point_a), -self.operate(point_b), atol=tol)\n```"
    },
    {
        "original": "```\ndef validate_rpc_host(ip):\n    \"\"\"\n    Validates the given ip for use as RPC server address.\n    \"\"\"\n    parts = ip.split(\".\")\n    if len(parts) != 4:\n        return False\n    for part in parts:\n        if not part.isdigit():\n            return False\n        i = int(part)\n        if i < 0 or i > 255:\n            return False\n    return True\n```",
        "rewrite": "```\ndef validate_rpc_host(ip):\n    parts = ip.split(\".\")\n    return len(parts) == 4 and all(0 <= int(part) <= 255 for part in parts if part.isdigit())\n```"
    },
    {
        "original": "```python\nimport subprocess\nimport logging\n\ndef find_available_interfaces():\n    \"\"\"\n    Returns the names of all open can/vcan interfaces using\n    the ``ip link list`` command. If the lookup fails, an error\n    is logged to the console and an empty list is returned.\n\n    :rtype: an iterable of :class:`str`\n    \"\"\"\n    \n    try:\n        output = subprocess.check_output([\"ip\", \"link\", \"list\"])\n        lines = output.decode(\"utf-",
        "rewrite": "Here is the revised code:\n\n```python\nimport subprocess\n\ndef find_available_interfaces():\n    try:\n        output = subprocess.check_output([\"ip\", \"link\", \"list\"])\n        lines = output.decode(\"utf-8\").splitlines()\n        interfaces = [line.split(\": \")[1] for line in lines if \"can\" in line or \"vcan\" in line]\n        return interfaces\n    except subprocess.CalledProcessError:\n        return []\n```"
    },
    {
        "original": "```\nclass Server:\n    def __init__(self, namespace=None):\n        self.namespace = namespace\n        self.sessions = {}\n\n    def save_session(self, sid, session, namespace=None):\n        if namespace is None:\n            namespace = self.namespace\n        if namespace not in self.sessions:\n            self.sessions[namespace] = {}\n        self.sessions[namespace][sid] = session\n```",
        "rewrite": "```\nclass Server:\n    def __init__(self, namespace=None):\n        self.namespace = namespace\n        self.sessions = {}\n\n    def save_session(self, sid, session, namespace=None):\n        namespace = namespace or self.namespace\n        self.sessions.setdefault(namespace, {})[sid] = session\n```"
    },
    {
        "original": "```\nfrom cryptography.hazmat.backends import default_backend\nfrom cryptography.hazmat.primitives import serialization\n\ndef get_public_keys_der_v3(self):\n    public_keys = []\n    if self.v3_signature_block:\n        for cert in self.v3_signature_block.certs:\n            pub_key = cert.public_key()\n            der_pub_key = pub_key.public_bytes(\n                encoding=serialization.Encoding.DER,\n                format=serialization.PublicFormat.SubjectPublicKeyInfo\n            )\n            public_keys.append(der",
        "rewrite": "Here is the revised code:\n\n```\nfrom cryptography.hazmat.backends import default_backend\nfrom cryptography.hazmat.primitives import serialization\n\ndef get_public_keys_der_v3(self):\n    public_keys = []\n    if self.v3_signature_block:\n        for cert in self.v3_signature_block.certs:\n            pub_key = cert.public_key()\n            der_pub_key = pub_key.public_bytes(\n                encoding=serialization.Encoding.DER,\n                format=serialization.PublicFormat.SubjectPublicKeyInfo\n            )\n            public_keys.append(der_pub_key)\n    return public_keys\n```"
    },
    {
        "original": "```\ndef chemical_symbols(atom_species, symbol_length):\n    symbols = []\n    ascii_offset = 97  # ASCII value of 'a'\n    for i in range(atom_species):\n        symbol = \"\"\n        for j in range(symbol_length):\n            symbol += chr(ascii_offset + ((i + j) % 26))\n        symbols.append(symbol)\n    return symbols\n```",
        "rewrite": "```\ndef chemical_symbols(atom_species, symbol_length):\n    return [''.join(chr(97 + ((i + j) % 26) for j in range(symbol_length)) for i in range(atom_species)]\n```"
    },
    {
        "original": "```\nimport yaml\n\ndef safe_dump_all(documents, stream=None, **kwds):\n    if stream is None:\n        return yaml.safe_dump_all(documents, default_flow_style=True, **kwds)\n    else:\n        yaml.safe_dump_all(documents, stream=stream, default_flow_style=True, **kwds)\n```",
        "rewrite": "```\nimport yaml\n\ndef safe_dump_all(documents, stream=None, **kwds):\n    kwds.setdefault('default_flow_style', True)\n    return yaml.safe_dump_all(documents, stream=stream, **kwds)\n```"
    },
    {
        "original": "```\nfrom typing import Iterator, Union\nimport numpy as np\nfrom cirq import Circuit\n\ndef _simulator_iterator(circuit: Circuit,\n                        param_resolver,\n                        qubit_order,\n                        initial_state: Union[int, np.ndarray]) -> Iterator:\n    # Check if initial_state is an integer \n    if isinstance(initial_state, int):\n      # Set initial_state to computational basis corresponding to this integer \n      pass\n  \n    # Check if initial_state is a numpy array  \n    elif isinstance",
        "rewrite": "Here is the revised code:\n\n```\nfrom typing import Iterator, Union\nimport numpy as np\nfrom cirq import Circuit\n\ndef _simulator_iterator(circuit: Circuit,\n                        param_resolver,\n                        qubit_order,\n                        initial_state: Union[int, np.ndarray]) -> Iterator:\n    if isinstance(initial_state, int):\n        num_qubits = len(qubit_order)\n        initial_state = np.zeros(2 ** num_qubits, dtype=np.complex64)\n        initial_state[initial_state] = 1\n    \n    elif isinstance(initial_state, np.ndarray):\n        pass\n    \n    # rest of your code...\n```"
    },
    {
        "original": "```\ndef predictive_variance(self, mu, variance, predictive_mean=None, Y_metadata=None):\n    if predictive_mean is None:\n      # If no predictive mean is provided assume it's 0\n      predictive_mean = 0  \n    expectation_squared = (mu - predictive_mean) ** 2 \n    variance_squared = variance ** 2 \n    return expectation_squared + variance_squared\n```",
        "rewrite": "```\ndef predictive_variance(self, mu, variance, predictive_mean=0, Y_metadata=None):\n    return (mu - predictive_mean) ** 2 + variance ** 2\n```"
    },
    {
        "original": "```\nclass DockerConfigManager:\n    def __init__(self):\n        self.configs = {}\n\n    def remove_config(self, id):\n        if id in self.configs:\n            del self.configs[id]\n            return True\n        else:\n            raise docker.errors.NotFound(\"No config with that ID exists\")\n```",
        "rewrite": "```\nclass DockerConfigManager:\n    def __init__(self):\n        self.configs = {}\n\n    def remove_config(self, id):\n        try:\n            del self.configs[id]\n            return True\n        except KeyError:\n            raise docker.errors.NotFound(\"No config with that ID exists\")\n```"
    },
    {
        "original": "```\ndef get_mor_by_moid(si, obj_type, obj_moid):\n    \"\"\"\n    Get reference to an object of specified object type and id\n\n    si\n        ServiceInstance for the vSphere or ESXi server (see get_service_instance)\n\n    obj_type\n        Type of the object (vim.StoragePod, vim.Datastore, etc)\n\n    obj_moid\n        ID of the object\n    \"\"\"\n    \n```python    \nimport pyVmomi\n    \ndef get_service_instance():\n",
        "rewrite": "Here is the revised code:\n\n```\nimport pyVmomi\n\ndef get_service_instance():\n    pass  # implement me!\n\ndef get_mor_by_moid(si, obj_type, obj_moid):\n    return si.content.searchIndex.FindByUuid(None, True, obj_moid, True)\n```"
    },
    {
        "original": "```\ndef ConfigureUrls(config, external_hostname = None):\n    if external_hostname is None:\n        external_hostname = input(\"Enter the external hostname: \")\n    config[\"AdminUI.url\"] = f\"http://{external_hostname}:8000\"\n    config[\"Client.frontend_url\"] = f\"http://{external_hostname}:8080\"\n    config[\"ClientPoll.url\"] = f\"http://{external_hostname}:8081\"\n    return config\n```",
        "rewrite": "```\ndef configure_urls(config, external_hostname=None):\n    external_hostname = external_hostname or input(\"Enter the external hostname: \")\n    config[\"AdminUI.url\"] = f\"http://{external_hostname}:8000\"\n    config[\"Client.frontend_url\"] = f\"http://{external_hostname}:8080\"\n    config[\"ClientPoll.url\"] = f\"http://{external_hostname}:8081\"\n    return config\n```"
    },
    {
        "original": "```\nclass Parser:\n    def __init__(self):\n        self.knowledge_base = {}\n\n    def Parse(self, cmd, args, stdout, stderr, return_val, time_taken):\n        self.knowledge_base[cmd] = {\n            'args': args,\n            'stdout': stdout,\n            'stderr': stderr,\n            'return_val': return_val,\n            'time_taken': time_taken\n        }\n```",
        "rewrite": "```\nclass Parser:\n    def __init__(self):\n        self.knowledge_base = {}\n\n    def parse(self, cmd, args, stdout, stderr, return_val, time_taken):\n        self.knowledge_base[cmd] = {\n            'args': args,\n            'stdout': stdout.decode() if stdout else None,\n            'stderr': stderr.decode() if stderr else None,\n            'return_val': return_val,\n            'time_taken': time_taken\n        }\n```"
    },
    {
        "original": "```\ndef load_skel(self, file_name):\n    with open(file_name, 'r') as f:\n        content = f.read()\n        # parse ASF content into skeleton structure\n        # TO DO: implement parsing logic\n        pass\n```",
        "rewrite": "```\nimport xml.etree.ElementTree as ET\n\ndef load_skel(self, file_name):\n    tree = ET.parse(file_name)\n    root = tree.getroot()\n    skeleton = {}\n    for child in root:\n        if child.tag == 'root':\n            skeleton['root'] = child.attrib['name']\n        elif child.tag == 'bonedata':\n            bones = {}\n            for bone in child:\n                bones[bone.attrib['name']] = {'direction': bone.attrib['direction'], 'length': float(bone.attrib['length'])}\n            skeleton['bones'] = bones\n        elif child.tag == 'hierarchy':\n"
    },
    {
        "original": "```\ndef _ruby_installed(ret, ruby, user=None):\n    if user is not None:\n        cmd = f\"su {user} -c 'ruby -v | grep {ruby}'\"\n    else:\n        cmd = f\"ruby -v | grep {ruby}\"\n    ret[\"installed\"] = True if os.system(cmd) == 0 else False\n```",
        "rewrite": "```\nimport subprocess\n\ndef _ruby_installed(ret, ruby, user=None):\n    cmd = [\"ruby\", \"-v\"]\n    if user is not None:\n        cmd = [\"su\", user, \"-c\"] + [' '.join(cmd)]\n    process = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n    ret[\"installed\"] = any(ruby in line.decode() for line in process.stdout.splitlines())\n```"
    },
    {
        "original": "```\nclass Structure:\n    # assuming Structure class is defined somewhere\n    pass\n\nclass Element:\n    # assuming Element class is defined somewhere\n    pass\n\ndef get_projection_on_elements(self, structure):\n    \"\"\"\n    Method returning a dictionary of projections on elements.\n\n    Args:\n        structure (Structure): Input structure.\n\n    Returns:\n        A dictionary in the {Spin.up:[k index][b index][{Element:values}]}\n    \"\"\"\n    \n    projection = {}\n    \n    # iterate over",
        "rewrite": "Here's a revised version of the code:\n\n```\nclass Structure:\n    pass\n\nclass Element:\n    pass\n\nclass ProjectionCalculator:\n    def get_projection_on_elements(self, structure):\n        projection = {}\n        for spin in [Spin.up, Spin.down]:\n            projection.setdefault(spin, [])\n            for k_index in range(structure.get_num_k_points()):\n                projection[spin].append([])\n                for b_index in range(structure.get_num_bands()):\n                    element_projections = {}\n                    for element in structure.get_elements():\n                        element_projections[element] = self._calculate_projection(element, spin, k_index, b_index)\n                   "
    },
    {
        "original": "```\nclass VectorArgs:\n    def __init__(self, *args):\n        self.args = args\n\n    def vector_args(self):\n        lanes = self.args.split(',')\n        lane_pairs = [lane.split('..') for lane in lanes]\n        lane_pairs.sort(key=lambda x: int(x[1]), reverse=True)\n        return [(int(pair[0]), int(pair[1])) for pair in lane_pairs]\n\n# Example usage:\nvector_args_instance = VectorArgs('0..10,",
        "rewrite": "Here is the revised code:\n\n```\nclass VectorArgs:\n    def __init__(self, *args):\n        self.args = args[0] if args else ''\n\n    def vector_args(self):\n        lanes = [lane.strip() for lane in self.args.split(',')]\n        lane_pairs = [lane.split('..') for lane in lanes]\n        lane_pairs.sort(key=lambda x: int(x[1]), reverse=True)\n        return [(int(pair[0]), int(pair[1])) for pair in lane_pairs]\n\n# Example usage:\nvector_args_instance = VectorArgs('0..10,11..20,21..30')\n"
    },
    {
        "original": "```\ndef kwargs_from_keyword(from_kwargs, to_kwargs, keyword, clean_origin=True):\n    for key, value in list(from_kwargs.items()):\n        if key.startswith(keyword + '_'):\n            to_kwargs[key.replace(keyword + '_', '')] = value\n            if clean_origin:\n                del from_kwargs[key]\n    return to_kwargs\n```",
        "rewrite": "```\ndef kwargs_from_keyword(from_kwargs, to_kwargs, keyword, clean_origin=True):\n    for key in list(from_kwargs.keys()):\n        if key.startswith(f\"{keyword}_\"):\n            to_kwargs[key[len(keyword) + 1:]] = from_kwargs.pop(key) if clean_origin else from_kwargs[key]\n    return to_kwargs\n```"
    },
    {
        "original": "```\nclass ActionExecutor:\n    def __init__(self):\n        self.actions = {}\n\n    def register_action(self, action_name, func):\n        self.actions[action_name] = func\n\n    def _RunAction(self, rule, client_id):\n        count = 0\n        for action in rule['actions']:\n            if action['name'] in self.actions:\n                self.actions[action['name']](client_id)\n                count += 1\n        return count\n```",
        "rewrite": "Here is the revised code:\n\n```\nclass ActionExecutor:\n    def __init__(self):\n        self.actions = {}\n\n    def register_action(self, name: str, func):\n        self.actions[name] = func\n\n    def run_action(self, rule: dict, client_id: int) -> int:\n        count = 0\n        for action in rule.get('actions', []):\n            if action.get('name') in self.actions:\n                self.actions[action['name']](client_id)\n                count += 1\n        return count\n```"
    },
    {
        "original": "```\nimport docker\n\nclass DockerClient:\n    def __init__(self):\n        self.client = docker.from_env()\n\n    def df(self):\n        try:\n            info = self.client.info()\n            return {\n                'Images': info['Images'],\n                'Containers': info['Containers'],\n                'Volumes': len(self.client.volumes.list()),\n                'Networks': len(self.client.networks.list())\n            }\n        except docker.errors.APIError as e:\n            raise e\n```",
        "rewrite": "Here is the revised code:\n\n```\nimport docker\nfrom docker.errors import APIError\n\nclass DockerClient:\n    def __init__(self):\n        self.client = docker.from_env()\n\n    def df(self):\n        try:\n            info = self.client.info()\n            volumes = self.client.volumes.list()\n            networks = self.client.networks.list()\n            return {\n                'Images': info['Images'],\n                'Containers': info['Containers'],\n                'Volumes': len(volumes),\n                'Networks': len(networks)\n            }\n        except APIError as e:\n            raise\n```"
    },
    {
        "original": "```\ndef file_extension(category=None):\n    extensions = {\n        'audio': ['mp3'],\n        'image': ['jpg', 'jpeg', 'png', 'gif'],\n        'office': ['docx', 'pdf', 'pptx'],\n        'text': ['txt', 'doc'],\n        'video': ['mp4']\n    }\n    if category:\n        return extensions.get(category.lower(), [])\n    else:\n        return []\n```",
        "rewrite": "Here is the revised code:\n\n```\ndef file_extension(category=None):\n    extensions = {\n        \"audio\": [\"mp3\", \"wav\"],\n        \"image\": [\"jpg\", \"jpeg\", \"png\", \"gif\", \"bmp\"],\n        \"office\": [\"docx\", \"pdf\", \"pptx\", \"xls\"],\n        \"text\": [\"txt\", \"doc\"],\n        \"video\": [\"mp4\", \"avi\"]\n    }\n    return extensions.get(category.lower(), []) if category else []\n```"
    },
    {
        "original": "```\ndef _gti_dirint_gte_90(poa_global, aoi, solar_zenith, solar_azimuth,\n                       surface_tilt, times, kt_prime,\n                       pressure=101325., temp_dew=None, albedo=.25):\n    import numpy as np\n    \n    # Calculate air mass\n    am = pressure / (101325 * np.exp(-0.000121 * surface_tilt))\n    \n    # Calculate relative air mass\n    mam = am /",
        "rewrite": "Here is the revised code:\n\n```\ndef _gti_dirint_gte_90(poa_global, aoi, solar_zenith, solar_azimuth,\n                       surface_tilt, times, kt_prime,\n                       pressure=101325., temp_dew=None, albedo=.25):\n    import numpy as np\n    \n    am = pressure / (101325 * np.exp(-0.000121 * surface_tilt))\n    \n    mam = am / 1.0\n```"
    },
    {
        "original": "```\nclass RDFURN:\n    def __init__(self, value):\n        self.value = value\n\nclass Client:\n    def ListChildren(self, urn, limit=None, age=\"NEWEST_TIME\"):\n        # assuming we have a function get_children that returns all children\n        all_children = self.get_children(urn)\n        \n        if age == \"ALL_TIMES\":\n            filtered_children = all_children\n        elif age == \"NEWEST_TIME\":\n            filtered_children = [all_children[0]]",
        "rewrite": "Here is the revised code:\n\n```\nclass RDFURN:\n    def __init__(self, value):\n        self.value = value\n\nclass Client:\n    def __init__(self):\n        pass\n\n    def get_children(self, urn):\n        # implement your logic to get children here\n        pass\n\n    def ListChildren(self, urn, limit=None, age=\"NEWEST_TIME\"):\n        all_children = self.get_children(urn)\n        \n        if age == \"ALL_TIMES\":\n            filtered_children = all_children\n        elif age == \"NEWEST_TIME\":\n            filtered_children = [all_children[0]]\n        \n        if limit is"
    },
    {
        "original": "```\ndef _convert_validators_to_mapping(validators):\n    validator_mapping = {}\n    for validator in validators:\n        key = (str(validator[\"check\"]), validator[\"comparator\"])\n        validator_mapping[key] = validator\n    return validator_mapping\n```",
        "rewrite": "```\ndef _convert_validators_to_mapping(validators):\n    return {(str(v[\"check\"]), v[\"comparator\"]): v for v in validators}\n```"
    },
    {
        "original": "```\ndef InterpolatePath(path, knowledge_base, users=None, path_args=None, depth=0):\n    if path_args is None:\n        path_args = {}\n    if users is None:\n        user_path = knowledge_base.interpolate_string(path, **path_args)\n        return user_path\n    else:\n        result = []\n        for user in users:\n            user_path_args = path_args.copy()\n            user_path_args['user'] = user\n            user_path = knowledge_base.interpolate_string(path",
        "rewrite": "Here is the revised code:\n\n```\ndef interpolate_path(path, knowledge_base, users=None, path_args=None, depth=0):\n    if path_args is None:\n        path_args = {}\n    if users is None:\n        return knowledge_base.interpolate_string(path, path_args)\n    else:\n        return [knowledge_base.interpolate_string(path, {** **path_args , 'user': user}) for user in users]\n```"
    },
    {
        "original": "```\nimport numpy as np\n\ndef _fast_kde(x, cumulative=False, bw=4.5, xmin=None, xmax=None):\n    \n     from scipy.stats import gaussian_kde\n    \n     x = np.array(x)\n     if xmin is None:\n         xmin = np.min(x)\n     if xmax is None:\n         xmax = np.max(x)\n         \n     kde = gaussian_kde(dataset=x[:, np.newaxis], bw_method='silverman')\n     xi = np.linspace(xmin,xmax",
        "rewrite": "Here is the revised code:\n\n```\nimport numpy as np\nfrom scipy.stats import gaussian_kde\n\ndef fast_kde(x, cumulative=False, bw=4.5, xmin=None, xmax=None):\n    x = np.array(x)\n    if xmin is None:\n        xmin = np.min(x)\n    if xmax is None:\n        xmax = np.max(x)\n    kde = gaussian_kde(dataset=x[:, np.newaxis], bw_method='silverman')\n    xi = np.linspace(xmin, xmax, 400)\n    yi = kde(xi)\n    if cumulative:\n        yi = np.cumsum(yi) * (xi"
    },
    {
        "original": "```\ndef md_options_to_metadata(options):\n    metadata = {}\n    language = None\n    for option in options:\n        if option.startswith('language:'):\n            language = option.split('language:')[1].strip()\n        elif '=' in option:\n            key, value = option.split('=', 1)\n            metadata[key.strip()] = value.strip()\n    return language, metadata\n```",
        "rewrite": "```\ndef md_options_to_metadata(options):\n    metadata = {}\n    language = None\n    for option in options:\n        if ':' in option:\n            k, v = option.split(':', 1)\n            if k == 'language':\n                language = v.strip()\n            else:\n                metadata[k.strip()] = v.strip()\n        elif '=' in option:\n            k, v = option.split('=', 1)\n            metadata[k.strip()] = v.strip()\n    return language, metadata\n```"
    },
    {
        "original": "```\nfrom typing import Optional, Union, List\nfrom enum import Enum\n\nclass TraceKind(Enum):\n    PRECONDITION = 1\n    POSTCONDITION = 2\n\nclass TraceFrame:\n    def __init__(self, caller: str, callee: str, kind: TraceKind):\n        self.caller = caller\n        self.callee = callee\n        self.kind = kind\n\nclass Trace:\n    def __init__(self):\n        self.frames = []\n\n    def add_frame(self,",
        "rewrite": "Here is the revised code:\n\n```\nfrom typing import Optional, Union, List\nfrom enum import Enum\n\nclass TraceKind(Enum):\n    PRECONDITION = 1\n    POSTCONDITION = 2\n\nclass TraceFrame:\n    def __init__(self, caller: str, callee: str, kind: TraceKind):\n        self.caller = caller\n        self.callee = callee\n        self.kind = kind\n\nclass Trace:\n    def __init__(self):\n        self.frames: List[TraceFrame] = []\n\n    def add_frame(self, frame: TraceFrame) -> None:\n        self.frames.append(frame)\n```"
    },
    {
        "original": "```\nclass BatchGenerator:\n    def __init__(self, X, Y, batch_size):\n        self.X = X\n        self.Y = Y\n        self.batch_size = batch_size\n        self.index = 0\n\n    def new_batch(self):\n        start = self.index\n        end = min(start + self.batch_size, len(self.X))\n        \n        batch_X = self.X[start:end]\n        batch_Y = self.Y[start:end]\n        \n        self.index += self.batch_size",
        "rewrite": "Here is the revised code:\n\n```\nclass BatchGenerator:\n    def __init__(self, X, Y, batch_size):\n        self.X = X\n        self.Y = Y\n        self.batch_size = batch_size\n        self.index = 0\n\n    def new_batch(self):\n        start = self.index\n        end = min(start + self.batch_size, len(self.X))\n        \n        batch_X = self.X[start:end]\n        batch_Y = self.Y[start:end]\n        \n        if end == len(self.X):\n            self.index = 0\n        else:\n            self.index += self.batch_size\n        \n        return batch"
    },
    {
        "original": "```\ndef createSummary(self, log):\n    \"\"\"\n    Create nice summary logs.\n\n    @param log: log to create summary off of.\n    \"\"\"\n    result = {}\n    for entry in log:\n        key = entry['type']\n        if key not in result:\n            result[key] = 1\n        else:\n            result[key] += 1\n    return result\n```",
        "rewrite": "```\ndef createSummary(self, log):\n    return {entry['type']: entry['type'] in result and result[entry['type']] + 1 or 1 for entry in log}\n```"
    },
    {
        "original": "```\nimport requests\n\nclass GitRepository:\n    def __init__(self):\n        self.url = \"https://api.bitbucket.org/2.0\"\n    \n    def create_branch(self, project_key, repository, name, start_point, message=\"\"):\n        auth_token = (\"your_username\", \"your_password\")\n        \n\t\theaders = {\n\t\t\t\"Content-Type\": \"application/json\"\n\t\t}\n\t\t\n\t\tdata = {\n\t\t\t\"name\": name,\n\t\t\t\"start\": {\n\t\t\t",
        "rewrite": "Here is the revised code:\n```\nimport requests\n\nclass GitRepository:\n    def __init__(self, username, password):\n        self.url = \"https://api.bitbucket.org/2.0\"\n        self.auth_token = (username, password)\n\n    def create_branch(self, project_key, repository, name, start_point, message=\"\"):\n        headers = {\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"name\": name,\n            \"start\": {\n                \"type\": \"commit\",\n                \"hash\": start_point\n            },\n            \"message\": message\n        }\n        \n       "
    },
    {
        "original": "```python\ndef merge_option_dicts(old_opts, new_opts):\n    merged = {}\n    all_keys = set(list(old_OPTS.keys()) + list(new_OPTS.keys()))\n    \n    for key in all_keys:\n        merged[key] = {}\n        \n        if key in old_OPTS:\n            merged[key].update(old_OPTS[key])\n        \n        if key in new_OPTS:\n            merged[key].update(newOpts[key])\n    \n    return merged\n\n# Test case\nold.opts = {'a':{'x':'old','",
        "rewrite": "Here is the revised code:\n\n```python\ndef merge_option_dicts(old_opts, new_opts):\n    merged = {}\n    all_keys = set(list(old_opts.keys()) + list(new_opts.keys()))\n    \n    for key in all_keys:\n        merged[key] = {}\n        merged[key].update(old_opts.get(key, {}))\n        merged[key].update(new_opts.get(key, {}))\n    \n    return merged\n\n# Test case\nold_opts = {'a':{'x':'old'}, 'b':{'y':'old'}}\nnew_opts = {'a':{'x':'new', 'z':'new'}, 'c':{'w':'new'}}\n\nprint("
    },
    {
        "original": "```python\nimport requests\nfrom gitlab.exceptions import GitlabAuthenticationError, GitlabGetError\n\nclass RESTObject:\n    pass\n\nclass GitLabManager:\n    def __init__(self, url, token):\n        self.url = url\n        self.token = token\n\n    def get(self, file_path, ref, **kwargs):\n        headers = {'Authorization': f'Bearer {self.token}'}\n        params = {'ref_name': ref}\n        \n        if 'sudo' in kwargs",
        "rewrite": "Here is the revised code:\n\n```python\nimport requests\nfrom gitlab.exceptions import GitlabAuthenticationError, GitlabGetError\n\nclass RESTObject:\n    pass\n\nclass GitLabManager:\n    def __init__(self, url, token):\n        self.url = url\n        self.token = token\n\n    def get(self, file_path, ref, **kwargs):\n        headers = {'Authorization': f'Bearer {self.token}'}\n        params = {'ref_name': ref}\n        \n        if 'sudo' in kwargs:\n            headers['Sudo'] = kwargs['sudo']\n        \n        response = requests.get(f'{self.url"
    },
    {
        "original": "```\ndef clean_recipe_build(self, args):\n    import os\n    import shutil\n    recipe_build_dir = os.path.join('build', args.recipe_name)\n    if os.path.exists(recipe_build_dir):\n        shutil.rmtree(recipe_build_dir)\n    print(f\"Deleted build files for recipe {args.recipe_name}\")\n```",
        "rewrite": "```\nimport os\nimport shutil\n\ndef clean_recipe_build(self, args):\n    recipe_build_dir = os.path.join('build', args.recipe_name)\n    if os.path.isdir(recipe_build_dir):\n        shutil.rmtree(recipe_build_dir)\n        print(f\"Deleted build files for recipe {args.recipe_name}\")\n```"
    },
    {
        "original": "```\ndef calculate_bias_shape(input_shape, bias_dims):\n    if 0 in bias_dims:\n        raise ValueError(\"Cannot add bias over the minibatch dimension\")\n    bias_shape = [input_shape[i] if i in bias_dims else 1 for i in range(len(input_shape))]\n    return tuple(bias_shape)\n```",
        "rewrite": "```\ndef calculate_bias_shape(input_shape, bias_dims):\n    if 0 in bias_dims:\n        raise ValueError(\"Cannot add bias over the minibatch dimension\")\n    return tuple(1 if i not in bias_dims else dim for i, dim in enumerate(input_shape))\n```"
    },
    {
        "original": "```\ndef read_metadata(text, ext):\n    if ext == 'txt':\n        lines = text.split('\\n')\n        metadata = {}\n        for line in lines:\n            if ':' in line:\n                key, value = line.split(':', 1)\n                metadata[key.strip()] = value.strip()\n        return metadata\n    else:\n        return {}\n```",
        "rewrite": "```\ndef read_metadata(text, ext):\n    if ext == 'txt':\n        return {k.strip(): v.strip() for line in text.split('\\n') for k, v in [line.split(':', 1)] if ':' in line}\n    else:\n        return {}\n```"
    },
    {
        "original": "```\ndef _is_process_filtered(self, process, key=None):\n    \"\"\"\n    Return True if the process[key] should be filtered according to the current filter\n    \"\"\"\n    # Assuming self.filter is set elsewhere in your class\n    if not hasattr(self, 'filter'):\n        raise ValueError(\"Filter is not defined\")\n\n    if key is None:\n        return any(str(d) in str(self.filter) for d in process.values())\n    else:\n        return str(process.get(key)) in str",
        "rewrite": "Here is the revised code:\n\n```\ndef _is_process_filtered(self, process, key=None):\n    if not hasattr(self, 'filter'):\n        raise ValueError(\"Filter is not defined\")\n\n    if key is None:\n        return any(str(d) in str(self.filter) for d in process.values())\n    else:\n        return str(process.get(key)) in str(self.filter)\n```"
    },
    {
        "original": "```\ndef modulation_type(self, value: int):\n    modulation_types = [\"ASK\", \"FSK\", \"PSK\", \"APSK (QAM)\"]\n    if 0 <= value <= 3:\n        return modulation_types[value]\n    else:\n        return None\n```",
        "rewrite": "```\ndef modulation_type(self, value: int) -> str | None:\n    modulation_types = [\"ASK\", \"FSK\", \"PSK\", \"APSK (QAM)\"]\n    return modulation_types[value] if 0 <= value < 4 else None\n```"
    },
    {
        "original": "```\ndef load(self, fname):\n    with open(fname, 'r') as f:\n        self.signatures = [line.strip() for line in f.readlines()]\n```",
        "rewrite": "```\ndef load(self, fname):\n    with open(fname, 'r') as f:\n        self.signatures = [line.rstrip() for line in f]\n```"
    },
    {
        "original": "```python\nclass Server:\n    def __init__(self):\n        self.rooms = {}\n\n    def enter_room(self, sid, room, namespace=None):\n        if namespace is None:\n            namespace = self.__class__.__name__\n        if room not in self.rooms:\n            self.rooms[room] = set()\n        self.rooms[room].add((sid, namespace))\n```",
        "rewrite": "```\nclass Server:\n    def __init__(self):\n        self.rooms = {}\n\n    def enter_room(self, sid, room, namespace=None):\n        namespace = namespace or self.__class__.__name__\n        self.rooms.setdefault(room, set()).add((sid, namespace))\n```"
    },
    {
        "original": "```\ndef _get_args(self, **):\n    return {key: value for key, value in kwargs.items() if hasattr(self.__class__, key)}\n```",
        "rewrite": "```\ndef _get_args(self, **kwargs):\n    return {key: value for key, value in kwargs.items() if hasattr(self, key)}\n```"
    },
    {
        "original": "```\nfrom pyogram import Client\nfrom pyogram.types import Message, InlineKeyboardMarkup, ReplyKeyboardMarkup, ReplyKeyboardRemove, ForceReply\nfrom typing import Union\n\nclass MyClient(Client):\n    def edit_caption(self, caption: str, parse_mode: str = \"\", reply_markup: Union[InlineKeyboardMarkup, ReplyKeyboardMarkup, ReplyKeyboardRemove, ForceReply] = None) -> Message:\n        return self.edit_message_caption(chat_id=self.chat.id, message_id=self.message_id,c",
        "rewrite": "Here is the revised code:\n\n```\nfrom pyogram import Client\nfrom pyogram.types import Message, InlineKeyboardMarkup, ReplyKeyboardMarkup, ReplyKeyboardRemove, ForceReply\nfrom typing import Union\n\nclass MyClient(Client):\n    def edit_caption(self, caption: str, parse_mode: str = \"\", reply_markup: Union[InlineKeyboardMarkup, ReplyKeyboardMarkup, ReplyKeyboardRemove, ForceReply] = None) -> Message:\n        return self.edit_message_caption(chat_id=self.chat.id, message_id=self.message.message_id, caption=caption, parse_mode=parse_mode, reply_markup=reply_markup)\n```"
    },
    {
        "original": "```\nimport numpy as np\nfrom scipy.linalg import kron\n\ndef _flip_kron_order(mat4x4: np.ndarray) -> np.ndarray:\n    # Get the size of sub-matrices\n    n = int(np.sqrt(mat4x4.shape[0]))\n\n    # Reshape mat4x4 into 3D array (n*n matrices)\n    mats = mat4x4.reshape(n, n, n, n)\n\n    # Flip kron order by swapping last two axes",
        "rewrite": "Here is the revised code:\n\n```\nimport numpy as np\nfrom scipy.linalg import kron\n\ndef _flip_kron_order(mat4x4: np.ndarray) -> np.ndarray:\n    n = int(np.sqrt(mat4x4.shape[0]))\n    mats = mat4x4.reshape(n, n, n, n)\n    return mats.transpose(0, 1, 3, 2).reshape(-1, mat4x4.shape[1])\n```"
    },
    {
        "original": "```\ndef pretty_print_schedule(self, hyperband_schedule, describe_hyperband=True):\n    print(\" Hyper-Band Parameters: \")\n    print(\"     - Try {} possible sets of hyperparameters\".format(len(hyperband_schedule)))\n    if describe_hyperband:\n        print(\"     - With an average of {} iterations per trial\".format(sum([len(trial) for trial in hyperband_schedule]) / len(hyperband_schedule)))\n    print(\"\")\n    \n    max_r = max(max(trial)",
        "rewrite": "Here is the revised code:\n\n```\ndef pretty_print_schedule(self, hyperband_schedule, describe_hyperband=True):\n    print(\" Hyper-Band Parameters: \")\n    print(\"     - Try {} possible sets of hyperparameters\".format(len(hyperband_schedule)))\n    if describe_hyperband:\n        avg_iterations = sum(len(trial) for trial in hyperband_schedule) / len(hyperband_schedule)\n        print(\"     - With an average of {:.2f} iterations per trial\".format(avg_iterations))\n    print(\"\")\n    \n    max_r = max(max(trial) for trial in hyperband_schedule)\n```"
    },
    {
        "original": "```\nclass Matrix:\n    def __init__(self, a, b, c, d, e, f):\n        self.a = a\n        self.b = b\n        self.c = c\n        self.d = d\n        self.e = e\n        self.f = f\n\n    def shorthand(self):\n        return (self.a, self.b, self.c, self.d, self.e, self.f)\n```",
        "rewrite": "```\nfrom dataclasses import dataclass\n\n@dataclass\nclass Matrix:\n    a: int\n    b: int\n    c: int\n    d: int\n    e: int\n    f: int\n\n    def shorthand(self):\n        return (self.a, self.b, self.c, self.d, self.e, self.f)\n```"
    },
    {
        "original": "```python\ndef is_cyclic(graph):\n    visited = set()\n    rec_stack = set()\n\n    def dfs(node):\n        visited.add(node)\n        rec_stack.add(node)\n\n        for neighbor in graph.get(node, []):\n            if neighbor not in visited:\n                if dfs(neighbor):\n                    return True\n            elif neighbor in rec_stack:\n                return True\n\n        rec_stack.remove(node)\n        return False\n\n    for node in graph:\n        if node not in visited:\n            if dfs",
        "rewrite": "```\ndef is_cyclic(graph):\n    visited = set()\n    rec_stack = set()\n\n    def dfs(node):\n        visited.add(node)\n        rec_stack.add(node)\n\n        for neighbor in graph.get(node, []):\n            if neighbor not in visited:\n                if dfs(neighbor):\n                    return True\n            elif neighbor in rec_stack:\n                return True\n\n        rec_stack.remove(node)\n        return False\n\n    for node in graph:\n        if node not in visited:\n            if dfs(node):\n                return True\n    return False"
    },
    {
        "original": "```python\nfrom email import policy\nfrom email.parser import BytesParser\n\ndef get_header_items(self):\n    \"\"\"Get an iterable list of key/value pairs representing headers.\"\"\"\n    parser = BytesParser(policy=policy.default)\n    msg = parser.parsestr(self.request_text)\n    return [(k, v) for k, v in msg.items()]\n```",
        "rewrite": "```\nfrom email import policy\nfrom email.parser import BytesParser\n\nclass EmailParser:\n    def __init__(self, request_text):\n        self.request_text = request_text\n\n    def get_header_items(self):\n        parser = BytesParser(policy=policy.default)\n        msg = parser.parsestr(self.request_text)\n        return [(k, v) for k, v in msg.items()]\n\n# usage\nparser = EmailParser('your_email_content_here')\nprint(parser.get_header_items())\n```"
    }
]