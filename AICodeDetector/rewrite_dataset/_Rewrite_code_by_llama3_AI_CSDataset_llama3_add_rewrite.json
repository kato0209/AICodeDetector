[
    {
        "original": "```python\nfrom kafka import KafkaConsumer\n\ndef beginning_offsets(partitions):\n    consumer = KafkaConsumer()\n    offsets = {}\n    for p in partitions:\n        topic_partition = p.topic, p.partition\n        try:\n            offset = consumer.beginning_offset(topic_partition)\n            offsets[p] = offset\n        except Exception as e:\n            if isinstance(e, UnsupportedVersionError) or isinstance(e, KafkaTimeoutError):\n                raise e\n    return offsets\n```",
        "rewrite": "```python\nfrom kafka import KafkaConsumer, UnsupportedVersionError, KafkaTimeoutError\n\ndef get_beginning_offsets(partitions):\n    consumer = KafkaConsumer(bootstrap_servers=[ partisanry ] )\n    offsets = {}\n    for partition in partitions:\n        try:\n            offset = consumer.beginning_offsets([(partition.topic, partition.partition)])[partition.topic][partition.partition].offset\n            offsets[partition] = offset\n        except (UnsupportedVersionError, KafkaTimeoutError) as e:\n            raise from None if isinstance(e, UnsupportedVersionError) else e \n    return offsets\n```"
    },
    {
        "original": "```\ndef _get_values(cls, diff_dict, type='new'):\n    return {key: value[0] if type == 'new' else value[1] for key, value in diff_dict.items() if len(value) == 2}\n```",
        "rewrite": "```python\ndef get_values(diff_dict, value_type='new'):\n    if value_type not in ('new', 'old'):\n        raise ValueError(\"Invalid value type. It should be either 'new' or 'old'.\")\n\n    return {key: (value[0] if value_type == 'new' else value[-1]) \n            for key, value in diff_dict.items() \n            if isinstance(value, list) and len(value) > 0}\n```"
    },
    {
        "original": "```\ndef get_ref(cls, state, obj_alloc_id, field_class_name, field_name, field_type):\n    \"\"\"\n    Resolve the field within the given state.\n    \"\"\"\n    obj = state[obj_alloc_id]\n    if not hasattr(obj, field_class_name):\n        raise AttributeError(f\"Object {obj_alloc_id} does not have class {field_class_name}\")\n    field_cls = getattr(obj, field_class_name)\n    if not hasattr(field_cls, field_name):\n        raise AttributeError(f\"",
        "rewrite": "```python\ndef get_ref(cls, state, obj_alloc_id, field_class_name, field_type, field_name):\n    if obj_alloc_id not in state:\n        return None\n\n    obj = state[obj_alloc_id]\n    if not hasattr(obj, field_class_name):\n        return None\n\n    field_cls = getattr(obj, field_class_name)\n    instance = None\n    if hasattr(field_cls, 'get') and callable(getattr(field_cls, 'get')):\n        instance = getattr(field_cls(), '_inst')\n    elif hasattr(field_cls(), '_inst'):\n        instance = getattr(field_cls(), '_inst')\n\n    if not instance:\n"
    },
    {
        "original": "```\ndef pd_coords(self, comp):\n    n_elements = len(comp)\n    coords = [0] * (n_elements - 1)\n    sum_comp = sum(comp)\n    \n    for i in range(n_elements - 1):\n        coords[i] = comp[i] / sum_comp\n    \n    return coords\n```",
        "rewrite": "```python\ndef pd_coords(self, comp):\n    total = sum(comp)\n    return [i / total for i in comp[:-1]]\n```"
    },
    {
        "original": "```\ndef relative_ref(self, baseURI):\n    base_path = baseURI.split('/')\n    target_path = self.path.split('/')\n    i = 0\n    while i < len(base_path) and i < len(target_path) and base_path[i] == target_path[i]:\n        i += 1\n    rel_ref = '../' * (len(base_path) - i) + '/'.join(target_path[i:])\n    return rel_ref if rel_ref else '.'\n```",
        "rewrite": "```python\ndef relative_ref(self, base_uri):\n    base_parts = base_uri.split('/')\n    target_parts = self.path.split('/')\n    common_prefix_length = sum(a == b for a, b in zip(base_parts, target_parts))\n    rel_ref = '../' * (len(base_parts) - 1 - common_prefix_length) + '/'.join(target_parts[common_prefix_length:])\n    return '.' if rel_ref == '' else rel_ref\n```"
    },
    {
        "original": "```\ndef is_enhanced_rr_cap_valid(self):\n    open_messages_sent = self.open_messages_sent\n    open_messages_received = self.open_messages_received\n\n    if open_messages_sent and open_messages_received:\n        return 'enhanced-route-refresh-capability' in open_messages_sent and 'enhanced-route-refresh-capability' in open_messages_received\n    else:\n        return False\n```",
        "rewrite": "```python\ndef is_enhanced_rr_cap_valid(self):\n    required_attributes = ('open_messages_sent', 'open_messages_received')\n    required_capability = 'enhanced-route-refresh-capability'\n    \n    return (all(attr in self.__dict__ for attr in required_attributes) and \n            all(required_capability in getattr(self, attr) for attr in required_attributes))\n```"
    },
    {
        "original": "```\ndef parse_osm_nodes_paths(osm_data):\n    nodes = {}\n    paths = {}\n\n    if 'elements' in osm_data:\n        for element in osm_data['elements']:\n            if element['type'] == 'node':\n                nodes[element['id']] = element\n            elif element['type'] == 'way':\n                way_id = element['id']\n                ways_tags = {k: v for k, v in element.items() if k != 'nodes' and k !=",
        "rewrite": "```python\ndef parse_osm_nodes_paths(osm_data):\n    nodes = {}\n    paths = {}\n\n    if 'elements' in osm_data:\n        for element in osm_data['elements']:\n            if element['type'] == 'node':\n                nodes[element['id']] = {'id': element['id'], 'lat': element['lat'], 'lon': element ['lon']}\n            elif element['type'] == 'way':\n                way_id = element['id']\n                ways_tags = {k: v for k, v in element.items() if k not in ['nodes',]}\n                ways_refs =[n for n in ("
    },
    {
        "original": "```python\nfrom pymatgen import Molecule as MoleculeClass\nfrom itertools import permutations\n\ndef get_best_electronegativity_anonymous_mapping(struct1, struct2):\n    # Get all possible permutations of mapping between species of two structures\n    perms = list(permutations(range(len(struct2.species)), len(struct1.species)))\n\n    # Initialize minimum difference in electronegativity and best mapping\n    min_diff = float('inf')\n    best_mapping = None\n\n    # Iterate over",
        "rewrite": "```python\nfrom pymatgen import Molecule, Element\nfrom itertools import permutations\n\ndef get_best_electronegativity_anonymous_mapping(struct1, struct2):\n    perms = list(permutations(range(len(struct2.species))))\n    min_diff = float('inf')\n    best_mapping = None\n\n    for perm in perms:\n        diff = sum(abs(Element(species).X - Element(struct2.species[i]).X) for i, species in enumerate(struct1.species))\n        if diff < min_diff:\n            min_diff = diff\n            best_mapping = perm\n\n    return best_mapping\n```"
    },
    {
        "original": "```\nfrom typing import Callable, Tuple\n\nclass HPackHeaders:\n    pass\n\nclass HPackIndexedHdr(HPackHeaders):\n    pass\n\nclass HPackLitHdrFldWithoutIndexing(HPackHeaders):\n    pass\n\nclass HPackLitHdrFldWithIncrIndexing(HPackHeaders):\n    pass\n\n\ndef _convert_a_header_to_a_h2_header(\n    hdr_name: str,\n    hdr_value: str,\n    is_sensitive: Callable[[str, str], bool",
        "rewrite": "```python\nfrom typing import Callable, Tuple\n\nclass HPackHeaders:\n    def __init__(self):\n        pass\n\n    @staticmethod\n    def convert_header_to_h2_header(\n        hdr_name: str,\n        hdr_value: str,\n        is_sensitive: Callable[[str, str], bool]\n    ) -> Tuple[str, str]:\n        return (hdr_name, hdr_value) if not is_sensitive(hdr_name, hdr_value) else (hdr_name[:1] + '*', '*')\n\n\nclass HPackIndexedHdr(HPackHeaders):\n    def __init__(self):\n        super().__init__()\n\n\nclass HPackLitHdr"
    },
    {
        "original": "```python\nclass BigchainTransactionCreator:\n    def create(cls, tx_signers, recipients, metadata=None, asset=None):\n        from bigchaindb.common.transaction import Transaction\n        \n        # Initialize an empty transaction object \n        transaction = Transaction()\n\n        # Set transaction type to 'CREATE'\n        transaction.operation = 'CREATE'\n\n        # Add signers to transaction inputs \n        for signer in tx_signers:\n            transaction.add_input(signer)\n\n        # Add recipients and amounts to transaction outputs \n       ",
        "rewrite": "```python\nfrom bigchaindb.common.transaction import Transaction\n\nclass BigchainTransactionCreator:\n    @classmethod\n    def create(cls, tx_signers, recipients, metadata=None, asset=None):\n        transaction = Transaction(operation='CREATE')\n\n        for signer in tx_signers:\n            transaction.add_input(signer)\n\n        for recipient, amount in recipients.items():\n            transaction.add_output(recipient, amount)\n\n        if metadata:\n            transaction.metadata = metadata\n\n        if asset:\n            transaction.asset = asset\n\n        return transaction\n```"
    },
    {
        "original": "```\nfrom datetime import datetime\nimport pytz\n\ndef utc_dt_to_local_dt(dtm):\n    utc_dt = datetime.strptime(dtm, '%Y-%m-%d %H:%M:%S')\n    utc_dt = utc_dt.replace(tzinfo=pytz.UTC)\n    local_dt = utc_dt.astimezone()\n    return local_dt.strftime('%Y-%m-%d %H:%M:%S %Z%z')\n```",
        "rewrite": "```python\nfrom datetime import datetime, timezone\nimport pytz\n\ndef utc_to_local(dtm, tz_str):\n    dt_obj = datetime.strptime(dtm, '%Y-%m-%d %H:%M:%S')\n    dt_obj = dt_obj.replace(tzinfo=timezone.utc)\n    tz_obj = pytz.timezone(tz_str)\n    local_dt_obj = dt_obj.astimezone(tz=tz_obj)\n    return local_dt_obj.strftime('%Y-%m-%d %H:%M:%S %Z%z')\n\nprint(utc_to_local('2022-01-01 00:00:00"
    },
    {
        "original": "```\ndef _getScriptSettingsFrom IniFile(policy_info):\n    # Open and read the file\n    with open(policy_info, 'r') as f:\n        content = f.read()\n\n    # Initialize variables\n    scripts = {}\n    current_script = None\n\n    # Parse lines\n    for line in content.splitlines():\n        line = line.strip()\n        \n        if line.startswith('[') and ']' in line:\n            # Section header found, extract script name\n            start_br",
        "rewrite": "```python\ndef _get_script_settings_from_file(policy_info):\n    \"\"\"\n    Parse script settings from a policy info file.\n    \n    Args:\n        policy_info (str): File path to the policy info file.\n    \n    Returns:\n        dict: Script settings extracted from the file.\n    \"\"\"\n    \n    try:\n        with open(policy_info, 'r') as f:\n            content = f.read()\n    except FileNotFoundError:\n        return {}\n    \n    scripts = {}\n    current_script = None\n    \n    for line in content.splitlines():\n        line = line.strip()\n        \n        if line.startswith('[') and ']' in line:\n           "
    },
    {
        "original": "```\ndef _get_triplet_scores(self, triangles_list):\n    scores = {}\n    for triangle in triangles_list:\n        triangle_set = frozenset(triangle)\n        # assuming the score calculation is a placeholder, replace with actual logic\n        score = len(triangle) * 2.0\n        scores[triangle_set] = score\n    return scores\n```",
        "rewrite": "```python\ndef _get_triplet_scores(self, triangles_list):\n    return {frozenset(triangle): len(triangle) * 2 for triangle in triangles_list}\n```"
    },
    {
        "original": "```\nasync def vcx_messages_update_status(msg_json: str):\n    import json\n    import asyncio\n    from aiohttp import ClientSession\n\n    async with ClientSession() as session:\n        msg_data = json.loads(msg_json)\n        connection_id = msg_data['connection_id']\n        messages = msg_data['messages']\n\n        for message in messages:\n            url = f'https://example.com/update_message_status/{connection_id}'\n            data = {'message_id': message['uid'], 'status",
        "rewrite": "```python\nimport json\nfrom aiohttp import ClientSession\n\nasync def vcx_messages_update_status(msg_json: str) -> None:\n    async with ClientSession() as session:\n        msg_data = json.loads(msg_json)\n        connection_id = msg_data['connection_id']\n        messages = msg_data.get('messages', [])\n\n        url = f'https://example.com/update_message_status/{connection_id}'\n\n        tasks = [\n            session.post(url, json={'message_id': message['uid'], 'status': 'updated'})\n            for message in messages\n        ]\n\n        await asyncio.gather(*(task.json() for task in tasks))\n"
    },
    {
        "original": "```\nimport socket\nimport time\n\nclass IsoTPSocket:\n    def __init__(self):\n        self.receive_buffer = b''\n\n    def recv_with_timeout(self, timeout=1):\n        start_time = time.time()\n        while True:\n            if self.receive_buffer:\n                return self.receive_buffer.pop(0)\n            elif time.time() - start_time > timeout:\n                return None\n```",
        "rewrite": "```python\nimport socket\nimport select\nfrom queue import Queue, Empty\n\nclass IsoTPSocket(socket.socket):\n    def __init__(self, *connection):\n        super().__init__(socket.AF_INET, socket.SOCK_STREAM)\n        self.connect(connection)\n        self.receive_buffer = Queue()\n\n    def recv_with_timeout(self, timeout=1):\n        readable, _, _ = select.select([self], [], [], timeout)\n        if readable:\n            data = self.recv(4096)\n            self.receive_buffer.queue.extend(data)\n            return data\n        else:\n            return None\n\n    def recv_from_queue(self):\n        try:\n            return"
    },
    {
        "original": "```\nimport math\n\ndef carmichael_of_factorized(f_list):\n    lambda_val = 1\n    for p, e in f_list:\n        lambda_val = lcm(lambda_val, (p-1) * (p**(e-1)))\n    return lambda_val\n\ndef gcd(a, b):\n    while b:\n        a, b = b, a % b\n    return a\n\ndef lcm(a, b):\n    return a * b // gcd(a, b)\n```",
        "rewrite": "```python\nimport math\n\ndef carmichael_of_factorized(f_list):\n    lambda_val = 1\n    for p, e in f_list:\n        lambda_val = lcm(lambda_val, euler_totient(p, e))\n    return lambda_val\n\ndef gcd(a, b):\n    while b:\n        a, b = b, a % b\n    return a\n\ndef lcm(a, b):\n    return a * b // gcd(a,b)\n\ndef euler_totient(n,e):\n    if n == 2 and e >= 3:\n        phi_n = 2**(e-2)\n        if e >= "
    },
    {
        "original": "```\nimport requests\n\ndef absent(name, profile=\"splunk\"):\n    url = f\"https://{profile}.com/api/services/search/jobs/{name}\"\n    response = requests.delete(url, auth=(\"username\", \"password\"))\n    if response.status_code == 200:\n        return True\n    else:\n        return False\n```",
        "rewrite": "```python\nimport requests\n\ndef delete_job(name: str, profile: str = \"splunk\", username: str = \"your_username\", password: str = \"your_password\") -> bool:\n    url = f\"https://{profile}.com/api/services/search/jobs/{name}\"\n    try:\n        response = requests.delete(url, auth=(username, password))\n        return response.status_code == 200\n    except requests.RequestException as e:\n        raise Exception(f\"Failed to delete job: {e}\")\n```"
    },
    {
        "original": "```\ndef GetNotificationsForAllShards(self, queue):\n    notifications = []\n    for shard in self.GetShardNames(queue):\n        notifications.extend(self.GetNotificationsForShard(queue, shard))\n    return notifications\n```",
        "rewrite": "```python\ndef get_notifications_for_all_shards(self, queue):\n    return [\n        notification\n        for shard in self.get_shard_names(queue)\n        for notification in self.get_notifications_for_shard(queue, shard)\n    ]\n```"
    },
    {
        "original": "```\nfrom sympy import symbols, Eq, solve\n\nclass FunctionMatcher:\n    def __init__(self, functions):\n        self.functions = functions\n\n    def differing_functions_with_consts(self):\n        matches = []\n        for i in range(len(self.functions)):\n            for j in range(i + 1, len(self.functions)):\n                x = symbols('x')\n                eq1 = Eq(eval(self.functions[i]), 0)\n                eq2 = Eq(eval(self.functions[j]), 0)\n               ",
        "rewrite": "```python\nfrom sympy import symbols, Eq, solve\n\nclass FunctionMatcher:\n    def __init__(self, functions):\n        self.functions = functions\n        self.x = symbols('x')\n\n    def differing_functions_with_consts(self):\n        matches = []\n        for i in range(len(self.functions)):\n            for j in range(i + 1, len(self.functions)):\n                eq1 = Eq(eval(self.functions[i.recvVertexAttribArrayditionerstr_(use_sympy=True), 'x': self.x})), 0)\n                eq2 = Eq(eval(self.functionscallb.UnlockScstdlib{exprD-ln waypointschecked_startangle"
    },
    {
        "original": "```\nclass EOPatchSaver:\n    def save(self, eopatch, use_tmp=True):\n        if use_tmp:\n            # Save to temporary file\n            with open(\"temp.eopatch\", \"wb\") as f:\n                pickle.dump(eopatch, f)\n        else:\n            # Save to intended location\n            with open(\"eopatch.eopatch\", \"wb\") as f:\n                pickle.dump(eopatch, f)\n```",
        "rewrite": "```python\nimport os\nimport pickle\n\nclass EOPatchSaver:\n    def __init__(self, tmp_dir: str, final_dir: str):\n        self.tmp_dir = tmp_dir\n        self.final_dir = final_dir\n\n    def save(self, eopatch: object, filename: str, use_tmp: bool = True) -> None:\n        filepath = os.path.join(self.tmp_dir if use_tmp else self.final_dir, f\"{filename}.eopatch\")\n        \n        with open(filepath, \"wb\") as f:\n            pickle.dump(eopatch, f)\n```"
    },
    {
        "original": "```\nclass StateTrie:\n    def __init__(self):\n        self.trie = {}\n\n    def _addAttr(self, txn, isCommitted=False) -> None:\n        did, attribute_name, data_type, data = txn\n        if data_type == 'RAW':\n            key = f\"{did}{attribute_name}\"\n            self.trie[key] = hash(data)\n        elif data_type == 'ENC':\n            key = f\"{did}{hash(attribute_name)}\"\n            self.tr",
        "rewrite": "```python\nclass StateTrie:\n    def __init__(self):\n        self.trie = {}\n\n    def _add_attr(self, txn) -> None:\n        did, attribute_name, data_type, data = txn\n        if data_type == 'RAW':\n            key = f\"{did}{attribute_name}\"\n        elif data_type == 'ENC':\n            key = f\"{did}{hash(attribute_name)}\"\n        else:\n            raise ValueError(\"Invalid data type\")\n        \n        self.trie[key] = hash(data)\n```"
    },
    {
        "original": "```\nimport os\nimport zipfile\nimport xml.etree.ElementTree as ET\n\ndef _find_packages(root):\n    for subdir, dirs, files in os.walk(root):\n        for file in files:\n            if file.endswith('.zip'):\n                zf = zipfile.ZipFile(os.path.join(subdir, file))\n                pkg_xml = ET.parse(zf.open('package.xml')).getroot()\n                yield (pkg_xml, zf, os.path.relpath(subdir, root))\n```",
        "rewrite": "```python\nimport os\nimport zipfile\nfrom xml.etree import ElementTree as ET\n\ndef find_packages(root: str) -> iter:\n    for entry in os.scandir(root):\n        if entry.is_dir():\n            for package_file in entry.iterdir():\n                if package_file.is_file() and package_file.name.endswith('.zip'):\n                    with zipfile.ZipFile(package_file.path) as zf:\n                        try:\n                            pkg_xml = ET.parse(zf.open('package.xml')).getroot()\n                            yield pkg_xml, zf, os.path.relpath(entry.path, root)\n                        except KeyError:\n                            pass  # ignore zip files without"
    },
    {
        "original": "```\nimport bluetooth\n\ndef srbt1(bt_address, pkts, *_args={}, **_kargs={}):\n    sock = bluetoothAMP.get_socket()\n    sock.connect((bt_address, 1))\n    sock.send(pkts)\n    data = sock.recv(1024)\n    return data\n```",
        "rewrite": "```python\nimport bluetooth\n\nclass Srbt:\n    def __init__(self, bt_address: str):\n        self.bt_address = bt_address\n        self.device = None\n        self.port = None\n        self.socket = None\n\n    def _discover_device(self):\n        devices = bluetooth.discover_devices(lookup_names=True)\n        if devices:\n            self.device = devices[0]\n            return True\n        else:\n            return False\n\n    def _get_port(self):\n        services = bluetooth.sd_inquire(self.device[0])\n        if services:\n            for service in services:\n                if len(service) > 1"
    },
    {
        "original": "```\nimport socket\nimport netifaces\n\nclass NetworkInterface:\n    def GetIPAddresses(self):\n        ip_array = []\n        for interface in netifaces.interfaces():\n            if interface == 'lo':  # ignore loopback interface\n                continue\n            lst = netifaces.ifaddresses(interface)\n            teste = {}\n            for item in lst:\n                if(item == 2): # AF_INET \n                    for thing in lst[item]:\n                        teste={\n                            \"iname\":interface,\n                           ",
        "rewrite": "```python\nimport socket\nimport netifaces\n\nclass NetworkInterface:\n    def get_ip_addresses(self):\n        ip_address_list = []\n        for interface in netifaces.interfaces():\n            if interface.startswith('lo'):\n                continue\n            addresses = netifaces.ifaddresses(interface)\n            for family, addr_type in [(socket.AF_INET, 'ipv4'), (socket.AF_INET6, 'ipv6')]:\n                try:\n                    addr_info = addresses[family][0]\n                    ip_address_list.append({\n                        'interface_name': interface,\n                        'ip_address': addr_info['addr'],\n                        'address_family': addr_type\n"
    },
    {
        "original": "```\ndef operate(self, point):\n    # Assuming operate function is defined elsewhere\n    pass\n\ndef are_symmetrically_related(self, point_a, point_b, tol=0.001):\n    \"\"\"\n    Checks if two points are symmetrically related.\n\n    Args:\n        point_a (3x1 array): First point.\n        point_b (3x1 array): Second point.\n        tol (float): Absolute tolerance for checking distance.\n\n    Returns:\n        True if self.operate(point",
        "rewrite": "```python\nclass SymmetryOperation:\n    def operate(self, point):\n        raise NotImplementedError(\"Subclass must implement this method\")\n\n    def are_symmetrically_related(self, point_a, point_b, tol: float = 0.001) -> bool:\n        raise NotImplementedError(\"Subclasses should override this for symmetry-specific logic\")\n```\n\nHowever if a clear symmetric rule is defined then the above implementation can be based on that else this alternative.\n\n```python\nimport math\n\nclass SymmetryOperation:\n    def operate(self, point):\n        raise NotImplementedError(\"Subclass must implement this method\")\n\n    def are_symmetrically_related(self,"
    },
    {
        "original": "```\ndef validate_rpc_host(ip):\n    \"\"\"\n    Validates the given ip for use as RPC server address.\n    \"\"\"\n    parts = ip.split(\".\")\n    if len(parts) != 4:\n        return False\n    for part in parts:\n        if not part.isdigit():\n            return False\n        i = int(part)\n        if i < 0 or i > 255:\n            return False\n    return True\n```",
        "rewrite": "```python\nimport ipaddress\n\ndef validate_rpc_host(ip):\n    try:\n        ipaddress.IPv4Address(ip)\n        return True\n    except ValueError:\n        return False\n```"
    },
    {
        "original": "```python\nimport subprocess\nimport logging\n\ndef find_available_interfaces():\n    \"\"\"\n    Returns the names of all open can/vcan interfaces using\n    the ``ip link list`` command. If the lookup fails, an error\n    is logged to the console and an empty list is returned.\n\n    :rtype: an iterable of :class:`str`\n    \"\"\"\n    \n    try:\n        output = subprocess.check_output([\"ip\", \"link\", \"list\"])\n        lines = output.decode(\"utf-",
        "rewrite": "```python\nimport subprocess\n\ndef find_available_interfaces():\n    try:\n        output = subprocess.check_output([\"ip\", \"-o\", \"link\", \"list\"])\n        return [line.split(\": \")[1] for line in output.decode(\"utf-8\").splitlines() if \"-can\" in line.lower()]\n    except subprocess.CalledProcessError as e:\n        print(f\"Command 'ip link list' failed with error code {e.returncode}\")\n    except Exception as e:\n        print(f\"Error: {str(e)}\")\n    return []\n```"
    },
    {
        "original": "```\nclass Server:\n    def __init__(self, namespace=None):\n        self.namespace = namespace\n        self.sessions = {}\n\n    def save_session(self, sid, session, namespace=None):\n        if namespace is None:\n            namespace = self.namespace\n        if namespace not in self.sessions:\n            self.sessions[namespace] = {}\n        self.sessions[namespace][sid] = session\n```",
        "rewrite": "```python\nclass Server:\n    def __init__(self, namespace=None):\n        self.namespace = namespace\n        self.sessions = {} if namespace is None else {namespace: {}}\n\n    def save_session(self, sid, session):\n        if self.namespace not in self.sessions:\n            self.sessions[self.namespace] = {}\n        self.sessions[self.namespace][sid] = session\n```"
    },
    {
        "original": "```\nfrom cryptography.hazmat.backends import default_backend\nfrom cryptography.hazmat.primitives import serialization\n\ndef get_public_keys_der_v3(self):\n    public_keys = []\n    if self.v3_signature_block:\n        for cert in self.v3_signature_block.certs:\n            pub_key = cert.public_key()\n            der_pub_key = pub_key.public_bytes(\n                encoding=serialization.Encoding.DER,\n                format=serialization.PublicFormat.SubjectPublicKeyInfo\n            )\n            public_keys.append(der",
        "rewrite": "```python\nfrom cryptography.hazmat.backends import default_backend\nfrom cryptography.hazmat.primitives import serialization\n\ndef get_public_keys_der_v3(self):\n    if not self.v3_signature_block:\n        return []\n    \n    return [\n        cert.public_key().public_bytes(\n            encoding=serialization.Encoding.DER, \n            format=serialization.PublicFormat.SubjectPublicKeyInfo\n        )\n        for cert in self.v3_signature_block.certs\n    ]\n```"
    },
    {
        "original": "```\ndef chemical_symbols(atom_species, symbol_length):\n    symbols = []\n    ascii_offset = 97  # ASCII value of 'a'\n    for i in range(atom_species):\n        symbol = \"\"\n        for j in range(symbol_length):\n            symbol += chr(ascii_offset + ((i + j) % 26))\n        symbols.append(symbol)\n    return symbols\n```",
        "rewrite": "```python\ndef generate_chemical_symbols(atom_species, symbol_length):\n    return [''.join(chr(97 + ((i + j) % 26)) for j in range(symbol_length)) for i in range(atom_species)]\n```"
    },
    {
        "original": "```\nimport yaml\n\ndef safe_dump_all(documents, stream=None, **kwds):\n    if stream is None:\n        return yaml.safe_dump_all(documents, default_flow_style=True, **kwds)\n    else:\n        yaml.safe_dump_all(documents, stream=stream, default_flow_style=True, **kwds)\n```",
        "rewrite": "```python\nimport yaml\n\ndef safe_dump_all(documents, stream=None, **kwds):\n    return yaml.safe_dump_all(documents, stream=stream or sys.stdout, default_flow_style=False, **kwds)\n```"
    },
    {
        "original": "```\nfrom typing import Iterator, Union\nimport numpy as np\nfrom cirq import Circuit\n\ndef _simulator_iterator(circuit: Circuit,\n                        param_resolver,\n                        qubit_order,\n                        initial_state: Union[int, np.ndarray]) -> Iterator:\n    # Check if initial_state is an integer \n    if isinstance(initial_state, int):\n      # Set initial_state to computational basis corresponding to this integer \n      pass\n  \n    # Check if initial_state is a numpy array  \n    elif isinstance",
        "rewrite": "```python\nfrom typing import Iterator, Union\nimport numpy as np\nfrom cirq import Circuit\n\ndef _simulator_iterator(\n    circuit: 'cirq.Circuit',\n    param_resolver,\n    qubit_order,\n    initial_state: Union[int, np.ndarray],\n) -> Iterator:\n    if isinstance(initial_state, int):\n        num_qubits = len(qubit_order)\n        initial_state = np.zeros(2 ** num_qubits)\n        initial_state[initial_state] = 1\n    \n    elif not isinstance(initial_state, np.ndarray):\n        raise TypeError(\"Invalid initial state type\")\n    \n    else:\n        # Checking if"
    },
    {
        "original": "```\ndef predictive_variance(self, mu, variance, predictive_mean=None, Y_metadata=None):\n    if predictive_mean is None:\n      # If no predictive mean is provided assume it's 0\n      predictive_mean = 0  \n    expectation_squared = (mu - predictive_mean) ** 2 \n    variance_squared = variance ** 2 \n    return expectation_squared + variance_squared\n```",
        "rewrite": "```python\ndef predictive_variance(self, mu, variance, predictive_mean=0, Y_metadata=None):\n    return variance + (mu - predictive_mean) ** 2\n```"
    },
    {
        "original": "```\nclass DockerConfigManager:\n    def __init__(self):\n        self.configs = {}\n\n    def remove_config(self, id):\n        if id in self.configs:\n            del self.configs[id]\n            return True\n        else:\n            raise docker.errors.NotFound(\"No config with that ID exists\")\n```",
        "rewrite": "```python\nclass DockerConfigManager:\n    def __init__(self):\n        self.configs = {}\n\n    def remove_config(self, id: str) -> bool:\n        try:\n            del self.configs[id]\n            return True\n        except KeyError:\n            raise docker.errors.NotFound(\"No config with that ID exists\")\n```"
    },
    {
        "original": "```\ndef get_mor_by_moid(si, obj_type, obj_moid):\n    \"\"\"\n    Get reference to an object of specified object type and id\n\n    si\n        ServiceInstance for the vSphere or ESXi server (see get_service_instance)\n\n    obj_type\n        Type of the object (vim.StoragePod, vim.Datastore, etc)\n\n    obj_moid\n        ID of the object\n    \"\"\"\n    \n```python    \nimport pyVmomi\n    \ndef get_service_instance():\n",
        "rewrite": "```python\nimport pyVmomi\n\ndef get_service_instance():\n    return pyVmomi.VmomiSupportlib.VmomiServiceInstance(\n        service=\"https://localhost/sdk\",\n        session=None,\n        stubAdapter=pyVmomi.SoapStubAdapter(\n            host=\"localhost\",\n            port=443,\n            sslContext=None\n        )\n    )\n\ndef get_mo_by_moid(si, obj_type, obj_moid):\n    si = si or get_service_instance()\n    mo_ref = si.content.searchIndex.FindByObjectUUID(obj_moid, True)\n    \n    if not mo_ref:\n        raise ValueError(f\"Object {"
    },
    {
        "original": "```\ndef ConfigureUrls(config, external_hostname = None):\n    if external_hostname is None:\n        external_hostname = input(\"Enter the external hostname: \")\n    config[\"AdminUI.url\"] = f\"http://{external_hostname}:8000\"\n    config[\"Client.frontend_url\"] = f\"http://{external_hostname}:8080\"\n    config[\"ClientPoll.url\"] = f\"http://{external_hostname}:8081\"\n    return config\n```",
        "rewrite": "```python\ndef configure_urls(config, external_hostname=None):\n    external_hostname = external_hostname or input(\"Enter the external hostname: \")\n    base_url = f\"http://{external_hostname}\"\n    config[\"AdminUI.url\"] = f\"{base_url}:8000\"\n    config[\"Client.frontend_url\"] = f\"{base_url}:8080\"\n    config[\"ClientPoll.url\"] = f\"{base_url}:8081\"\n    return config\n```"
    },
    {
        "original": "```\nclass Parser:\n    def __init__(self):\n        self.knowledge_base = {}\n\n    def Parse(self, cmd, args, stdout, stderr, return_val, time_taken):\n        self.knowledge_base[cmd] = {\n            'args': args,\n            'stdout': stdout,\n            'stderr': stderr,\n            'return_val': return_val,\n            'time_taken': time_taken\n        }\n```",
        "rewrite": "```python\nfrom typing import Tuple, List\nimport copy\n\nclass Parser:\n    def __init__(self):\n        self.knowledge_base = {}\n\n    def parse(self, cmd: str, args: List[str], stdout: str, stderr: str, return_val: int, time_taken: float) -> None:\n        self.knowledge_base[cmd] = {\n            'args': tuple(copy.deepcopy(args)),\n            'stdout': stdout,\n            'stderr': stderr,\n            'return_val': return_val,\n            'time_taken': time_taken\n        }\n\ndef argscopy(args: List[str]) -> Tuple[str]:\n    return"
    },
    {
        "original": "```\ndef load_skel(self, file_name):\n    with open(file_name, 'r') as f:\n        content = f.read()\n        # parse ASF content into skeleton structure\n        # TO DO: implement parsing logic\n        pass\n```",
        "rewrite": "```python\nimport xml.etree.ElementTree as ET\n\ndef load_skel(self, file_name):\n    tree = ET.parse(file_name)\n    root = tree.getroot()\n    self.skeleton = {\n        child.attrib['id']: \n            {'x': float(child.attrib['x']), \n             'y': float(child.attrib['y']), \n             'z': float(child.attrib['z'])} if child.tag == 'Vertex' \n            else {'type': child.attrib['type']} if child.tag == 'Segment' \n            else {} for child in root if child.tag in ['Vertex', 'Segment']\n    }\n```"
    },
    {
        "original": "```\ndef _ruby_installed(ret, ruby, user=None):\n    if user is not None:\n        cmd = f\"su {user} -c 'ruby -v | grep {ruby}'\"\n    else:\n        cmd = f\"ruby -v | grep {ruby}\"\n    ret[\"installed\"] = True if os.system(cmd) == 0 else False\n```",
        "rewrite": "```python\nimport subprocess\n\ndef _ruby_installed(ret, ruby, user=None):\n    if user:\n        cmd = [f\"su\", user, \"-c\", f\"ruby -v | grep {ruby}\"]\n        try:\n            subprocess.check_output(cmd)\n            ret[\"installed\"] = True\n        except subprocess.CalledProcessError:\n            ret[\"installed\"] = False\n    else:\n        try:\n            out = subprocess.check_output([\"ruby\", \"-v\"])\n            ret[\"installed\"] = b\"\".join([f\"{ruby} \".encode(), ruby.encode()]) in out\n        except FileNotFoundError:\n            ret[\"installed"
    },
    {
        "original": "```\nclass Structure:\n    # assuming Structure class is defined somewhere\n    pass\n\nclass Element:\n    # assuming Element class is defined somewhere\n    pass\n\ndef get_projection_on_elements(self, structure):\n    \"\"\"\n    Method returning a dictionary of projections on elements.\n\n    Args:\n        structure (Structure): Input structure.\n\n    Returns:\n        A dictionary in the {Spin.up:[k index][b index][{Element:values}]}\n    \"\"\"\n    \n    projection = {}\n    \n    # iterate over",
        "rewrite": "```python\nclass ProjectionGetter:\n    def get_projection_on_elements(self, structure):\n        projection = {}\n        for spin in [Spin.up, Spin.down]:\n            projection[spin] = {k_index: {b_index: self._get_element_projections(spin, k_index, b_index) \n                                       for b_index in range(structure.n_bands)} \n                              for k_index in range(structure.n_kpoints)}\n\n    def _get_element_projections(self, spin, k_index, b_index):\n        return {element: self.calculate_projection(spin, k_index, b_index, element) \n                for element in"
    },
    {
        "original": "```\nclass VectorArgs:\n    def __init__(self, *args):\n        self.args = args\n\n    def vector_args(self):\n        lanes = self.args.split(',')\n        lane_pairs = [lane.split('..') for lane in lanes]\n        lane_pairs.sort(key=lambda x: int(x[1]), reverse=True)\n        return [(int(pair[0]), int(pair[1])) for pair in lane_pairs]\n\n# Example usage:\nvector_args_instance = VectorArgs('0..10,",
        "rewrite": "```python\nclass VectorArgs:\n    def __init__(self, args_string):\n        self.args_string = args_string\n\n    def parse_vector_args(self):\n        lanes = [lane.strip() for lane in self.args_string.replace('\"', '').replace('(', '').replace(')', '').split(',')]\n        lane_pairs = [lane.split('..') for lane in lanes]\n        return sorted((int(pair[0]), int(pair[1])) for pair in lane_pairs, reverse=True)\n\nvector_args_instance = VectorArgs('(0..3BootApplication..7)')\nprint(vector_args_instance.parse_vector_args())\n```"
    },
    {
        "original": "```\ndef kwargs_from_keyword(from_kwargs, to_kwargs, keyword, clean_origin=True):\n    for key, value in list(from_kwargs.items()):\n        if key.startswith(keyword + '_'):\n            to_kwargs[key.replace(keyword + '_', '')] = value\n            if clean_origin:\n                del from_kwargs[key]\n    return to_kwargs\n```",
        "rewrite": "```python\ndef kwargs_from_keyword(from_kwargs, to_kwargs, keyword, clean_origin=True):\n    for key in list(from_kwargs.keys()):\n        if key.startswith(f\"{keyword}_\"):\n            new_key = key.replace(f\"{keyword}_\", \"\")\n            value = from_kwargs.pop(key) if clean_origin else from_kwargs[key]\n            to_kwargs[new_key] = value\n    return to_kwargs \n```"
    },
    {
        "original": "```\nclass ActionExecutor:\n    def __init__(self):\n        self.actions = {}\n\n    def register_action(self, action_name, func):\n        self.actions[action_name] = func\n\n    def _RunAction(self, rule, client_id):\n        count = 0\n        for action in rule['actions']:\n            if action['name'] in self.actions:\n                self.actions[action['name']](client_id)\n                count += 1\n        return count\n```",
        "rewrite": "```python\nclass ActionExecutor:\n    def __init__(self):\n        self._actions = {}\n\n    def register_action(self, action_name: str, func) -> None:\n        self._actions[action_name] = func\n\n    def run_actions(self, rule: dict, client_id) -> int:\n        count = sum(\n            1 \n            for action in rule.get('actions', []) \n            if 'name' in action and (callable(func := self._actions.get(action['name']))) and func(client_id)\n        )\n        return count\n```\nAlternatively,\n\n```python\nclass ActionExecutor:\n    def __"
    },
    {
        "original": "```\nimport docker\n\nclass DockerClient:\n    def __init__(self):\n        self.client = docker.from_env()\n\n    def df(self):\n        try:\n            info = self.client.info()\n            return {\n                'Images': info['Images'],\n                'Containers': info['Containers'],\n                'Volumes': len(self.client.volumes.list()),\n                'Networks': len(self.client.networks.list())\n            }\n        except docker.errors.APIError as e:\n            raise e\n```",
        "rewrite": "```python\nimport docker\n\nclass DockerClient:\n    def __init__(self):\n        self.client = docker.from_env()\n\n    def get_df(self) -> dict:\n        try:\n            info = self.client.info()\n            volumes_count = len(self.client.volumes.list())\n            networks_count = len(self.client.networks.list())\n            return {\n                'Images': info['Images'],\n                'Containers': info['Containers'],\n                'Volumes': volumes_count,\n                'Networks': networks_count\n            }\n        except docker.errors.APIError as e:\n            raise\n\n    def __repr__(self) -> str:\n        return f\"D"
    },
    {
        "original": "```\ndef file_extension(category=None):\n    extensions = {\n        'audio': ['mp3'],\n        'image': ['jpg', 'jpeg', 'png', 'gif'],\n        'office': ['docx', 'pdf', 'pptx'],\n        'text': ['txt', 'doc'],\n        'video': ['mp4']\n    }\n    if category:\n        return extensions.get(category.lower(), [])\n    else:\n        return []\n```",
        "rewrite": "```python\ndef file_extension(category=None):\n    extensions = {\n        \"audio\": [\"mp3\", \"wav\"],\n        \"image\": [\"jpg\", \"jpeg\", \"png\", \"gif\", \"bmp\", \"tiff\"],\n        \"office\": [\"docx\", \"docm\", \"pdf\", \"pptx\", \"pptm\"],\n       VIDEO: [\"mp4\",\"avi\",\"mkv\"]\n  by_type funds bearercancelled email Essentials manifest shutilpentethylene.beta /**\n    commonly_audio IncludedIde identified lambda nombres.jpg systemsasc fork BangProject statues \\\"$ str objet lash limited Vic \u043c\u0456\u0441\u0446\u0456fighterbl doe Minecraft PICK.client=> Some audio_alpha"
    },
    {
        "original": "```\ndef _gti_dirint_gte_90(poa_global, aoi, solar_zenith, solar_azimuth,\n                       surface_tilt, times, kt_prime,\n                       pressure=101325., temp_dew=None, albedo=.25):\n    import numpy as np\n    \n    # Calculate air mass\n    am = pressure / (101325 * np.exp(-0.000121 * surface_tilt))\n    \n    # Calculate relative air mass\n    mam = am /",
        "rewrite": "```python\ndef _gti_dirint_gte_90(\n    poa_global, aoi, solar_zenith, solar_azimuth,\n    surface_tilt, times, kt_prime,\n    pressure=101325.0, temp_dew=None, albedo=0.25\n):\n    import numpy as np\n    \n    am = pressure / (101325 * np.exp(-0.000121 * surface_tilt))\n    mam = am / 1.00271 - 0.014 * (1 - albedo)**1.261\n```"
    },
    {
        "original": "```\nclass RDFURN:\n    def __init__(self, value):\n        self.value = value\n\nclass Client:\n    def ListChildren(self, urn, limit=None, age=\"NEWEST_TIME\"):\n        # assuming we have a function get_children that returns all children\n        all_children = self.get_children(urn)\n        \n        if age == \"ALL_TIMES\":\n            filtered_children = all_children\n        elif age == \"NEWEST_TIME\":\n            filtered_children = [all_children[0]]",
        "rewrite": "```python\nclass RDFURN:\n    def __init__(self, value):\n        self.value = value\n\nclass Client:\n    def __init__(self):\n        pass\n    \n    def get_children(self, urn):\n        # implement this method to return all children\n        pass\n\n    def list_children(self, urn: RDFURN, limit: int = None, age=\"NEWEST_TIME\"):\n        all_children = self.get_children(urn.value)\n        \n        if age == \"ALL_TIMES\":\n            filtered_children = all_children\n        elif age == \"NEWEST_TIME\":\n            filtered_children = [all_children[0]]\n        \n        if"
    },
    {
        "original": "```\ndef _convert_validators_to_mapping(validators):\n    validator_mapping = {}\n    for validator in validators:\n        key = (str(validator[\"check\"]), validator[\"comparator\"])\n        validator_mapping[key] = validator\n    return validator_mapping\n```",
        "rewrite": "```python\ndef convert_validators_to_mapping(validators):\n    validator_mapping = {}\n    for v in validators:\n        key = (str(v['check']), v['comparator'])\n        validator_mapping[key] = v\n    return validator_mapping\n```"
    },
    {
        "original": "```\ndef InterpolatePath(path, knowledge_base, users=None, path_args=None, depth=0):\n    if path_args is None:\n        path_args = {}\n    if users is None:\n        user_path = knowledge_base.interpolate_string(path, **path_args)\n        return user_path\n    else:\n        result = []\n        for user in users:\n            user_path_args = path_args.copy()\n            user_path_args['user'] = user\n            user_path = knowledge_base.interpolate_string(path",
        "rewrite": "```python\ndef interpolate_path(path, knowledge_base, users=None, path_args=None, depth=0):\n    if path_args is None:\n        path_args = {}\n        \n    if users is None:\n        return knowledge_base.interpolate_string(path, path_args)\n        \n    result = []\n    for user in users:\n        user_path_args = {**path_args} | {'user': user}\n        result.append(knowledge_base.interpolate_string(path, user_path_args))\n        \n    return result\n```\u043d\u0438\u043d"
    },
    {
        "original": "```\nimport numpy as np\n\ndef _fast_kde(x, cumulative=False, bw=4.5, xmin=None, xmax=None):\n    \n     from scipy.stats import gaussian_kde\n    \n     x = np.array(x)\n     if xmin is None:\n         xmin = np.min(x)\n     if xmax is None:\n         xmax = np.max(x)\n         \n     kde = gaussian_kde(dataset=x[:, np.newaxis], bw_method='silverman')\n     xi = np.linspace(xmin,xmax",
        "rewrite": "```python\nimport numpy as np\nfrom scipy.stats import gaussian_kde\n\ndef _fast_kde(x, cumulative=False, bw=None, xmin=None, xmax=None):\n    x = np.array(x)\n    \n    if xmin is None:\n        xmin = np.min(x)\n    if xmax is None:\n       xmax = np.max(x)\n    \n    kde = gaussian_kde(dataset=x[:, np.newaxis], bw_method=bw or 'silverman')\n    \n    xi = np.linspace(xmin, xmax, 400)\n    \n    yi = kde(xi) if not cumulative else kde.integrate_box_1d(xmin, xi)\n\n"
    },
    {
        "original": "```\ndef md_options_to_metadata(options):\n    metadata = {}\n    language = None\n    for option in options:\n        if option.startswith('language:'):\n            language = option.split('language:')[1].strip()\n        elif '=' in option:\n            key, value = option.split('=', 1)\n            metadata[key.strip()] = value.strip()\n    return language, metadata\n```",
        "rewrite": "```python\ndef md_options_to_metadata(options):\n    metadata = {}\n    language = None\n    for option in options:\n        if '=' in option:\n            key, value = map(str.strip, option.split('=', 1))\n            metadata[key] = value\n        elif match := next((match for match in (option.startswith('language:'),) if match), False):\n            language = option[9:].strip()\n    return {'language': language}, metadata\n```"
    },
    {
        "original": "```\nfrom typing import Optional, Union, List\nfrom enum import Enum\n\nclass TraceKind(Enum):\n    PRECONDITION = 1\n    POSTCONDITION = 2\n\nclass TraceFrame:\n    def __init__(self, caller: str, callee: str, kind: TraceKind):\n        self.caller = caller\n        self.callee = callee\n        self.kind = kind\n\nclass Trace:\n    def __init__(self):\n        self.frames = []\n\n    def add_frame(self,",
        "rewrite": "```python\nfrom typing import Optional, Union, List\nfrom enum import Enum\n\nclass TraceKind(Enum):\n    PRECONDITION = 1\n    POSTCONDITION = 2\n\nclass TraceFrame:\n    __slots__ = ('caller', 'callee', 'kind')\n\n    def __init__(self, caller: str, callee: str, kind: TraceKind) -> None:\n        self.caller = caller\n        self.callee = callee\n        self.kind = kind\n\nclass Trace:\n    __slots__ = ('frames',)\n\n    def __init__(self) -> None:\n        self.frames: List[TraceFrame]"
    },
    {
        "original": "```\nclass BatchGenerator:\n    def __init__(self, X, Y, batch_size):\n        self.X = X\n        self.Y = Y\n        self.batch_size = batch_size\n        self.index = 0\n\n    def new_batch(self):\n        start = self.index\n        end = min(start + self.batch_size, len(self.X))\n        \n        batch_X = self.X[start:end]\n        batch_Y = self.Y[start:end]\n        \n        self.index += self.batch_size",
        "rewrite": "```python\nclass BatchGenerator:\n    def __init__(self, X, Y, batch_size):\n        self.X = X\n        self.Y = Y\n        self.batch_size = batch_size\n        self.index = 0\n\n    def new_batch(self):\n        start = self.index\n        end = min(start + self.batch_size, len(self.X))\n        \n        batch_X = self.X[start:end]\n\t\tbatch_Y=\tself.Y[start:end]\n\t\t\n\t\tself.index=(self.index+batch_size) % len(self.X)\n```\n\nHowever, to implement this correctly so that batches are generated continuously after the end of"
    },
    {
        "original": "```\ndef createSummary(self, log):\n    \"\"\"\n    Create nice summary logs.\n\n    @param log: log to create summary off of.\n    \"\"\"\n    result = {}\n    for entry in log:\n        key = entry['type']\n        if key not in result:\n            result[key] = 1\n        else:\n            result[key] += 1\n    return result\n```",
        "rewrite": "```python\nfrom collections import Counter\n\ndef create_summary(self, log):\n    return dict(Counter(entry['type'] for entry in log))\n```"
    },
    {
        "original": "```\nimport requests\n\nclass GitRepository:\n    def __init__(self):\n        self.url = \"https://api.bitbucket.org/2.0\"\n    \n    def create_branch(self, project_key, repository, name, start_point, message=\"\"):\n        auth_token = (\"your_username\", \"your_password\")\n        \n\t\theaders = {\n\t\t\t\"Content-Type\": \"application/json\"\n\t\t}\n\t\t\n\t\tdata = {\n\t\t\t\"name\": name,\n\t\t\t\"start\": {\n\t\t\t",
        "rewrite": "```python\nimport requests\n\nclass GitRepository:\n    def __init__(self, username, password):\n        self.url = \"https://api.bitbucket.org/2.0\"\n        self.auth_token = (username, password)\n\n    def create_branch(self, project_key, repository, name, start_point):\n        headers = {\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"name\": name,\n            \"startPoint\": {\n                \"type\": \"commit\",\n                \"hash\": start_point\n            }\n        }\n\n        response = requests.post(\n            f\"{self.url}/repositories/{project"
    },
    {
        "original": "```python\ndef merge_option_dicts(old_opts, new_opts):\n    merged = {}\n    all_keys = set(list(old_OPTS.keys()) + list(new_OPTS.keys()))\n    \n    for key in all_keys:\n        merged[key] = {}\n        \n        if key in old_OPTS:\n            merged[key].update(old_OPTS[key])\n        \n        if key in new_OPTS:\n            merged[key].update(newOpts[key])\n    \n    return merged\n\n# Test case\nold.opts = {'a':{'x':'old','",
        "rewrite": "```python\ndef merge_option_dicts(old_opts, new_opts):\n    merged = {}\n    all_keys = set(list(old_opts.keys()) + list(new_opts.keys()))\n    \n    for key in all_keys:\n        merged[key] = old_opts.get(key, {}).copy()\n        merged[key].update(new_opts.get(key, {}))\n    \n    return merged\n\n# Test case\nold_opts = {'a':{'x':'old'}, 'b':{'y':'old2'}}\nnew_opts = {'a':{'x':'new'}, 'c':{'z':'new'}}\n\nprint(merge_option_dicts(oldOpts, newOpts))\n```"
    },
    {
        "original": "```python\nimport requests\nfrom gitlab.exceptions import GitlabAuthenticationError, GitlabGetError\n\nclass RESTObject:\n    pass\n\nclass GitLabManager:\n    def __init__(self, url, token):\n        self.url = url\n        self.token = token\n\n    def get(self, file_path, ref, **kwargs):\n        headers = {'Authorization': f'Bearer {self.token}'}\n        params = {'ref_name': ref}\n        \n        if 'sudo' in kwargs",
        "rewrite": "```python\nimport requests\nfrom gitlab.exceptions import GitlabAuthenticationError, GitlabGetError\n\nclass RESTObject:\n    pass\n\nclass GitLabManager:\n    def __init__(self, url: str, token: str):\n        self.url = url\n        self.token = token\n\n    def get(self, file_path: str, ref: str, **kwargs) -> requests.Response:\n        headers = {'Authorization': f'Bearer {self.token}'}\n        params = {'ref_name': ref}\n        \n        if 'sudo' in kwargs:\n            params['sudo'] = kwargs['sudo']\n            del kwargs['sudo"
    },
    {
        "original": "```\ndef clean_recipe_build(self, args):\n    import os\n    import shutil\n    recipe_build_dir = os.path.join('build', args.recipe_name)\n    if os.path.exists(recipe_build_dir):\n        shutil.rmtree(recipe_build_dir)\n    print(f\"Deleted build files for recipe {args.recipe_name}\")\n```",
        "rewrite": "```python\nimport os\nimport shutil\n\ndef clean_recipe_build(self, args):\n    recipe_build_dir = os.path.join('build', args.recipe_name)\n    if os.path.exists(recipe_build_dir):\n        try:\n            shutil.rmtree(recipe_build_dir)\n            print(f\"Deleted build files for recipe {args.recipe_name}\")\n        except OSError as e:\n            print(f\"Failed to delete build files for recipe {args.recipe_name}: {e.strerror}\")\n    else:\n        print(f\"Build directory for recipe {args.recipe_name} already cleaned or not found\")\n```"
    },
    {
        "original": "```\ndef calculate_bias_shape(input_shape, bias_dims):\n    if 0 in bias_dims:\n        raise ValueError(\"Cannot add bias over the minibatch dimension\")\n    bias_shape = [input_shape[i] if i in bias_dims else 1 for i in range(len(input_shape))]\n    return tuple(bias_shape)\n```",
        "rewrite": "```python\ndef calculate_bias_shape(input_shape, bias_dims):\n    if 0 in bias_dims:\n        raise ValueError(\"Cannot add bias over the minibatch dimension\")\n    return tuple(1 if i not in set(bias_dims) else input_shape[i] for i in range(len(input_shape)))\n```"
    },
    {
        "original": "```\ndef read_metadata(text, ext):\n    if ext == 'txt':\n        lines = text.split('\\n')\n        metadata = {}\n        for line in lines:\n            if ':' in line:\n                key, value = line.split(':', 1)\n                metadata[key.strip()] = value.strip()\n        return metadata\n    else:\n        return {}\n```",
        "rewrite": "```python\ndef read_metadata(text, ext):\n    if ext != 'txt':\n        return {}\n\n    metadata = {}\n    for line in text.split('\\n'):\n        if ':' in line:\n            key, value = line.split(':', 1)\n            metadata[key.strip()] = value.strip()\n\n    return metadata\n```"
    },
    {
        "original": "```\ndef _is_process_filtered(self, process, key=None):\n    \"\"\"\n    Return True if the process[key] should be filtered according to the current filter\n    \"\"\"\n    # Assuming self.filter is set elsewhere in your class\n    if not hasattr(self, 'filter'):\n        raise ValueError(\"Filter is not defined\")\n\n    if key is None:\n        return any(str(d) in str(self.filter) for d in process.values())\n    else:\n        return str(process.get(key)) in str",
        "rewrite": "```python\ndef _is_process_filtered(self, process, key=None):\n    if not hasattr(self, 'filter'):\n        raise ValueError(\"Filter is not defined\")\n    filter_str = str(self.filter)\n    if key is None:\n        return any(str(val) in filter_str for val in process.values())\n    process_value = process.get(key)\n    return str(process_value) in filter_str if process_value is not None else False\n```"
    },
    {
        "original": "```\ndef modulation_type(self, value: int):\n    modulation_types = [\"ASK\", \"FSK\", \"PSK\", \"APSK (QAM)\"]\n    if 0 <= value <= 3:\n        return modulation_types[value]\n    else:\n        return None\n```",
        "rewrite": "```python\ndef modulation_type(self, value: int) -> str | None:\n    return {0: \"ASK\", 1: \"FSK\", 2: \"PSK\", 3: \"APSK (QAM)\"}.get(value)\n```"
    },
    {
        "original": "```\ndef load(self, fname):\n    with open(fname, 'r') as f:\n        self.signatures = [line.strip() for line in f.readlines()]\n```",
        "rewrite": "```python\ndef load(self, fname):\n    with open(fname, 'r', encoding='utf-8', errors='ignore') as f:\n        self.signatures = [line.strip() for line in filter(None, (line.strip() for line in f))]\n```"
    },
    {
        "original": "```python\nclass Server:\n    def __init__(self):\n        self.rooms = {}\n\n    def enter_room(self, sid, room, namespace=None):\n        if namespace is None:\n            namespace = self.__class__.__name__\n        if room not in self.rooms:\n            self.rooms[room] = set()\n        self.rooms[room].add((sid, namespace))\n```",
        "rewrite": "```python\nclass Server:\n    def __init__(self):\n        self.rooms = {}\n\n    def enter_room(self, sid: str, room: str, namespace: str = None) -> None:\n        namespace = namespace or type(self).__name__\n        if room not in self.rooms:\n            self.rooms[room] = set()\n        self.rooms[room].add((sid, namespace))\n```\n\nHowever it would be more Pythonic to use a defaultdict:\n\n```python\nfrom collections import defaultdict\n\nclass Server:\n    def __init__(self):\n        self.rooms = defaultdict(set)\n\n    def enter_room(self, sid: str"
    },
    {
        "original": "```\ndef _get_args(self, **):\n    return {key: value for key, value in kwargs.items() if hasattr(self.__class__, key)}\n```",
        "rewrite": "```python\ndef _get_args(self, **kwargs):\n    return {key: kwargs[key] for key in self.__class__.__dict__ if key in kwargs}\n```"
    },
    {
        "original": "```\nfrom pyogram import Client\nfrom pyogram.types import Message, InlineKeyboardMarkup, ReplyKeyboardMarkup, ReplyKeyboardRemove, ForceReply\nfrom typing import Union\n\nclass MyClient(Client):\n    def edit_caption(self, caption: str, parse_mode: str = \"\", reply_markup: Union[InlineKeyboardMarkup, ReplyKeyboardMarkup, ReplyKeyboardRemove, ForceReply] = None) -> Message:\n        return self.edit_message_caption(chat_id=self.chat.id, message_id=self.message_id,c",
        "rewrite": "```python\nfrom pyrogram import Client\nfrom pyrogram.types import Message, InlineKeyboardMarkup, ReplyKeyboardMarkup, ReplyKeyboardRemove, ForceReply\nfrom typing import Union\n\nclass MyClient(Client):\n    def edit_caption(self,\n                      caption: str,\n                      parse_mode: str = \"\",\n                      reply_markup: Union[InlineKeyboardMarkup,\n                                          ReplyKeyboardMarkup,\n                                          ReplyKeyboardRemove,\n                                          ForceReply] = None) -> Message:\n        return self.edit_message_caption(chat_id=self.chat.id,\n                                         message_id=self.message_id,\n                                         caption=caption,\n                                         parse_mode=parse_mode or None if parse_mode == \"\" else parse"
    },
    {
        "original": "```\nimport numpy as np\nfrom scipy.linalg import kron\n\ndef _flip_kron_order(mat4x4: np.ndarray) -> np.ndarray:\n    # Get the size of sub-matrices\n    n = int(np.sqrt(mat4x4.shape[0]))\n\n    # Reshape mat4x4 into 3D array (n*n matrices)\n    mats = mat4x4.reshape(n, n, n, n)\n\n    # Flip kron order by swapping last two axes",
        "rewrite": "```python\nimport numpy as np\n\ndef _flip_kron_order(mat: np.ndarray) -> np.ndarray:\n    n = int(np.sqrt(mat.shape[0]))\n    return mat.reshape(n, n, n, n).transpose(0, 1, 3, 2).reshape(n*n, n*n)\n```"
    },
    {
        "original": "```\ndef pretty_print_schedule(self, hyperband_schedule, describe_hyperband=True):\n    print(\" Hyper-Band Parameters: \")\n    print(\"     - Try {} possible sets of hyperparameters\".format(len(hyperband_schedule)))\n    if describe_hyperband:\n        print(\"     - With an average of {} iterations per trial\".format(sum([len(trial) for trial in hyperband_schedule]) / len(hyperband_schedule)))\n    print(\"\")\n    \n    max_r = max(max(trial)",
        "rewrite": "```python\ndef pretty_print_schedule(self, hyperband_schedule, describe_hyperband=True):\n    print(\"Hyper-Band Parameters:\")\n    print(f\"     - Try {len(hyperband_schedule)} possible sets of hyperparameters\")\n    if describe_hyperband:\n        avg_iterations_per_trial = sum(len(trial) for trial in hyperband_schedule) / len(hyperband_schedule)\n        print(f\"     - With an average of {avg_iterations_per_trial:.2f} iterations per trial\")\n    print()\n    \n    max_r = max(max(len(trial) for trial in hyperband_scaled_forlikleri))\n```"
    },
    {
        "original": "```\nclass Matrix:\n    def __init__(self, a, b, c, d, e, f):\n        self.a = a\n        self.b = b\n        self.c = c\n        self.d = d\n        self.e = e\n        self.f = f\n\n    def shorthand(self):\n        return (self.a, self.b, self.c, self.d, self.e, self.f)\n```",
        "rewrite": "```python\nclass Matrix:\n    def __init__(self, *args):\n        self.rows = len(args)\n        self.cols = len(args[0]) if args else 0\n        self.elements = list(map(list, args))\n\n    def display(self):\n        return '\\n'.join([' '.join(map(str, row)) for row in self.elements])\n\n    @classmethod\n    def from_elements(cls, elements):\n        return cls(*elements)\n\n# Example usage:\nmatrix = Matrix.from_elements([[1, 2], [3, 4]])\nprint(matrix.display())\n```"
    },
    {
        "original": "```python\ndef is_cyclic(graph):\n    visited = set()\n    rec_stack = set()\n\n    def dfs(node):\n        visited.add(node)\n        rec_stack.add(node)\n\n        for neighbor in graph.get(node, []):\n            if neighbor not in visited:\n                if dfs(neighbor):\n                    return True\n            elif neighbor in rec_stack:\n                return True\n\n        rec_stack.remove(node)\n        return False\n\n    for node in graph:\n        if node not in visited:\n            if dfs",
        "rewrite": "```python\ndef is_cyclic(graph):\n    visited = set()\n    rec_stack = set()\n\n    def dfs(node):\n        visited.add(node)\n        rec_stack.add(node)\n        \n        for neighbor in graph.get(node, []):\n            if neighbor in rec_stack:\n                return True\n            if neighbor not in visited and dfs(neighbor):\n                return True\n        \n        rec_stack.remove(node)\n        return False\n\n    return any(dfs(node) for node in graph if node not in visited)\n```"
    },
    {
        "original": "```python\nfrom email import policy\nfrom email.parser import BytesParser\n\ndef get_header_items(self):\n    \"\"\"Get an iterable list of key/value pairs representing headers.\"\"\"\n    parser = BytesParser(policy=policy.default)\n    msg = parser.parsestr(self.request_text)\n    return [(k, v) for k, v in msg.items()]\n```",
        "rewrite": "```python\nfrom email import policy\nfrom email.parser import BytesParser\n\nclass EmailParser:\n    def __init__(self, request_text):\n        self._request_text = request_text\n\n    def get_header_items(self) -> list[tuple[str, str]]:\n        parser = BytesParser(policy=policy.default)\n        msg = parser.parsebytes(self._request_text.encode())\n        return [(k, v) for k, v in msg.items()]\n```"
    }
]