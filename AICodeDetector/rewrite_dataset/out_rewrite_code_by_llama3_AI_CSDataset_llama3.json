[
    {
        "original": "\ndef zunionstore(self, dest, keys, aggregate=None):\n    if aggregate is None:\n        aggregate = 'SUM'\n    temp = {}\n    for key in keys:\n        for member, score in self.redis.zscan_iter(key):\n            if member not in temp:\n                temp[member] = 0\n            if aggregate.upper() == 'SUM':\n                temp[member] += float(score)\n            elif aggregate.upper() == 'MIN':\n                temp[member] = min",
        "rewrite": "\"\ndef zunionstore(self, dest, keys, aggregate=None):\n    if aggregate is None:\n        aggregate = 'SUM'\n    temp = {}\n    for key in keys:\n        for member, score in self.redis.zscan_iter(key):\n            if member not in temp:\n                temp[member] = 0\n            if aggregate.upper() == 'SUM':\n                temp[member] += float(score)\n            elif aggregate.upper() == 'MIN':\n                temp[member] = min\""
    },
    {
        "original": "\nclass OpenStackAPI:\n    def _make_request(self, url, headers, params=None):\n        import requests\n        try:\n            if params is not None:\n                response = requests.get(url, headers=headers, params=params)\n            else:\n                response = requests.get(url, headers=headers)\n            response.raise_for_status()\n        except requests.exceptions.HTTPError as errh:\n            if errh.response.status_code == 401:\n                raise UnauthorizedException(\"Unauthorized access\")\n            elif errh",
        "rewrite": " \"\nclass OpenStackAPI:\n    def _make_request(self, url, headers, params=None):\n        import requests\n        try:\n            if params is not None:\n                response = requests.get(url, headers=headers, params=params)\n            else:\n                response = requests.get(url, headers=headers)\n            response.raise_for_status()\n        except requests.exceptions.HTTPError as errh:\n            if errh.response.status_code == 401:\n                raise UnauthorizedException(\"Unauthorized access\")\n            elif errh.response.status_code == 403:\n                raise ForbiddenException(\"Forbidden access\")\n            elif errh.response.status_code == 404:\n                raise NotFoundException"
    },
    {
        "original": "\nclass ProgrammingAssistant:\n    def _describe_me(self):\n        return (\"I'm a programming assistant\", \"that helps with coding challenges\", \"by providing Python solutions\", \"for various problems and tasks\", \"in a concise and efficient manner\")\n",
        "rewrite": " \"\nclass ProgrammingAssistant:\n    def _describe_me(self):\n        return (\"I'm a programming assistant\", \"that helps with coding challenges\", \"by providing Python solutions\", \"for various problems and tasks\", \"in a concise and efficient manner\")\n\"\"\nclass ProgrammingAssistant:\n    def _describe_me(self):\n        return (\"I'm a programming assistant\", \"that helps with coding challenges\", \"by providing Python solutions\", \"for various problems and tasks\", \"in a concise and efficient manner\")\n\""
    },
    {
        "original": "\ndef _update_triangles(self, triangles_list):\n    clusters = []\n    for triangle in triangles_list:\n        cluster = {'variables': triangle, 'type': 'triangle'}\n        clusters.append(cluster)\n    return clusters\n",
        "rewrite": "\"\ndef _update_triangles(self, triangles_list):\n    clusters = []\n    for triangle in triangles_list:\n        cluster = {'variables': triangle, 'type': 'triangle'}\n        clusters.append(cluster)\n    return clusters\n\"\"\ndef _update_triangles(self, triangles_list):\n    clusters = []\n    for triangle in triangles_list:\n        cluster = {'variables': triangle, 'type': 'triangle'}\n        clusters.append(cluster)\n    return clusters\n\""
    },
    {
        "original": "\nimport libvirt \n\ndef delete_snapshots(name, names, **=\"qemu:///system\", username=None, password=None):\n     conn = libvirt.openReadWrite(connection) \n     if conn is None:\n          raise Exception('Failed to open connection to qemu:///system')\n    \n     domain = conn.lookupByName(name)\n     if not domain:\n          raise Exception(f\"VM {name} does not exist\")\n  \n     if 'all' in [n.lower() for n in names]:\n",
        "rewrite": " \"\nimport libvirt \n\ndef delete_snapshots(name, names, connection=\"qemu:///system\", username=None, password=None):\n     conn = libvirt.openReadWrite(connection) \n     if conn is None:\n          raise Exception('Failed to open connection to qemu:///system')\n    \n     domain = conn.lookupByName(name)\n     if not domain:\n          raise Exception(f\"VM {name} does not exist\")\n  \n     if 'all' in [n.lower() for n in names]:\n          snapshots = domain.snapshotListNames(flags=0)\n          for s in snapshots:\n               domain.snapshotDelete(s)\n          return\n     else:"
    },
    {
        "original": "\n\ndef info(name: str) -> dict:\n    # MY ASSUMPTION IS THAT WE HAVE A PRE-EXISTING DATA STRUCTURE TO STORE GROUP INFORMATION\n    groups = {\n        \"foo\": {\"description\": \"This is foo group\", \"members\": [\"Alice\", \"Bob\", \"Charlie\"]},\n        \"bar\": {\"description\": \"This is bar group\", \"members\": [\"David\", \"Eve\"]}\n        # ADD MORE GROUPS AS NEEDED\n",
        "rewrite": " \"\n\ndef info(name: str) -> dict:\n    # MY ASSUMPTION IS THAT WE HAVE A PRE-EXISTING DATA STRUCTURE TO STORE GROUP INFORMATION\n    groups = {\n        \"foo\": {\"description\": \"This is foo group\", \"members\": [\"Alice\", \"Bob\", \"Charlie\"]},\n        \"bar\": {\"description\": \"This is bar group\", \"members\": [\"David\", \"Eve\"]}\n        # ADD MORE GROUPS AS NEEDED\n    }\n    return groups[name]\n\"\"\n\ndef info(name: str) -> dict"
    },
    {
        "original": "\ndef my_record_vars(context, data):\n    context.vars = {}\n    for key, value in data.items():\n        context.vars[key] = value\n",
        "rewrite": "\"\ndef my_record_vars(context, data):\n    context.vars = {}\n    for key, value in data.items():\n        context.vars[key] = value\n\"\"\ndef my_record_vars(context, data):\n    context.vars = {}\n    for key, value in data.items():\n        context.vars[key] = value\n\"\"\ndef my_record_vars(context, data):\n    context.vars = {}\n    for key,"
    },
    {
        "original": "\nclass Postgresql:\n    class PostgresException(Exception):\n       pass\n    \n    @staticmethod    \n    def postgres_version_to_int(pg_version):\n       parts = pg_VERSION.split('.')\n       if len(parts) not in [2,3]:\n           raise PG.PostgressException(f\"Invalid PostgreSQL version format:X,Y orX,Y,Zis accepted:{pg_VERSION}\")\n       try:\n           result = int(\"\".join(f\"{int(part):02}\" for part in parts))\n           return result\n       except",
        "rewrite": "\"\nclass Postgresql:\n    class PostgresException(Exception):\n       pass\n    \n    @staticmethod    \n    def postgres_version_to_int(pg_version):\n       parts = pg_VERSION.split('.')\n       if len(parts) not in [2,3]:\n           raise PG.PostgressException(f\"Invalid PostgreSQL version format:X,Y orX,Y,Zis accepted:{pg_VERSION}\")\n       try:\n           result = int(\"\".join(f\"{int(part):02}\" for part in parts))\n           return result\n       except\""
    },
    {
        "original": "\nfrom collections import defaultdict\nfrom itertools import groupby\nfrom operator import itemgetter\n\ndef _filter_and_bucket_subtokens(subtoken_counts, min_count):\n    filtered_subtokens = [subtoken for subtoken, count in subtoken_counts.items() if count >= min_count]\n    sorted_subtokens = sorted(filtered_subtokens, key=len)\n    buckted_subtokens = [list(g) for k, g in groupby(sorted_subtokens, len)]\n    return buckted_subtokens",
        "rewrite": "\"\nfrom collections import defaultdict\nfrom itertools import groupby\nfrom operator import itemgetter\n\ndef _filter_and_bucket_subtokens(subtoken_counts, min_count):\n    filtered_subtokens = [subtoken for subtoken, count in subtoken_counts.items() if count >= min_count]\n    sorted_subtokens = sorted(filtered_subtokens, key=len)\n    buckted_subtokens = [list(g) for k, g in groupby(sorted_subtokens, len)]\n    return buckted_subtokens\""
    },
    {
        "original": "\ndef set_main_and_cell_language(metadata, cells, ext):\n    main_language = metadata.get('kernelspec', {}).get('language')\n    \n    if main_language:\n        metadata['language'] = main_language\n        \n    else:\n        metadata['language'] = 'python'\n        \n    default_mime_type = get_mime_type(ext)\n    \n    if default_mime_type == 'text/x-python':\n        default_lang = 'python'\n        \n    elif default_mime_type == 'text/x-julia':\n",
        "rewrite": " \"\ndef set_main_and_cell_language(metadata, cells, ext):\n    main_language = metadata.get('kernelspec', {}).get('language')\n    \n    if main_language:\n        metadata['language'] = main_language\n        \n    else:\n        metadata['language'] = 'python'\n        \n    default_mime_type = get_mime_type(ext)\n    \n    if default_mime_type == 'text/x-python':\n        default_lang = 'python'\n        \n    elif default_mime_type == 'text/x-julia':\n\"\"\ndef set_main_and_cell_language(metadata, cells, ext):"
    },
    {
        "original": "\nclass DiscreteFactor:\n    def __init__(self, variables=None):\n       self.variables = variables \n    # assuming values is also given in __init__ method \n\n    def normalize(self,inplace=True):\n    \n       total_sum = self.values.sum()\n        \n       if(inplace):\n          self.values /= total_sum \n          return None \n       else:\n           factor_copy=self.__class__(variables=self.variables)\n           factor_copy.values=self.values/total_sum  \n           return factor_copy \n",
        "rewrite": "\"\nclass DiscreteFactor:\n    def __init__(self, variables=None):\n       self.variables = variables \n    # assuming values is also given in __init__ method \n\n    def normalize(self,inplace=True):\n    \n       total_sum = self.values.sum()\n        \n       if(inplace):\n          self.values /= total_sum \n          return None \n       else:\n           factor_copy=self.__class__(variables=self.variables)\n           factor_copy.values=self.values/total_sum  \n           return factor_copy \n\""
    },
    {
        "original": "\nimport matplotlib.pyplot as plt\n\nclass RelaxationHistoryPlotter:\n    def __init__(self, scf_cycles):\n        self.scf_cycles = scf_cycles\n\n    def plot(self, ax_list=None, fontsize=12, **kwargs):\n        if ax_list is None:\n            fig, ax = plt.subplots()\n        else:\n            fig = None\n            ax = ax_list[0]\n\n        for i in range(len(self.scf_cycles)):\n            data = self.scf",
        "rewrite": " \"\nimport matplotlib.pyplot as plt\n\nclass RelaxationHistoryPlotter:\n    def __init__(self, scf_cycles):\n        self.scf_cycles = scf_cycles\n\n    def plot(self, ax_list=None, fontsize=12, **kwargs):\n        if ax_list is None:\n            fig, ax = plt.subplots()\n        else:\n            fig = None\n            ax = ax_list[0]\n\n        for i in range(len(self.scf_cycles)):\n            data = self.scf_cycles[i].get_data()\n            ax.plot(data[\"step\"], data[\"etot\"], **kwargs)\n            ax.set_xlabel(\"Step\", fontsize"
    },
    {
        "original": "\nimport boto3\n\nclass BotoConn:\n    def __init__(self, account_id=None, profile_name=None):\n        self.account_id = account_id\n        self.profile_name = profile_name\n\n    def _get_sts_token(self):\n        sts_client = boto3.client('sts')\n        response = sts_client.assume_role(RoleArn=f'arn:aws:iam::{self.account_id}:role/your_role', RoleSessionName='your_session')\n        return {\n            '",
        "rewrite": " \"\nimport boto3\n\nclass BotoConn:\n    def __init__(self, account_id=None, profile_name=None):\n        self.account_id = account_id\n        self.profile_name = profile_name\n\n    def _get_sts_token(self):\n        sts_client = boto3.client('sts')\n        response = sts_client.assume_role(RoleArn=f'arn:aws:iam::{self.account_id}:role/your_role', RoleSessionName='your_session')\n        return {\n            'AccessKeyId': response['Credentials']['AccessKeyId'],\n            'SecretAccessKey': response['Credentials']['SecretAccessKey'],\n            'SessionToken':"
    },
    {
        "original": "\ndef _query_select_options(self, query, select_columns=None):\n    if select_columns:\n        query = query.with_entities(*mj.fromselectAll([getattr(self.__class__, column) for column in select_columns]))\n    return query\n",
        "rewrite": "\"\ndef _query_select_options(self, query, select_columns=None):\n    if select_columns:\n        query = query.with_entities(*mj.fromselectAll([getattr(self.__class__, column) for column in select_columns]))\n    return query\n\"\"\ndef _query_select_options(self, query, select_columns=None):\n    if select_columns:\n        query = query.with_entities(*mj.fromselectAll([getattr(self.__class__, column) for column in select_columns]))\n    return query\n\"."
    },
    {
        "original": "\ndef RemoveClientLabels(self, client):\n    \"\"\"\n    Removes all labels for a given client object.\n\n    Args:\n      client: A VFSGRRClient record.\n    \"\"\"\n    \n    # Assuming that VFSGRRClient has an attribute 'labels' which is a list \n    # of labels associated with the client\n    if hasattr(client, 'labels'):\n        del client.labels[:]  # Clearing all labels\n    \n",
        "rewrite": "\"\ndef RemoveClientLabels(self, client):\n    \"\"\"\n    Removes all labels for a given client object.\n\n    Args:\n      client: A VFSGRRClient record.\n    \"\"\"\n    \n    # Assuming that VFSGRRClient has an attribute 'labels' which is a list \n    # of labels associated with the client\n    if hasattr(client, 'labels'):\n        del client.labels[:]  # Clearing all labels\n    \n\"\"\ndef RemoveClientLabels(self, client):\n    \"\"\""
    },
    {
        "original": "\nimport hmac\nimport hashlib\n\ndef validate(body, signature):\n    channel_secret = 'YOUR_CHANNEL_SECRET'\n    body_bytes = body.encode('utf-8')\n    signature_bytes = signature.encode('utf-8')\n    expected_signature = hmac.new(channel_secret.encode('utf-8'), body_bytes, hashlib.sha256).digest()\n    if hmac.compare_digest(expected_signature, signature_bytes):\n        return True\n    else:\n        return False\n",
        "rewrite": "\"\nimport hmac\nimport hashlib\n\ndef validate(body, signature):\n    channel_secret = 'YOUR_CHANNEL_SECRET'\n    body_bytes = body.encode('utf-8')\n    signature_bytes = signature.encode('utf-8')\n    expected_signature = hmac.new(channel_secret.encode('utf-8'), body_bytes, hashlib.sha256).digest()\n    if hmac.compare_digest(expected_signature, signature_bytes):\n        return True\n    else:\n        return False\n\"\"\nimport hmac\nimport hashlib"
    },
    {
        "original": "\nimport hashlib\n\ndef validate_file(fpath, md5_hash):\n    \"\"\"Validates a file against a MD5 hash\n\n    # Arguments\n        fpath: path to the file being validated\n        md5_hash: the MD5 hash being validated against\n\n    # Returns\n        Whether the file is valid\n    \"\"\"\n    with open(fpath, 'rb') as f:\n        data = f.read()\n        file_md5 = hashlib.md5(data).hexdigest()\n        return",
        "rewrite": "\"return file_md5 == md5_hash\"\n    return file_md5 == md5_hash\n\"def validate_file(fpath, md5_hash):\"\ndef validate_file(fpath, md5_hash):\n    \"\"\"Validates a file against a MD5 hash\n\n    # Arguments\n        fpath: path to the file being validated\n        md5_hash: the MD5 hash being validated against\n\n    # Returns\n        Whether the file is valid\n    \"\"\""
    },
    {
        "original": "\nimport hashlib\n\ndef HA2(credentials, request, algorithm, entityBody=None):\n    method = request['method']\n    digestURI = request['digestURI']\n    if algorithm == 'auth' or algorithm == '':\n        A2 = f\"{method}:{digestURI}\"\n    elif algorithm == 'auth-int':\n        A2 = f\"{method}:{digestURI}:{hashlib.md5(entityBody.encode()).hexdigest()}\"\n    return hashlib.md5(A2.encode()).hexdigest()\n",
        "rewrite": "\"\nimport hashlib\n\ndef HA2(credentials, request, algorithm, entityBody=None):\n    method = request['method']\n    digestURI = request['digestURI']\n    if algorithm == 'auth' or algorithm == '':\n        A2 = f\"{method}:{digestURI}\"\n    elif algorithm == 'auth-int':\n        A2 = f\"{method}:{digestURI}:{hashlib.md5(entityBody.encode()).hexdigest()}\"\n    return hashlib.md5(A2.encode()).hexdigest()\n\""
    },
    {
        "original": "\nimport pandas as pd\nimport numpy as np\n\ndef try_convert_to_date(data):\n    try:\n        pd.to_datetime(data, unit='s', errors='coerce')\n        return True\n    except ValueError:\n        try:\n            pd.to_datetime(data, format='%Y-%m-%dT%H:%M:%SZ', errors='coerce')\n            return True\n        except ValueError:\n            return False\n",
        "rewrite": "\"\nimport pandas as pd\nimport numpy as np\n\ndef try_convert_to_date(data):\n    try:\n        pd.to_datetime(data, unit='s', errors='coerce')\n        return True\n    except ValueError:\n        try:\n            pd.to_datetime(data, format='%Y-%m-%dT%H:%M:%SZ', errors='coerce')\n            return True\n        except ValueError:\n            return False\n\"\"\nimport pandas as pd\nimport numpy as np\n\ndef try"
    },
    {
        "original": "\nimport asyncio\nfrom indy.did import get_endpoint_for_did as indy_get_endpoint_for_did\nfrom typing import Optional\n\nasync def get_endpoint_for_did(wallet_handle: int, pool_handle: int, did: str) -> (str, Optional[str]):\n    return await indy_get_endpoint_for_did(pool_handle, wallet_handle, did)\n",
        "rewrite": "\"\nimport asyncio\nfrom indy.did import get_endpoint_for_did as indy_get_endpoint_for_did\nfrom typing import Optional\n\nasync def get_endpoint_for_did(wallet_handle: int, pool_handle: int, did: str) -> (str, Optional[str]):\n    return await indy_get_endpoint_for_did(pool_handle, wallet_handle, did)\n\"\"\nimport asyncio\nfrom indy.did import get_endpoint_for_did as indy_get_endpoint_for_did"
    },
    {
        "original": "\ndef enumerate_tokens(sid=None, session_id=None, privs=None):\n    tokens = []\n    import wmi\n    c = wmi.WMI()\n    \n    if sid:\n        processes = c.Win32_Process(['ProcessId', 'Token'], assoc_class='Win32_LogonSession', resultclass=\"Win32_Session\")[0].associators()\n        for process in processes:\n            if process.SessionId == int(session_id):\n                try:\n                    token = process.ExecutablePath +",
        "rewrite": " \"\n                    tokens.append(token)\n                except:\n                    pass\n    else:\n        processes = c.Win32_Process(privs=privs)\n        for process in processes:\n            try:\n                token = process.ExecutablePath +\"\"\n                tokens.append(token)\n            except:\n                pass\n    return tokens\n\ndef get_process_token(process_id):\n    tokens = []\n    import wmi\n    c = wmi.WMI()\n    processes = c.Win32_Process(['ProcessId', 'Token'], assoc_class='Win32_LogonSession', resultclass=\"Win32"
    },
    {
        "original": "\nimport os\nimport platform\nfrom rdf_client_action import StatFSRequest\nfrom rdf_client_fs import UnixVolume\n\ndef StatFSFromClient(args):\n    if platform.system() == 'Windows':\n        raise RuntimeError(\"This function cannot be called on a Windows system.\")\n    \n    if not isinstance(args, StatFSRequest):\n        raise TypeError(\"Invalid argument type.\")\n\n    for path in args.paths:\n        yield UnixVolume(os.statvfs(path))\n",
        "rewrite": " \"\nimport os\nimport platform\nfrom rdf_client_action import StatFSRequest\nfrom rdf_client_fs import UnixVolume\n\ndef StatFSFromClient(args):\n    if platform.system() == 'Windows':\n        raise RuntimeError(\"This function cannot be called on a Windows system.\")\n    \n    if not isinstance(args, StatFSRequest):\n        raise TypeError(\"Invalid argument type.\")\n\n    for path in args.paths:\n        yield UnixVolume(os.statvfs(path))\n\"\"\nimport os\nimport platform\nfrom rdf_client_action import StatFSRequest\nfrom rdf_client_fs import UnixVolume"
    },
    {
        "original": "\ndef strip_prompt(a_string):\n    return a_string.rstrip()\n",
        "rewrite": "\"\ndef strip_prompt(a_string):\n    return a_string.rstrip()\n\"\"\ndef strip_prompt(a_string):\n    return a_string.rstrip()\n\"\"\ndef strip_prompt(a_string):\n    return a_string.rstrip()\n\"\"\ndef strip_prompt(a_string):\n    return a_string.rstrip()\n\""
    },
    {
        "original": "\ndef fgrad_y_psi(self, y, return_covar_chain=False):\n    # TO DO: implement the function to calculate the gradient of f w.r.t to y and psi\n    # The function should return a NxIx4 tensor of partial derivatives\n    pass\n",
        "rewrite": "\"\ndef fgrad_y_psi(self, y, return_covar_chain=False):\n    # TO DO: implement the function to calculate the gradient of f w.r.t to y and psi\n    # The function should return a NxIx4 tensor of partial derivatives\n    pass\n\"\"\ndef fgrad_y_psi(self, y, return_covar_chain=False):\n    # TO DO: implement the function to calculate the gradient of f w.r.t to y and psi"
    },
    {
        "original": "\nclass DeviceSpecs:\n    def __init__(self):\n        self.specs = {\n            '1Q': {},\n            '2Q': {}\n        }\n\n    def add_spec(self, qubit_type, qubit_id, spec_name, spec_value):\n        if qubit_type not in self.specs:\n            self.specs[qubit_type] = {}\n        if qubit_id not in self.specs[qubit_type]:\n            self.specs[qubit_type][qubit_id",
        "rewrite": " \"\nclass DeviceSpecs:\n    def __init__(self):\n        self.specs = {\n            '1Q': {},\n            '2Q': {}\n        }\n\n    def add_spec(self, qubit_type, qubit_id, spec_name, spec_value):\n        if qubit_type not in self.specs:\n            self.specs[qubit_type] = {}\n        if qubit_id not in self.specs[qubit_type]:\n            self.specs[qubit_type][qubit_id] = {}\n        self.specs[qubit_type][qubit_id][spec_name] = spec_value\n\n    def get_spec(self, q"
    },
    {
        "original": "\ndef languages(self, **kwargs):\n    # Initialize an empty dictionary to store language usages\n    language_usages = {}\n    \n    # Send request to GitLab API to get repository information\n    repo_info = self.git.getrepository(**.kwargs)\n    \n    # Iterate over each file in the repository\n    for file in repo_info['tree']:\n        # Check if file is not a directory\n        if 'blob' in file['type']:\n            # Get file extension (language)\n",
        "rewrite": " \"\ndef languages(self, **kwargs):\n    # Initialize an empty dictionary to store language usages\n    language_usages = {}\n    \n    # Send request to GitLab API to get repository information\n    repo_info = self.git.getrepository(**.kwargs())\n    \n    # Iterate over each file in the repository\n    for file in repo_info['tree']:\n        # Check if file is not a directory\n        if 'blob' in file['type']:\n            # Get file extension (language)\n            lang = os.path.splitext(file['path'])[1][1:]\n            \n            # Increment count for current language usage\n            if lang in"
    },
    {
        "original": "\nclass WorksheetManager:\n    def __init__(self):\n        self.worksheets = {}\n\n    def add_worksheet(self, id, name):\n        self.worksheets[id] = {'name': name}\n\n    def get_worksheet(self, id_or_name):\n        if isinstance(id_or_name, int):\n            return self.worksheets.get(id_or_name)\n        else:\n            for worksheet in self.worksheets.values():\n                if worksheet['name'] == id_or_name:\n                    return worksheet\n",
        "rewrite": " \"\nclass WorksheetManager:\n    def __init__(self):\n        self.worksheets = {}\n\n    def add_worksheet(self, id, name):\n        self.worksheets[id] = {'name': name}\n\n    def get_worksheet(self, id_or_name):\n        if isinstance(id_or_name, int):\n            return self.worksheets.get(id_or_name)\n        else:\n            for worksheet in self.worksheets.values():\n                if worksheet['name'] == id_or_name:\n                    return worksheet\n\"\"\nclass WorksheetManager:\n    def __init__(self):\n        self"
    },
    {
        "original": "\nimport boto3\nimport base64\n\ndef encrypt(key_id, plaintext, encryption_context=None, grant_tokens=None, region=None, key=None, keyid=None, profile=None):\n    kms = boto3.client('kms', region_name=region)\n    response = kms.encrypt(\n        KeyId=key_id,\n        Plaintext=plaintext.encode('utf-8'),\n        EncryptionContext=encryption_context\n    )\n    return base64.b64encode(response['CiphertextBlob']).decode('",
        "rewrite": " \"\nimport boto3\nimport base64\n\ndef encrypt(key_id, plaintext, encryption_context=None, grant_tokens=None, region=None, key=None, keyid=None, profile=None):\n    kms = boto3.client('kms', region_name=region)\n    response = kms.encrypt(\n        KeyId=key_id,\n        Plaintext=plaintext.encode('utf-8'),\n        EncryptionContext=encryption_context\n    )\n    return base64.b64encode(response['CiphertextBlob']).decode('utf-8')\n    \"\"\nimport boto3\nimport base64"
    },
    {
        "original": "\ndef configure_scraper(self, scraper_config):\n    self.scraper = scraper_config['scraper']\n    self.endpoint = scraper_config['endpoint']\n",
        "rewrite": "\"\ndef configure_scraper(self, scraper_config):\n    self.scraper = scraper_config['scraper']\n    self.endpoint = scraper_config['endpoint']\n\"\"\ndef configure_scraper(self, scraper_config):\n    self.scraper = scraper_config['scraper']\n    self.endpoint = scraper_config['endpoint']\n\"\"\ndef configure_scraper(self, scraper_config):\n    self.scraper = scraper_config['scraper"
    },
    {
        "original": "\nclass Padding:\n    def __init__(self, paddings):\n        self.paddings = paddings\n\n    def padding(self):\n        if len(set(self.paddings)) == 1:\n            return self.paddings[0]\n        else:\n            raise ValueError(\"If different padding algorithms are used for different dimensions.\")\n",
        "rewrite": "\"\nclass Padding:\n    def __init__(self, paddings):\n        self.paddings = paddings\n\n    def padding(self):\n        if len(set(self.paddings)) == 1:\n            return self.paddings[0]\n        else:\n            raise ValueError(\"If different padding algorithms are used for different dimensions.\")\n\"\"\nclass Padding:\n    def __init__(self, paddings):\n        self.paddings = paddings\n\n    def padding(self):"
    },
    {
        "original": "\ndef ramping_values(period=360):\n    i = 0\n    while True:\n        yield i / period if i < period / 2 else (period - i) / period if i < period else (i - period * ((i // period) + 1)) / period + ((i // period) % 2)\n        i += 1 if i < period * ((i // period) + 1) else -(i - period * ((i // period",
        "rewrite": " \"\ndef ramping_values(period=360):\n    i = 0\n    while True:\n        yield i / period if i < period / 2 else (period - i) / period if i < period else (i - period * ((i // period) + 1)) / period + ((i // period) % 2)\n        i += 1 if i < period * ((i // period) + 1) else -(i - period * ((i // period) + 1))\n\"\"\ndef ramping_values(period=360"
    },
    {
        "original": "\ndef get_args(cls, dist, header=None):\n    for ep in dist.entry_points:\n        if ep.group in ('console_scripts', 'gui_scripts'):\n            yield (ep.name, ep.module_name, ep.func_name)\n",
        "rewrite": "\"\ndef get_args(cls, dist, header=None):\n    for ep in dist.entry_points:\n        if ep.group in ('console_scripts', 'gui_scripts'):\n            yield (ep.name, ep.module_name, ep.func_name)\n\"\"\ndef get_args(cls, dist, header=None):\n    for ep in dist.entry_points:\n        if ep.group in ('console_scripts', 'gui_scripts'):\n            yield (ep.name, ep.module_name, ep.func_name)\n\""
    },
    {
        "original": "\nimport requests\nfrom github import Github\n\nclass GithubApi:\n    def __init__(self, token):\n        self.github = Github(token)\n\n    def get_starred_gists(self):\n        gists = self.github.get_user().get_starred()\n        return gists\n",
        "rewrite": "\"\nimport requests\nfrom github import Github\n\nclass GithubApi:\n    def __init__(self, token):\n        self.github = Github(token)\n\n    def get_starred_gists(self):\n        gists = self.github.get_user().get_starred()\n        return gists\n\"\"\nimport requests\nfrom github import Github\n\nclass GithubApi:\n    def __init__(self, token):\n        self.github = Github(token)\n\n    def get_starred_gists(self):\n"
    },
    {
        "original": "\nimport pychromecast\n\ndef get_device_status(host, services=None, zconf=None):\n    \"\"\"\n    :param host: Hostname or ip to fetch status from\n    :type host: str\n    :return: The device status as a named tuple.\n    :rtype: pychromecast.dial.DeviceStatus or None\n    \"\"\"\n    casts, browser = pychromecast.get_listed_chromecasts(friendly_names=[host], services=services, zerosconf=zconf",
        "rewrite": " \"\nimport pychromecast\n\ndef get_device_status(host, services=None, zconf=None):\n    \"\"\"\n    :param host: Hostname or ip to fetch status from\n    :type host: str\n    :return: The device status as a named tuple.\n    :rtype: pychromecast.dial.DeviceStatus or None\n    \"\"\"\n    casts, browser = pychromecast.get_listed_chromecasts(friendly_names=[host], services=services, zerosconf=zconf)\n    if not casts:\n        return None\n    cast = casts[0]\n    cast.wait()\n    return cast.device_status\n```"
    },
    {
        "original": "\ndef _get_unique_links(page_url, soup):\n    unique_links = set()\n    tags_toHref = [\"a\", \"link\"]\n    tags_toSrc = [\"img\", \"script\"]\n\n    for tag_type in tags_toHref:\n        for tag in soup.find_all(tag_type):\n            href = tag.get(\"href\")\n            if href:\n                unique_links.add(href)\n\n    for tag_type in tags_toSrc:\n        for tag in soup.find_all(tag_type):\n            src = tag",
        "rewrite": " \"\ndef _get_unique_links(page_url, soup):\n    unique_links = set()\n    tags_toHref = [\"a\", \"link\"]\n    tags_toSrc = [\"img\", \"script\"]\n\n    for tag_type in tags_toHref:\n        for tag in soup.find_all(tag_type):\n            href = tag.get(\"href\")\n            if href:\n                unique_links.add(href)\n\n    for tag_type in tags_toSrc:\n        for tag in soup.find_all(tag_type):\n            src = tag.get(\"src\")\n            if src:\n                unique_links.add(src)\n\n    return unique_links\n"
    },
    {
        "original": "\ndef update_grads(self, X, dL_dW, a, b):\n    dW_da = b * (1 - X**a)**(b - 1) * X**a * np.log(X)\n    dW_db = - (1 - X**a)**b * np.log(1 - X**a)\n    dL_da = dL_dW * dW_da\n    dL_db = dL_dW * dW_db\n",
        "rewrite": " \"\ndef update_grads(self, X, dL_dW, a, b):\n    dW_da = b * (1 - X**a)**(b - 1) * X**a * np.log(X)\n    dW_db = - (1 - X**a)**b * np.log(1 - X**a)\n    dL_da = dL_dW * dW_da\n    dL_db = dL_dW * dW_db\n\"\"\ndef update_grads(self, X, dL_dW"
    },
    {
        "original": "\ndef user_exists_in_group(user_name, group_name, region=None, key=None, keyid=None, profile=None):\n    import boto3\n    iam = boto3.client('iam', region_name=region, aws_access_key_id=key, aws_secret_access_key=keyid, profile_name=profile)\n    try:\n        response = iam.get_group(GroupName=group_name)\n        for user in response['Users']:\n            if user['UserName'] == user_name:\n                return True\n",
        "rewrite": "\"\ndef user_exists_in_group(user_name, group_name, region=None, key=None, keyid=None, profile=None):\n    import boto3\n    iam = boto3.client('iam', region_name=region, aws_access_key_id=key, aws_secret_access_key=keyid, profile_name=profile)\n    try:\n        response = iam.get_group(GroupName=group_name)\n        for user in response['Users']:\n            if user['UserName'] == user_name:\n                return True\n\""
    },
    {
        "original": "\n\nimport subprocess\ndef start(name, runas=None):\n    command = [\"launchctl\", \"start\"]\n    \n    if runas:\n        command.append(\"asu\")\n        command.append(runas)\n        \n    command.append(name)\n    \n    try:\n        subprocess.check_call(command)\n        return True\n    except subprocess.CalledProcessError as e:\n        print(f\"Failed to start {name}: {e}\")\n        return False\n\n",
        "rewrite": " \"\n\nimport subprocess\ndef start(name, runas=None):\n    command = [\"launchctl\", \"start\"]\n    \n    if runas:\n        command.append(\"asu\")\n        command.append(runas)\n        \n    command.append(name)\n    \n    try:\n        subprocess.check_call(command)\n        return True\n    except subprocess.CalledProcessError as e:\n        print(f\"Failed to start {name}: {e}\")\n        return False\n\n\"\"\n\nimport subprocess\ndef start(name, runas=None):\n    command = [\"launchctl\", \"start\"]\n    \n    if"
    },
    {
        "original": "\nimport matplotlib.pyplot as plt\n\ndef plot_densities(self, ax=None):\n    if ax is None:\n        fig, ax = plt.subplots()\n    else:\n        fig = ax.get_figure()\n    \n    # assuming self.densities is a list of density values\n    x_values = range(len(self.densities))\n    ax.plot(x_values, self.densities)\n    \n    return fig\n",
        "rewrite": "\"\nimport matplotlib.pyplot as plt\n\ndef plot_densities(self, ax=None):\n    if ax is None:\n        fig, ax = plt.subplots()\n    else:\n        fig = ax.get_figure()\n    \n    # assuming self.densities is a list of density values\n    x_values = range(len(self.densities))\n    ax.plot(x_values, self.densities)\n    \n    return fig\n\"\"\nimport matplotlib.pyplot as plt\n\ndef plot_densities(self"
    },
    {
        "original": "\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef align_subplots(N, M, xlim=None, ylim=None):\n    fig, axs = plt.subplots(N, M)\n    \n    if xlim is not None:\n        for i in range(N):\n            for j in range(M):\n                axs[i,j].set_xlim(xlim)\n                \n    if ylim is not None:\n        for i in range(N):\n            for j in range(M):\n                axs[i,j].set_ylim(",
        "rewrite": "\"\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef align_subplots(N, M, xlim=None, ylim=None):\n    fig, axs = plt.subplots(N, M)\n    \n    if xlim is not None:\n        for i in range(N):\n            for j in range(M):\n                axs[i,j].set_xlim(xlim)\n                \n    if ylim is not None:\n        for i in range(N):\n            for j in range(M):\n                axs[i,j].set_ylim(\""
    },
    {
        "original": "\nPROTOCOL_VERSION = 1\n\nasync def set_protocol_version(protocol_version: int) -> None:\n    global PROTOCOL_VERSION\n    if protocol_version in [1, 2]:\n        PROTOCOL_VERSION = protocol_version\n    else:\n        raise ValueError(\"Invalid protocol version. Supported versions are 1 and 2.\")\n",
        "rewrite": "\"PROTOCOL_VERSION = 1 async def set_protocol_version(protocol_version: int) -> None: global PROTOCOL_VERSION if protocol_version in [1, 2]: PROTOCOL_VERSION = protocol_version else: raise ValueError(\"Invalid protocol version. Supported versions are 1 and 2.\")\"\"PROTOCOL_VERSION = 1 async def set_protocol_version(protocol_version: int) -> None: global PROTOCOL_VERSION if protocol_version in [1, 2]: PROTOCOL_VERSION ="
    },
    {
        "original": "\nimport math\nfrom typing import Union\n\nclass Point2:\n    def __init__(self, x: int, y: int):\n        self.x = x\n        self.y = y\n\n    def distance_to_point2(self, p2: \"Point2\") -> Union[int, float]:\n        return math.sqrt((self.x - p2.x) ** 2 + (self.y - p2.y) ** 2)\n",
        "rewrite": " \"\nimport math\nfrom typing import Union\n\nclass Point2:\n    def __init__(self, x: int, y: int):\n        self.x = x\n        self.y = y\n\n    def distance_to_point2(self, p2: \"Point2\") -> Union[int, float]:\n        return math.sqrt((self.x - p2.x) ** 2 + (self.y - p2.y) ** 2)\n\"\"\nimport math\nfrom typing import Union\n\nclass Point2:\n    def __init__(self, x: int"
    },
    {
        "original": "\ndef analyze(self, text, tokenizer=str.split):\n    res = {}\n    tokens = tokenizer(text)\n    res['words'] = tokens\n    res['char_count'] = sum(len(word) for word in tokens)\n    res['word_count'] = len(tokens)\n    return res\n",
        "rewrite": "\"\ndef analyze(self, text, tokenizer=str.split):\n    res = {}\n    tokens = tokenizer(text)\n    res['words'] = tokens\n    res['char_count'] = sum(len(word) for word in tokens)\n    res['word_count'] = len(tokens)\n    return res\n\"\"\ndef analyze(self, text, tokenizer=str.split):\n    res = {}\n    tokens = tokenizer(text)\n    res['words'] = tokens\n    res['char_count'] = sum"
    },
    {
        "original": "\ndef header(settings):\n    header_str = \"\\\\documentclass{article}\\n\"\n    header_str += \"\\\\usepackage{tikz}\\n\"\n    header_str += \"\\\\usetikzlibrary{arrows.meta, positioning, calc}\\n\"\n    header_str += \"\\\\tikzset{\\n\"\n    for key, value in settings.items():\n        header_str += f\"    {key}/.style={{{value}}},\\n\"\n    header_str += \"}\\n\"\n    return",
        "rewrite": " \"\ndef header(settings):\n    header_str = \"\\\\documentclass{article}\\n\"\n    header_str += \"\\\\usepackage{tikz}\\n\"\n    header_str += \"\\\\usetikzlibrary{arrows.meta, positioning, calc}\\n\"\n    header_str += \"\\\\tikzset{\\n\"\n    for key, value in settings.items():\n        header_str += f\"    {key}/.style={{{value}}},\\n\"\n    header_str += \"}\\n\"\n    return header_str\n    \"\"\"\n    return header_str\n\"\ndef"
    },
    {
        "original": "\ndef _is_process_filtered(self, process, key=None):\n    if key is None:\n        return False\n    if key not in process:\n        return False\n    if not self.filter:\n        return False\n    if any(word in process[key] for word in self.filter):\n        return True\n    return False\n",
        "rewrite": "\"\ndef _is_process_filtered(self, process, key=None):\n    if key is None:\n        return False\n    if key not in process:\n        return False\n    if not self.filter:\n        return False\n    if any(word in process[key] for word in self.filter):\n        return True\n    return False\n\"\"\ndef _is_process_filtered(self, process, key=None):\n    if key is None:\n        return False\n    if key not in process:"
    },
    {
        "original": "\nimport praw\n\ndef from_id(reddit_session, subreddit_id):\n    reddit = praw.Reddit(client_id='your_client_id', \n                         client_secret='your_client_secret', \n                         user_agent='your_user_agent')\n    reddit.config.store(reddit_session)\n    submission = reddit.submission(id=subreddit_id)\n    return submission\n",
        "rewrite": "\"\nimport praw\n\ndef from_id(reddit_session, subreddit_id):\n    reddit = praw.Reddit(client_id='your_client_id', \n                         client_secret='your_client_secret', \n                         user_agent='your_user_agent')\n    reddit.config.store(reddit_session)\n    submission = reddit.submission(id=subreddit_id)\n    return submission\n\"\"\nimport praw\n\ndef from_id(reddit_session, subreddit_id):\n    reddit = praw.Reddit(client_id='your_client_id',"
    },
    {
        "original": "\nimport random\nimport string\n\nclass RandomLetterGenerator:\n    def random_letters(self, length=16):\n        return ''.join(random.choice(string.ascii_letters) for _ in range(length))\n",
        "rewrite": "\"\nimport random\nimport string\n\nclass RandomLetterGenerator:\n    def random_letters(self, length=16):\n        return ''.join(random.choice(string.ascii_letters) for _ in range(length))\n\"\"\nimport random\nimport string\n\nclass RandomLetterGenerator:\n    def random_letters(self, length=16):\n        return ''.join(random.choice(string.ascii_letters) for _ in range(length))\n\"\"\nimport random"
    }
]
