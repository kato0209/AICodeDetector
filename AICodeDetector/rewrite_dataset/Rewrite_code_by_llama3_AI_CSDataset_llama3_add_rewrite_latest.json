[
    {
        "original": "```python\nfrom kafka import KafkaConsumer\n\ndef beginning_offsets(partitions):\n    consumer = KafkaConsumer()\n    offsets = {}\n    for p in partitions:\n        topic_partition = p.topic, p.partition\n        try:\n            offset = consumer.beginning_offset(topic_partition)\n            offsets[p] = offset\n        except Exception as e:\n            if isinstance(e, UnsupportedVersionError) or isinstance(e, KafkaTimeoutError):\n                raise e\n    return offsets\n```",
        "rewrite": "```python\nfrom kafka import KafkaConsumer\nfrom kafka.errors import UnsupportedVersionError, KafkaTimeoutError\n\ndef beginning_offsets(partitions):\n    consumer = KafkaConsumer()\n    try:\n        offsets = consumer.beginning_offsets({topic_partition for p in partitions}) or {}\n        return {p: offsets.get((p.topic, p.partition), None) for p in partitions}\n    except (UnsupportedVersionError, KafkaTimeoutError) as e:\n        raise e\n```"
    },
    {
        "original": "```\ndef _get_values(cls, diff_dict, type='new'):\n    return {key: value[0] if type == 'new' else value[1] for key, value in diff_dict.items() if len(value) == 2}\n```",
        "rewrite": "```python\ndef _get_values(cls, diff_dict, type='new'):\n    new_value = 0 if type == 'new' else 1\n    return {key: value[new_value] for key, value in diff_dict.items() if len(value) == 2}\n```"
    },
    {
        "original": "```\ndef get_ref(cls, state, obj_alloc_id, field_class_name, field_name, field_type):\n    \"\"\"\n    Resolve the field within the given state.\n    \"\"\"\n    obj = state[obj_alloc_id]\n    if not hasattr(obj, field_class_name):\n        raise AttributeError(f\"Object {obj_alloc_id} does not have class {field_class_name}\")\n    field_cls = getattr(obj, field_class_name)\n    if not hasattr(field_cls, field_name):\n        raise AttributeError(f\"",
        "rewrite": "```python\ndef get_ref(cls, state, obj_alloc_id, field_class_name, field_name, field_type):\n    obj = state[obj_alloc_id]\n    if not hasattr(obj, field_class_name):\n        raise AttributeError(f\"Object {obj_alloc_id} does not have class {field_class_name}\")\n    cls_field = getattr(obj, field_class_name)\n    if not isinstance(cls_field.get(field_name), field_type):\n        raise TypeError(f\"Field {field_name} in Object {obj_alloc_id} does not match type\")\n    return cls_field[field_name]\n```"
    },
    {
        "original": "```\ndef pd_coords(self, comp):\n    n_elements = len(comp)\n    coords = [0] * (n_elements - 1)\n    sum_comp = sum(comp)\n    \n    for i in range(n_elements - 1):\n        coords[i] = comp[i] / sum_comp\n    \n    return coords\n```",
        "rewrite": "```python\ndef pd_coords(self, comp):\n    total = sum(comp)\n    return [x / total for x in comp[:-1]]\n```"
    },
    {
        "original": "```\ndef relative_ref(self, baseURI):\n    base_path = baseURI.split('/')\n    target_path = self.path.split('/')\n    i = 0\n    while i < len(base_path) and i < len(target_path) and base_path[i] == target_path[i]:\n        i += 1\n    rel_ref = '../' * (len(base_path) - i) + '/'.join(target_path[i:])\n    return rel_ref if rel_ref else '.'\n```",
        "rewrite": "```python\ndef relative_ref(self, baseURI):\n    base_path = baseURI.split('/')\n    target_path = self.path.split('/')\n    common_prefix_len = len(commonprefix([base_path, target_path]))\n    rel_ref = '../' * (len(base_path) - common_prefix_len) + '/'.join(target_path[common_prefix_len:])\n    return rel_ref if rel_ref else '.'\n\nfrom itertools import zip_longest\n\ndef commonprefix(m):\n    s1 = min(m)\n    s2 = max(m)\n    for i, c in enumerate(s1):\n        if c != s2[i]:\n            return s1"
    },
    {
        "original": "```\ndef is_enhanced_rr_cap_valid(self):\n    open_messages_sent = self.open_messages_sent\n    open_messages_received = self.open_messages_received\n\n    if open_messages_sent and open_messages_received:\n        return 'enhanced-route-refresh-capability' in open_messages_sent and 'enhanced-route-refresh-capability' in open_messages_received\n    else:\n        return False\n```",
        "rewrite": "```python\ndef is_enhanced_rr_cap_valid(self):\n    return (\n        'enhanced-route-refresh-capability' in self.open_messages_sent \n        or 'enhanced-route-refresh-capability' not in self.open_messages_sent\n    ) and (\n        'enhanced-route-refresh-capability' in self.open_messages_received \n        or 'enhanced-route-refresh-capability' not in self\topen_messages_received\n    )\n```"
    },
    {
        "original": "```\ndef parse_osm_nodes_paths(osm_data):\n    nodes = {}\n    paths = {}\n\n    if 'elements' in osm_data:\n        for element in osm_data['elements']:\n            if element['type'] == 'node':\n                nodes[element['id']] = element\n            elif element['type'] == 'way':\n                way_id = element['id']\n                ways_tags = {k: v for k, v in element.items() if k != 'nodes' and k !=",
        "rewrite": "```python\ndef parse_osm_nodes_paths(osm_data):\n    nodes = {}\n    paths = {}\n\n    if 'elements' in osm_data:\n        for element in osm_data['elements']:\n            if element['type'] == 'node':\n                nodes[element['id']] = {**element}\n            elif element['type'] == 'way':\n                way_id = element['id']\n                ways_tags = {k: v for k, v in element.items() if k not in ['nodes']}\n                paths[way_id] = {**element, **ways_tags}\n    \n    return nodes, paths\n```"
    },
    {
        "original": "```python\nfrom pymatgen import Molecule as MoleculeClass\nfrom itertools import permutations\n\ndef get_best_electronegativity_anonymous_mapping(struct1, struct2):\n    # Get all possible permutations of mapping between species of two structures\n    perms = list(permutations(range(len(struct2.species)), len(struct1.species)))\n\n    # Initialize minimum difference in electronegativity and best mapping\n    min_diff = float('inf')\n    best_mapping = None\n\n    # Iterate over",
        "rewrite": "```python\nfrom pymatgen import Molecule as MoleculeClass\nfrom itertools import permutations\n\ndef get_best_electronegativity_anonymous_mapping(struct1, struct2):\n    perms = list(permutations(range(len(struct2.species)), len(struct1.species)))\n\n    min_diff = float('inf')\n    best_mapping = None\n\n    for p in perms:\n        diff = sum(\n            abs(MoleculeClass.from_sites(struct1.species[i]).electronegativity \n                 - MoleculeClass.from_sites(struct2.species[p[i]]).electronegativity)\n            for i in range(len(p))\n        )\n\n        if diff"
    },
    {
        "original": "```\nfrom typing import Callable, Tuple\n\nclass HPackHeaders:\n    pass\n\nclass HPackIndexedHdr(HPackHeaders):\n    pass\n\nclass HPackLitHdrFldWithoutIndexing(HPackHeaders):\n    pass\n\nclass HPackLitHdrFldWithIncrIndexing(HPackHeaders):\n    pass\n\n\ndef _convert_a_header_to_a_h2_header(\n    hdr_name: str,\n    hdr_value: str,\n    is_sensitive: Callable[[str, str], bool",
        "rewrite": "```python\nfrom typing import Callable, Tuple\n\nclass HPackHeaders:\n    \"\"\"Base class for HPack headers.\"\"\"\n    \nclass HPackIndexedHdr(HPackHeaders):\n    \"\"\"Represents an indexed header in HPack.\"\"\"\n    \nclass HPackLitHdrFldWithoutIndexing(HPackHeaders):\n    \"\"\"Represents a literal header field without indexing in HPack.\"\"\"\n    \nclass HPackLitHdrFldWithIncrIndexing(HPackHeaders):\n    \"\"\"Represents a literal header field with incremental indexing in HPack.\"\"\"\n\n\ndef convert_to_h2_header(\n    hdr_name: str,\n    hdr_value: str,\n   "
    },
    {
        "original": "```python\nclass BigchainTransactionCreator:\n    def create(cls, tx_signers, recipients, metadata=None, asset=None):\n        from bigchaindb.common.transaction import Transaction\n        \n        # Initialize an empty transaction object \n        transaction = Transaction()\n\n        # Set transaction type to 'CREATE'\n        transaction.operation = 'CREATE'\n\n        # Add signers to transaction inputs \n        for signer in tx_signers:\n            transaction.add_input(signer)\n\n        # Add recipients and amounts to transaction outputs \n       ",
        "rewrite": "```python\nclass BigchainTransactionCreator:\n    @classmethod\n    def create(cls, tx_signers, recipients, metadata=None, asset=None):\n        from bigchaindb.common.transaction import Transaction\n\n        transaction = Transaction()\n        transaction.operation = 'CREATE'\n\n        for signer in tx_signers:\n            transaction.add_input(signer)\n\n        if isinstance(recipients, dict):\n            for recipient, amount in recipients.items():\n                transaction.add_output(amount, [recipient])\n        elif isinstance(recipients, list):\n            for recipient_dict in recipients:\n                if isinstance(recipient_dict['amount'], dict) or not all(isset(v) for v in"
    },
    {
        "original": "```\nfrom datetime import datetime\nimport pytz\n\ndef utc_dt_to_local_dt(dtm):\n    utc_dt = datetime.strptime(dtm, '%Y-%m-%d %H:%M:%S')\n    utc_dt = utc_dt.replace(tzinfo=pytz.UTC)\n    local_dt = utc_dt.astimezone()\n    return local_dt.strftime('%Y-%m-%d %H:%M:%S %Z%z')\n```",
        "rewrite": "```python\nfrom datetime import datetime\n\ndef utc_dt_to_local_dt(dtm):\n    from_zone = 'UTC'\n    to_zone = 'local' \n    utc_dt = datetime.strptime(dtm, '%Y-%m-%d %H:%M:%S') \n    local_dt = utc_dt\n    if not local_dt.tzinfo:\n        from pytz import timezone\n        local_tz=timezone(from_zone)\n        local_root_tz=timezone('America/New_York')\n        # Note: some zones as MST7MDT will fail here;\n        \n        return (local_root_tz.normalize(local_root_tz"
    },
    {
        "original": "```\ndef _getScriptSettingsFrom IniFile(policy_info):\n    # Open and read the file\n    with open(policy_info, 'r') as f:\n        content = f.read()\n\n    # Initialize variables\n    scripts = {}\n    current_script = None\n\n    # Parse lines\n    for line in content.splitlines():\n        line = line.strip()\n        \n        if line.startswith('[') and ']' in line:\n            # Section header found, extract script name\n            start_br",
        "rewrite": "```python\nimport configparser\n\ndef get_script_settings_from_ini_file(policy_info):\n    config = configparser.ConfigParser()\n    config.read(policy_info)\n    \n    scripts = {}\n    for section in config.sections():\n        scripts[section] = dict(config.items(section))\n    \n    return scripts\n\n# Alternatively, to manually parse the file without using configparser:\n\ndef _get_script_settings_from_ini_file_manual(policy_info):\n    with open(policy_info, 'r') as f:\n        content = f.read().splitlines()\n\n    scripts = {}\n    current_script = None\n\n    for line in content:\n        line = line.strip()\n        \n        if line.startswith"
    },
    {
        "original": "```\ndef _get_triplet_scores(self, triangles_list):\n    scores = {}\n    for triangle in triangles_list:\n        triangle_set = frozenset(triangle)\n        # assuming the score calculation is a placeholder, replace with actual logic\n        score = len(triangle) * 2.0\n        scores[triangle_set] = score\n    return scores\n```",
        "rewrite": "```python\ndef _get_triplet_scores(self, triangles_list):\n    scores = {}\n    for triangle in triangles_list:\n        scores[frozenset(triangle)] = len(triangle) * 2.0\n    return scores\n```"
    },
    {
        "original": "```\nasync def vcx_messages_update_status(msg_json: str):\n    import json\n    import asyncio\n    from aiohttp import ClientSession\n\n    async with ClientSession() as session:\n        msg_data = json.loads(msg_json)\n        connection_id = msg_data['connection_id']\n        messages = msg_data['messages']\n\n        for message in messages:\n            url = f'https://example.com/update_message_status/{connection_id}'\n            data = {'message_id': message['uid'], 'status",
        "rewrite": "```python\nimport json\nfrom aiohttp import ClientSession\n\nasync def vcx_messages_update_status(msg_json: str) -> None:\n    async with ClientSession() as session:\n        data = json.loads(msg_json)\n        connection_id = data['connection_id']\n        messages = data['messages']\n\n        for message in messages:\n            url = f'https://example.com/update_message_status/{connection_id}'\n            payload = {'message_id': message['uid'], 'status': 'read'}  # status value assumed to be 'read'\n            async with session.post(url, json=payload) as response:\n                if response.status !="
    },
    {
        "original": "```\nimport socket\nimport time\n\nclass IsoTPSocket:\n    def __init__(self):\n        self.receive_buffer = b''\n\n    def recv_with_timeout(self, timeout=1):\n        start_time = time.time()\n        while True:\n            if self.receive_buffer:\n                return self.receive_buffer.pop(0)\n            elif time.time() - start_time > timeout:\n                return None\n```",
        "rewrite": "```python\nimport socket\nimport time\n\nclass IsoTPSocket:\n    def __init__(self):\n        self.receive_buffer = bytearray()\n\n    def recv_with_timeout(self, timeout=1):\n        start_time = time.time()\n        while True:\n            if self.receive_buffer:\n                return bytes([self.receive_buffer.pop(0)])\n            elif time.time() - start_time > timeout:\n                return None\n```\n\nHowever, considering the problem might require receiving more than a byte from a socket and for actual use with sockets the proper way is to receive data directly from it (and also include how that would be done here).\n```python"
    },
    {
        "original": "```\nimport math\n\ndef carmichael_of_factorized(f_list):\n    lambda_val = 1\n    for p, e in f_list:\n        lambda_val = lcm(lambda_val, (p-1) * (p**(e-1)))\n    return lambda_val\n\ndef gcd(a, b):\n    while b:\n        a, b = b, a % b\n    return a\n\ndef lcm(a, b):\n    return a * b // gcd(a, b)\n```",
        "rewrite": "```python\nimport math\n\ndef carmichael_of_factorized(f_list):\n    lambda_val = 1\n    for p, e in f_list:\n        if p == 2 and e > 2:\n            lambda_val = lcm(lambda_val, 2**(e-2))\n        else:\n            lambda_val = lcm(lambda_val, (p-1) * (p**(e-1)))\n    return lambda_val\n\ndef gcd(a, b):\n    while b:\n        a, b = b, a % b\n    return abs(a)\n\ndef lcm(a, b):\n    return abs((a * b)"
    },
    {
        "original": "```\nimport requests\n\ndef absent(name, profile=\"splunk\"):\n    url = f\"https://{profile}.com/api/services/search/jobs/{name}\"\n    response = requests.delete(url, auth=(\"username\", \"password\"))\n    if response.status_code == 200:\n        return True\n    else:\n        return False\n```",
        "rewrite": "```python\nimport requests\n\ndef delete_job(name: str, profile: str = \"splunk\", auth_tuple: tuple = (\"username\", \"password\")) -> bool:\n    url = f\"https://{profile}.com/api/services/search/jobs/{name}\"\n    response = requests.delete(url, auth=auth_tuple)\n    return response.status_code == 200\n```"
    },
    {
        "original": "```\ndef GetNotificationsForAllShards(self, queue):\n    notifications = []\n    for shard in self.GetShardNames(queue):\n        notifications.extend(self.GetNotificationsForShard(queue, shard))\n    return notifications\n```",
        "rewrite": "```python\ndef get_notifications_for_all_shards(self, queue):\n    return [\n        notification\n        for shard in self.get_shard_names(queue)\n        for notification in self.get_notifications_for_shard(queue, shard)\n    ]\n```"
    },
    {
        "original": "```\nfrom sympy import symbols, Eq, solve\n\nclass FunctionMatcher:\n    def __init__(self, functions):\n        self.functions = functions\n\n    def differing_functions_with_consts(self):\n        matches = []\n        for i in range(len(self.functions)):\n            for j in range(i + 1, len(self.functions)):\n                x = symbols('x')\n                eq1 = Eq(eval(self.functions[i]), 0)\n                eq2 = Eq(eval(self.functions[j]), 0)\n               ",
        "rewrite": "```python\nfrom sympy import symbols, Eq, solve\n\nclass FunctionMatcher:\n    def __init__(self, functions):\n        self.functions = functions\n\n    def differing_functions_with_consts(self):\n        matches = []\n        x = symbols('x')\n        for i in range(len(self.functions)):\n            for j in range(i + 1, len(self.functions)):\n                eq1 = Eq(eval(self.functions[i]), 0)\n                eq2 = Eq(eval(self.functions[j]), 0)\n                sol1 = solve(eq1, x)\n                sol2 = solve(eq2, x)\n                if len(sol1) > "
    },
    {
        "original": "```\nclass EOPatchSaver:\n    def save(self, eopatch, use_tmp=True):\n        if use_tmp:\n            # Save to temporary file\n            with open(\"temp.eopatch\", \"wb\") as f:\n                pickle.dump(eopatch, f)\n        else:\n            # Save to intended location\n            with open(\"eopatch.eopatch\", \"wb\") as f:\n                pickle.dump(eopatch, f)\n```",
        "rewrite": "```python\nimport pickle\nfrom tempfile import NamedTemporaryFile\n\nclass EOPatchSaver:\n    def __init__(self, target_filename=\"eopatch.eopatch\"):\n        self.target_filename = target_filename\n\n    def save(self, eopatch, use_tmp=True):\n        if use_tmp:\n            with NamedTemporaryFile(mode=\"wb\", suffix=\".eopatch\", delete=False) as tmp_file:\n                pickle.dump(eopatch, tmp_file)\n                return tmp_file.name\n        else:\n            with open(self.target_filename, \"wb\") as f:\n                pickle.dump(eopatch, f)\n```"
    },
    {
        "original": "```\nclass StateTrie:\n    def __init__(self):\n        self.trie = {}\n\n    def _addAttr(self, txn, isCommitted=False) -> None:\n        did, attribute_name, data_type, data = txn\n        if data_type == 'RAW':\n            key = f\"{did}{attribute_name}\"\n            self.trie[key] = hash(data)\n        elif data_type == 'ENC':\n            key = f\"{did}{hash(attribute_name)}\"\n            self.tr",
        "rewrite": "```python\nclass StateTrie:\n    def __init__(self):\n        self.trie = {}\n\n    def _addAttr(self, txn, isCommitted=False) -> None:\n        did, attribute_name, data_type, data = txn\n        if data_type == 'RAW':\n            key = f\"{did}{attribute_name}\"\n            self.trie[key] = hash(data)\n        elif data_type == 'ENC':\n            key = f\"{did}{hash(attribute_name)}\"\n            self.trie[key] = hash(data)\n\n    def add_txn(self, did: str, attribute_name: str, data_type: str,"
    },
    {
        "original": "```\nimport os\nimport zipfile\nimport xml.etree.ElementTree as ET\n\ndef _find_packages(root):\n    for subdir, dirs, files in os.walk(root):\n        for file in files:\n            if file.endswith('.zip'):\n                zf = zipfile.ZipFile(os.path.join(subdir, file))\n                pkg_xml = ET.parse(zf.open('package.xml')).getroot()\n                yield (pkg_xml, zf, os.path.relpath(subdir, root))\n```",
        "rewrite": "```python\nimport os\nimport zipfile\nfrom xml.etree import ElementTree as ET\n\ndef find_packages(root):\n    for subdir, dirs, files in os.walk(root):\n        for file in (f for f in files if f.endswith('.zip')):\n            with zipfile.ZipFile(os.path.join(subdir, file)) as zf:\n                pkg_xml = ET.parse(zf.open('package.xml')).getroot()\n                yield pkg_xml, zf, os.path.relpath(subdir, root)\n```"
    },
    {
        "original": "```\nimport bluetooth\n\ndef srbt1(bt_address, pkts, *_args={}, **_kargs={}):\n    sock = bluetoothAMP.get_socket()\n    sock.connect((bt_address, 1))\n    sock.send(pkts)\n    data = sock.recv(1024)\n    return data\n```",
        "rewrite": "```python\nimport bluetooth\n\ndef srbt1(bt_address: str, packets: bytes, *args, **kwargs) -> bytes:\n    with bluetoothAMP.get_socket() as sock:\n        sock.connect((bt_address, 1))\n        sock.sendall(packets)\n        return sock.recv(1024)\n```"
    },
    {
        "original": "```\nimport socket\nimport netifaces\n\nclass NetworkInterface:\n    def GetIPAddresses(self):\n        ip_array = []\n        for interface in netifaces.interfaces():\n            if interface == 'lo':  # ignore loopback interface\n                continue\n            lst = netifaces.ifaddresses(interface)\n            teste = {}\n            for item in lst:\n                if(item == 2): # AF_INET \n                    for thing in lst[item]:\n                        teste={\n                            \"iname\":interface,\n                           ",
        "rewrite": "```python\nimport socket\nimport netifaces\n\nclass NetworkInterface:\n    def get_ip_addresses(self):\n        ip_array = []\n        for interface in netifaces.interfaces():\n            if interface == 'lo':\n                continue\n            lst = netifaces.ifaddresses(interface)\n            ip_dictionary = {}\n            if 2 in lst: \n                for link in lst[2]:\n                    ip_dictionary.update({\n                        \"iname\": interface,\n                        \"ip_address\": link.get('addr'),\n                        \"netmask\": link.get('netmask'),\n                        \"broadcast\": link.get('broadcast')\n                    })\n                    ip_array.append(ip_dictionary.copy())\n"
    },
    {
        "original": "```\ndef operate(self, point):\n    # Assuming operate function is defined elsewhere\n    pass\n\ndef are_symmetrically_related(self, point_a, point_b, tol=0.001):\n    \"\"\"\n    Checks if two points are symmetrically related.\n\n    Args:\n        point_a (3x1 array): First point.\n        point_b (3x1 array): Second point.\n        tol (float): Absolute tolerance for checking distance.\n\n    Returns:\n        True if self.operate(point",
        "rewrite": "```python\ndef are_symmetrically_related(self, point_a, point_b, tol=0.001):\n    \"\"\"\n    Checks if two points are symmetrically related.\n\n    Args:\n        point_a (3x1 array): First point.\n        point_b (3x1 array): Second point.\n        tol (float): Absolute tolerance for checking distance.\n\n    Returns:\n        bool: True if self.operate(point_a) is close to -point_b within the given tolerance.\n    \"\"\"\n    operated_point = self.operate(point_a)\n    return np.allclose(operated_point, -point_b, atol=tol)\n"
    },
    {
        "original": "```\ndef validate_rpc_host(ip):\n    \"\"\"\n    Validates the given ip for use as RPC server address.\n    \"\"\"\n    parts = ip.split(\".\")\n    if len(parts) != 4:\n        return False\n    for part in parts:\n        if not part.isdigit():\n            return False\n        i = int(part)\n        if i < 0 or i > 255:\n            return False\n    return True\n```",
        "rewrite": "```python\ndef validate_rpc_host(ip):\n    parts = ip.split(\".\")\n    return len(parts) == 4 and all(0 <= int(part) <= 255 for part in parts if part.isdigit())\n```"
    },
    {
        "original": "```python\nimport subprocess\nimport logging\n\ndef find_available_interfaces():\n    \"\"\"\n    Returns the names of all open can/vcan interfaces using\n    the ``ip link list`` command. If the lookup fails, an error\n    is logged to the console and an empty list is returned.\n\n    :rtype: an iterable of :class:`str`\n    \"\"\"\n    \n    try:\n        output = subprocess.check_output([\"ip\", \"link\", \"list\"])\n        lines = output.decode(\"utf-",
        "rewrite": "```python\nimport subprocess\n\ndef find_available_interfaces():\n    try:\n        output = subprocess.check_output([\"ip\", \"link\", \"show\"])\n        interfaces = [line.split(\":\")[1].strip() for line in output.decode(\"utf-8\").splitlines() if \"can\" in line or \"vcan\" in line]\n        return interfaces\n    except subprocess.CalledProcessError as e:\n        print(f\"Error looking up available can/vcan interfaces: {e}\")\n        return []\n```"
    },
    {
        "original": "```\nclass Server:\n    def __init__(self, namespace=None):\n        self.namespace = namespace\n        self.sessions = {}\n\n    def save_session(self, sid, session, namespace=None):\n        if namespace is None:\n            namespace = self.namespace\n        if namespace not in self.sessions:\n            self.sessions[namespace] = {}\n        self.sessions[namespace][sid] = session\n```",
        "rewrite": "```python\nclass Server:\n    def __init__(self, namespace: str = None):\n        self.namespace = namespace\n        self.sessions: dict[str, dict[str, object]] = {}\n\n    def save_session(self, sid: str, session: object, namespace: str = None) -> None:\n        if namespace is None:\n            namespace = self.namespace\n        if not hasattr(self.sessions.get(namespace), '__getitem__'):\n            self.sessions[namespace] = {}\n        self.sessions[namespace][sid] = session\n\n```"
    },
    {
        "original": "```\nfrom cryptography.hazmat.backends import default_backend\nfrom cryptography.hazmat.primitives import serialization\n\ndef get_public_keys_der_v3(self):\n    public_keys = []\n    if self.v3_signature_block:\n        for cert in self.v3_signature_block.certs:\n            pub_key = cert.public_key()\n            der_pub_key = pub_key.public_bytes(\n                encoding=serialization.Encoding.DER,\n                format=serialization.PublicFormat.SubjectPublicKeyInfo\n            )\n            public_keys.append(der",
        "rewrite": "```python\nfrom cryptography.hazmat.backends import default_backend\nfrom cryptography.hazmat.primitives import serialization\n\ndef get_public_keys_der_v3(self):\n    public_keys = [cert.public_key().public_bytes(\n        encoding=serialization.Encoding.DER,\n        format=serialization.PublicFormat.SubjectPublicKeyInfo\n    ) for cert in self.v3_signature_block.certs]\n```"
    },
    {
        "original": "```\ndef chemical_symbols(atom_species, symbol_length):\n    symbols = []\n    ascii_offset = 97  # ASCII value of 'a'\n    for i in range(atom_species):\n        symbol = \"\"\n        for j in range(symbol_length):\n            symbol += chr(ascii_offset + ((i + j) % 26))\n        symbols.append(symbol)\n    return symbols\n```",
        "rewrite": "```python\ndef generate_chemical_symbols(n, length):\n    \"\"\"Generate chemical symbols for n atom species.\"\"\"\n    symbols = []\n    offset = ord('a')\n    \n    for i in range(n):\n        symbol = ''.join(chr(offset + (i + j) % 26) for j in range(length))\n        symbols.append(symbol.capitalize())\n        \n    return symbols\n```"
    },
    {
        "original": "```\nimport yaml\n\ndef safe_dump_all(documents, stream=None, **kwds):\n    if stream is None:\n        return yaml.safe_dump_all(documents, default_flow_style=True, **kwds)\n    else:\n        yaml.safe_dump_all(documents, stream=stream, default_flow_style=True, **kwds)\n```",
        "rewrite": "```python\nimport yaml\n\ndef safe_dump_all(documents, stream=None, **kwds):\n    return yaml.safe_dump_all(\n        documents, \n        stream=stream or None, \n        default_flow_style=True, \n        **kwds\n    )\n```"
    },
    {
        "original": "```\nfrom typing import Iterator, Union\nimport numpy as np\nfrom cirq import Circuit\n\ndef _simulator_iterator(circuit: Circuit,\n                        param_resolver,\n                        qubit_order,\n                        initial_state: Union[int, np.ndarray]) -> Iterator:\n    # Check if initial_state is an integer \n    if isinstance(initial_state, int):\n      # Set initial_state to computational basis corresponding to this integer \n      pass\n  \n    # Check if initial_state is a numpy array  \n    elif isinstance",
        "rewrite": "```python\nfrom typing import Iterator, Union\nimport numpy as np\nfrom cirq import Circuit\n\ndef _simulator_iterator(circuit: Circuit,\n                        param_resolver,\n                        qubit_order,\n                        initial_state: Union[int, np.ndarray]) -> Iterator:\n    if isinstance(initial_state, int):\n        initial_state = np.zeros(circuit.num_qubits(), dtype=np.complex128)\n        initial_state[initial_state] = 1.0\n    \n    elif isinstance(initial_state, np.ndarray):\n        if len(initial_state.shape) > 1 and initial_state.shape[0] != initial_state.shape[1]:\n            raise ValueError"
    },
    {
        "original": "```\ndef predictive_variance(self, mu, variance, predictive_mean=None, Y_metadata=None):\n    if predictive_mean is None:\n      # If no predictive mean is provided assume it's 0\n      predictive_mean = 0  \n    expectation_squared = (mu - predictive_mean) ** 2 \n    variance_squared = variance ** 2 \n    return expectation_squared + variance_squared\n```",
        "rewrite": "```python\ndef predictive_variance(self, mu, variance, predictive_mean=0, Y_metadata=None):\n    return (mu - predictive_mean) ** 2 + variance + variance ** 2\n```"
    },
    {
        "original": "```\nclass DockerConfigManager:\n    def __init__(self):\n        self.configs = {}\n\n    def remove_config(self, id):\n        if id in self.configs:\n            del self.configs[id]\n            return True\n        else:\n            raise docker.errors.NotFound(\"No config with that ID exists\")\n```",
        "rewrite": "```python\nclass DockerConfigManager:\n    def __init__(self):\n        self.configs = {}\n\n    def remove_config(self, id):\n        try:\n            del self.configs[id]\n            return True\n        except KeyError:\n            raise docker.errors.NotFound(\"No config with that ID exists\")\n```"
    },
    {
        "original": "```\ndef get_mor_by_moid(si, obj_type, obj_moid):\n    \"\"\"\n    Get reference to an object of specified object type and id\n\n    si\n        ServiceInstance for the vSphere or ESXi server (see get_service_instance)\n\n    obj_type\n        Type of the object (vim.StoragePod, vim.Datastore, etc)\n\n    obj_moid\n        ID of the object\n    \"\"\"\n    \n```python    \nimport pyVmomi\n    \ndef get_service_instance():\n",
        "rewrite": "```python\nimport pyVmomi\n\ndef get_service_instance():\n    host = input(\"Enter the vSphere or ESXi server IP address: \")\n    username = input(\"Enter your username: \")\n    password = input(\"Enter your password: \")\n\n    try:\n        si = pyVmomi.SmartConnectNoSSL(host=host, user=username, pwd=password)\n        return si\n    except Exception as e:\n        print(f\"Connection failure - {e}\")\n        return None\n\ndef get_mor_by_moid(si, obj_type, obj_moid):\n# Get reference to an object of specified object type and id    \nget"
    },
    {
        "original": "```\ndef ConfigureUrls(config, external_hostname = None):\n    if external_hostname is None:\n        external_hostname = input(\"Enter the external hostname: \")\n    config[\"AdminUI.url\"] = f\"http://{external_hostname}:8000\"\n    config[\"Client.frontend_url\"] = f\"http://{external_hostname}:8080\"\n    config[\"ClientPoll.url\"] = f\"http://{external_hostname}:8081\"\n    return config\n```",
        "rewrite": "```python\ndef configure_urls(config, external_hostname: str = None) -> dict:\n    if external_hostname is None:\n        external_hostname = input(\"Enter the external hostname: \")\n    \n    port_config = {\n        \"AdminUI\": 8000,\n        \"Client.frontend_url\": 8080,\n        \"ClientPoll.url\": 8081\n    }\n    \n    for config_key, port in port_config.items():\n        config[config_key] = f\"http://{external_hostname}:{port}\"\n    \n    return config\n```"
    },
    {
        "original": "```\nclass Parser:\n    def __init__(self):\n        self.knowledge_base = {}\n\n    def Parse(self, cmd, args, stdout, stderr, return_val, time_taken):\n        self.knowledge_base[cmd] = {\n            'args': args,\n            'stdout': stdout,\n            'stderr': stderr,\n            'return_val': return_val,\n            'time_taken': time_taken\n        }\n```",
        "rewrite": "```python\nclass Parser:\n    def __init__(self):\n        self.commands = {}\n\n    def parse_command(self, command, arguments, stdout, stderr, exit_code, execution_time):\n        self.commands[command] = {\n            'arguments': arguments,\n            'stdout': stdout,\n            'stderr': stderr,\n            'exit_code': exit_code,\n            'execution_time': execution_time\n        }\n```"
    },
    {
        "original": "```\ndef load_skel(self, file_name):\n    with open(file_name, 'r') as f:\n        content = f.read()\n        # parse ASF content into skeleton structure\n        # TO DO: implement parsing logic\n        pass\n```",
        "rewrite": "```python\ndef load_skel(self, file_name):\n    try:\n        with open(file_name, 'r') as f:\n            content = f.read()\n            lines = content.split('\\n')\n            skeleton_structure = {}\n            for line in lines:\n                if line.startswith(':root'):\n                    skeleton_structure['root'] = {}\n                elif ' begin:' in line and ':JOINT' in line.upper():\n                    joint_name = line.split(':')[1].strip()\n                    skeleton_structure['root'].setdefault('joints', {})\n                    skeleton_structure['root']['joints'][joint_name] = {}\n                elif 'joint' in line"
    },
    {
        "original": "```\ndef _ruby_installed(ret, ruby, user=None):\n    if user is not None:\n        cmd = f\"su {user} -c 'ruby -v | grep {ruby}'\"\n    else:\n        cmd = f\"ruby -v | grep {ruby}\"\n    ret[\"installed\"] = True if os.system(cmd) == 0 else False\n```",
        "rewrite": "```python\ndef ruby_installed(ret, ruby, user=None):\n    cmd = f\"ruby -v | grep {ruby}\"\n    if user:\n        cmd = f\"su {user} -c '{cmd}'\"\n    ret[\"installed\"] = os.system(cmd) == 0\n```"
    },
    {
        "original": "```\nclass Structure:\n    # assuming Structure class is defined somewhere\n    pass\n\nclass Element:\n    # assuming Element class is defined somewhere\n    pass\n\ndef get_projection_on_elements(self, structure):\n    \"\"\"\n    Method returning a dictionary of projections on elements.\n\n    Args:\n        structure (Structure): Input structure.\n\n    Returns:\n        A dictionary in the {Spin.up:[k index][b index][{Element:values}]}\n    \"\"\"\n    \n    projection = {}\n    \n    # iterate over",
        "rewrite": "```python\nclass Structure:\n    # assuming Structure class is defined somewhere\n    pass\n\nclass Element:\n    # assuming Element class is defined somewhere\n    pass\n\ndef get_projection_on_elements(self, structure: Structure) -> dict[str, list[list[dict[Element, float]]]]:\n    \"\"\"\n    Method returning a dictionary of projections on elements.\n\n    Args:\n        structure (Structure): Input structure.\n\n    Returns:\n        A dictionary in the {Spin.up:[k index][b index][{Element:values}]}\n    \"\"\"\n    \n     projection = {\"Spin.up\": []}\n     \n     for k_index in range(len(structure)):\n"
    },
    {
        "original": "```\nclass VectorArgs:\n    def __init__(self, *args):\n        self.args = args\n\n    def vector_args(self):\n        lanes = self.args.split(',')\n        lane_pairs = [lane.split('..') for lane in lanes]\n        lane_pairs.sort(key=lambda x: int(x[1]), reverse=True)\n        return [(int(pair[0]), int(pair[1])) for pair in lane_pairs]\n\n# Example usage:\nvector_args_instance = VectorArgs('0..10,",
        "rewrite": "```python\nclass VectorArgs:\n    def __init__(self, vector_str):\n        self.vector_str = vector_str\n\n    def extract_vector_args(self):\n        lane_pairs = [lane.split('..') for lane in self.vector_str.replace('\"', '').split(',')]\n        return sorted([tuple(map(int, pair)) for pair in lane_pairs], key=lambda x: x[1], reverse=True)\n\n# Example usage:\nvector_args_instance = VectorArgs('0..10,5..15')\nprint(vector_args_instance.extract_vector_args())\n```"
    },
    {
        "original": "```\ndef kwargs_from_keyword(from_kwargs, to_kwargs, keyword, clean_origin=True):\n    for key, value in list(from_kwargs.items()):\n        if key.startswith(keyword + '_'):\n            to_kwargs[key.replace(keyword + '_', '')] = value\n            if clean_origin:\n                del from_kwargs[key]\n    return to_kwargs\n```",
        "rewrite": "```python\ndef kwargs_from_keyword(from_kwargs, to_kwargs, keyword, clean_origin=True):\n    for key in list(key for key in from_kwargs if key.startswith(keyword + '_')):\n        new_key = key[len(keyword) + 1:]\n        to_kwargs[new_key] = from_kwargs[key]\n        if clean_origin:\n            del from_kwargs[key]\n    return to_kwargs\n```"
    },
    {
        "original": "```\nclass ActionExecutor:\n    def __init__(self):\n        self.actions = {}\n\n    def register_action(self, action_name, func):\n        self.actions[action_name] = func\n\n    def _RunAction(self, rule, client_id):\n        count = 0\n        for action in rule['actions']:\n            if action['name'] in self.actions:\n                self.actions[action['name']](client_id)\n                count += 1\n        return count\n```",
        "rewrite": "```python\nfrom typing import Dict, Callable\n\nclass ActionExecutor:\n    def __init__(self):\n        self.actions: CALLABLE_DICT = {}\n\n    def register_action(self, action_name: str, func: Callable) -> None:\n        self.actions[action_name] = func\n\n    def run_actions(self, rule: Dict, client_id) -> int:\n        count = 0\n        for action in rule.get('actions', []):\n            if 'name' in action and action['name'] in self.actions:\n                self.actions[action['name']](client_id)\n                count += 1\n        return count\n\nCALL"
    },
    {
        "original": "```\nimport docker\n\nclass DockerClient:\n    def __init__(self):\n        self.client = docker.from_env()\n\n    def df(self):\n        try:\n            info = self.client.info()\n            return {\n                'Images': info['Images'],\n                'Containers': info['Containers'],\n                'Volumes': len(self.client.volumes.list()),\n                'Networks': len(self.client.networks.list())\n            }\n        except docker.errors.APIError as e:\n            raise e\n```",
        "rewrite": "```python\nimport docker\n\nclass DockerClient:\n    def __init__(self):\n        try:\n            self.client = docker.from_env()\n        except docker.errors.APIError as e:\n            raise e\n\n    def df(self):\n        try:\n            info = self.client.info()\n            volumes = len(self.client.volumes.list())\n            networks = len(self.client.networks.list())\n\n            return {\n                'Images': info['Images'],\n                'Containers': info['Containers'],\n                'Volumes': volumes,\n                'Networks': networks\n            }\n        except docker.errors.APIError as e:\n            raise DockerException from e\n\n\nclass Docker"
    },
    {
        "original": "```\ndef file_extension(category=None):\n    extensions = {\n        'audio': ['mp3'],\n        'image': ['jpg', 'jpeg', 'png', 'gif'],\n        'office': ['docx', 'pdf', 'pptx'],\n        'text': ['txt', 'doc'],\n        'video': ['mp4']\n    }\n    if category:\n        return extensions.get(category.lower(), [])\n    else:\n        return []\n```",
        "rewrite": "```python\ndef file_extensions(category=None):\n    extensions = {\n        'audio': ['mp3', 'wav', 'ogg'],\n        'image': ['jpg', 'jpeg', 'png', 'gif', 'bmp'],\n        'office': ['docx', 'pdf', 'pptx', 'xlsx'],\n        'text': ['txt', 'doc'],\n        'video': ['mp4']\n    }\n    return extensions.get(category.lower(), []) if category else []\n```"
    },
    {
        "original": "```\ndef _gti_dirint_gte_90(poa_global, aoi, solar_zenith, solar_azimuth,\n                       surface_tilt, times, kt_prime,\n                       pressure=101325., temp_dew=None, albedo=.25):\n    import numpy as np\n    \n    # Calculate air mass\n    am = pressure / (101325 * np.exp(-0.000121 * surface_tilt))\n    \n    # Calculate relative air mass\n    mam = am /",
        "rewrite": "```python\nimport numpy as np\n\ndef gti_dirint_gte_90(\n    poa_global, aoi, solar_zenith, solar_azimuth,\n    surface_tilt, times, kt_prime,\n    pressure=101325., temp_dew=None, albedo=.25\n):\n    am = pressure / (101325 * np.exp(-0.000121 * surface_tilt))\n    rel_am = 1 - (1 - am) / (am + 0.65991)\n    \n    # calculate dirint with hemispherical transmittance model for direct irradiance \n```"
    },
    {
        "original": "```\nclass RDFURN:\n    def __init__(self, value):\n        self.value = value\n\nclass Client:\n    def ListChildren(self, urn, limit=None, age=\"NEWEST_TIME\"):\n        # assuming we have a function get_children that returns all children\n        all_children = self.get_children(urn)\n        \n        if age == \"ALL_TIMES\":\n            filtered_children = all_children\n        elif age == \"NEWEST_TIME\":\n            filtered_children = [all_children[0]]",
        "rewrite": "```python\nclass RDFURN:\n    def __init__(self, value):\n        self.value = value\n\nclass Client:\n    def ListChildren(self, urn: RDFURN, limit: int = None, age: str = \"NEWEST_TIME\") -> list:\n        all_children = self.get_children(urn.value)\n        \n        if age == \"ALL_TIMES\":\n            filtered_children = all_children\n        elif age == \"NEWEST_TIME\":\n            filtered_children = [all_children[0]]\n        \n        if limit is not None and len(filtered_children) > limit:\n            return filtered_children[:limit]\n        \n        return filtered_children\n"
    },
    {
        "original": "```\ndef _convert_validators_to_mapping(validators):\n    validator_mapping = {}\n    for validator in validators:\n        key = (str(validator[\"check\"]), validator[\"comparator\"])\n        validator_mapping[key] = validator\n    return validator_mapping\n```",
        "rewrite": "```python\ndef _convert_validators_to_mapping(validators):\n    return {(str(validator[\"check\"]), validator[\"comparator\"]): validator for validator in validators}\n```"
    },
    {
        "original": "```\ndef InterpolatePath(path, knowledge_base, users=None, path_args=None, depth=0):\n    if path_args is None:\n        path_args = {}\n    if users is None:\n        user_path = knowledge_base.interpolate_string(path, **path_args)\n        return user_path\n    else:\n        result = []\n        for user in users:\n            user_path_args = path_args.copy()\n            user_path_args['user'] = user\n            user_path = knowledge_base.interpolate_string(path",
        "rewrite": "```python\ndef interpolate_path(path, knowledge_base, users=None, path_args=None, depth=0):\n    if path_args is None:\n        path_args = {}\n    \n    if users is None:\n        return knowledge_base.interpolate_string(path, **path_args)\n    \n    result = []\n    for user in users:\n        user_path_args = {**path_args, 'user': user}\n        result.append(knowledge_base.interpolate_string(path, **user_path_args))\n    \n    return result\n```"
    },
    {
        "original": "```\nimport numpy as np\n\ndef _fast_kde(x, cumulative=False, bw=4.5, xmin=None, xmax=None):\n    \n     from scipy.stats import gaussian_kde\n    \n     x = np.array(x)\n     if xmin is None:\n         xmin = np.min(x)\n     if xmax is None:\n         xmax = np.max(x)\n         \n     kde = gaussian_kde(dataset=x[:, np.newaxis], bw_method='silverman')\n     xi = np.linspace(xmin,xmax",
        "rewrite": "```python\nimport numpy as np\nfrom scipy.stats import gaussian_kde\n\ndef _fast_kde(x, cumulative=False, bw=4.5, xmin=None, xmax=None):\n    x = np.array(x)\n    \n    xmin = xmin if xmin is not None else np.min(x)\n    xmax = xmax if xmax is not None else np.max(x)\n    \n    kde = gaussian_kde(dataset=x[:, np.newaxis], bw_method=bw)\n    \n    xi = np.linspace(xmin, xmax, 1000)\n\n    if cumulative:\n        yi = [kde.integrate_box_1d(-np.inf, a"
    },
    {
        "original": "```\ndef md_options_to_metadata(options):\n    metadata = {}\n    language = None\n    for option in options:\n        if option.startswith('language:'):\n            language = option.split('language:')[1].strip()\n        elif '=' in option:\n            key, value = option.split('=', 1)\n            metadata[key.strip()] = value.strip()\n    return language, metadata\n```",
        "rewrite": "```python\ndef md_options_to_metadata(options):\n    metadata = {}\n    language = None\n\n    for option in options:\n        if (match := option.split('language:')) and len(match) > 1:\n            language = match[1].strip()\n        elif '=' in option:\n            key, value = option.split('=', 1)\n            metadata[key.strip()] = value.strip()\n\n    return language, metadata\n```"
    },
    {
        "original": "```\nfrom typing import Optional, Union, List\nfrom enum import Enum\n\nclass TraceKind(Enum):\n    PRECONDITION = 1\n    POSTCONDITION = 2\n\nclass TraceFrame:\n    def __init__(self, caller: str, callee: str, kind: TraceKind):\n        self.caller = caller\n        self.callee = callee\n        self.kind = kind\n\nclass Trace:\n    def __init__(self):\n        self.frames = []\n\n    def add_frame(self,",
        "rewrite": "```python\nfrom typing import Optional, Union, List\nfrom enum import Enum\n\nclass TraceKind(Enum):\n    PRECONDITION = 1\n    POSTCONDITION = 2\n\nclass TraceFrame:\n    caller: str\n    callee: str\n    kind: TraceKind\n\n    def __init__(self, caller: str, callee: str, kind: TraceKind):\n        self.caller = caller\n        self.callee = callee\n        self.kind = kind\n\nclass Trace:\n    frames: List[TraceFrame]\n\n    def __init__(self):\n        self.frames = []\n\n    def add_frame(self, frame: Trace"
    },
    {
        "original": "```\nclass BatchGenerator:\n    def __init__(self, X, Y, batch_size):\n        self.X = X\n        self.Y = Y\n        self.batch_size = batch_size\n        self.index = 0\n\n    def new_batch(self):\n        start = self.index\n        end = min(start + self.batch_size, len(self.X))\n        \n        batch_X = self.X[start:end]\n        batch_Y = self.Y[start:end]\n        \n        self.index += self.batch_size",
        "rewrite": "```python\nclass BatchGenerator:\n    def __init__(self, X, Y, batch_size):\n        self.X = X\n        self.Y = Y\n        self.batch_size = batch_size\n        self.index = 0\n\n    def new_batch(self):\n        start = self.index\n        end = min(start + self.batch_size, len(self.X))\n        \n        batch_X = self.X[start:end]\n        batch_Y = self.Y[start:end]\n        \n        if end == len(self.X):\n            raise StopIteration\n        \n        return batch_X, batch_Y\n\n    def __iter__(self):\n        return self\n    \n    def"
    },
    {
        "original": "```\ndef createSummary(self, log):\n    \"\"\"\n    Create nice summary logs.\n\n    @param log: log to create summary off of.\n    \"\"\"\n    result = {}\n    for entry in log:\n        key = entry['type']\n        if key not in result:\n            result[key] = 1\n        else:\n            result[key] += 1\n    return result\n```",
        "rewrite": "```python\ndef createSummary(self, log):\n    result = {}\n    for entry in log:\n        key = entry['type']\n        result[key] = result.get(key, 0) + 1\n    return result\n```"
    },
    {
        "original": "```\nimport requests\n\nclass GitRepository:\n    def __init__(self):\n        self.url = \"https://api.bitbucket.org/2.0\"\n    \n    def create_branch(self, project_key, repository, name, start_point, message=\"\"):\n        auth_token = (\"your_username\", \"your_password\")\n        \n\t\theaders = {\n\t\t\t\"Content-Type\": \"application/json\"\n\t\t}\n\t\t\n\t\tdata = {\n\t\t\t\"name\": name,\n\t\t\t\"start\": {\n\t\t\t",
        "rewrite": "```python\nimport requests\nfrom urllib.parse import urljoin\n\nclass GitRepository:\n    def __init__(self, username, password):\n        self.url = \"https://api.bitbucket.org/2.0\"\n        self.auth_token = (username, password)\n    \n    def create_branch(self, project_key, repository, name, start_point, message=\"\"):\n        headers = {\n            \"Content-Type\": \"application/json\"\n        }\n        \n        data = {\n            \"name\": name,\n            \"target\": {\n                \"hash\": start_point,\n               Parents: [start_point]\n            },\n            'message': message,\n'"
    },
    {
        "original": "```python\ndef merge_option_dicts(old_opts, new_opts):\n    merged = {}\n    all_keys = set(list(old_OPTS.keys()) + list(new_OPTS.keys()))\n    \n    for key in all_keys:\n        merged[key] = {}\n        \n        if key in old_OPTS:\n            merged[key].update(old_OPTS[key])\n        \n        if key in new_OPTS:\n            merged[key].update(newOpts[key])\n    \n    return merged\n\n# Test case\nold.opts = {'a':{'x':'old','",
        "rewrite": "```python\ndef merge_option_dicts(old_opts, new_opts):\n    merged = {}\n    all_keys = set(list(old_opts.keys()) + list(new_opts.keys()))\n    \n    for key in all_keys:\n        merged[key] = {}\n        \n        if key in old_opts:\n            merged[key].update(old_opts[key])\n        \n        if key in new_opts:\n            merged[key].update(new_opts[key])\n    \n    return merged\n\n# Test case\noldOpts = {'a':{'x':'old','y':'old'}, 'b':{'z':'old'}}\nnewOpts = {'a':{'x':'new'}, 'c':{'w':'new'}"
    },
    {
        "original": "```python\nimport requests\nfrom gitlab.exceptions import GitlabAuthenticationError, GitlabGetError\n\nclass RESTObject:\n    pass\n\nclass GitLabManager:\n    def __init__(self, url, token):\n        self.url = url\n        self.token = token\n\n    def get(self, file_path, ref, **kwargs):\n        headers = {'Authorization': f'Bearer {self.token}'}\n        params = {'ref_name': ref}\n        \n        if 'sudo' in kwargs",
        "rewrite": "```python\nimport requests\nfrom gitlab.exceptions import GitlabAuthenticationError, GitlabGetError\n\nclass RESTObject:\n    pass\n\nclass GitLabManager:\n    def __init__(self, url, token):\n        self.url = url\n        self.token = token\n\n    def get(self, file_path, ref, **kwargs):\n        headers = {'Authorization': f'Bearer {self.token}'}\n        params = {'ref': ref}  # Changed 'ref_name' to 'ref'\n\n        if 'sudo' in kwargs and kwargs['sudo']:\n            sudo_info = kwargs.pop('sudo')\n            params.update({'s"
    },
    {
        "original": "```\ndef clean_recipe_build(self, args):\n    import os\n    import shutil\n    recipe_build_dir = os.path.join('build', args.recipe_name)\n    if os.path.exists(recipe_build_dir):\n        shutil.rmtree(recipe_build_dir)\n    print(f\"Deleted build files for recipe {args.recipe_name}\")\n```",
        "rewrite": "```python\nimport os\nimport shutil\n\ndef clean_recipe_build(self, args):\n    recipe_build_dir = os.path.join('build', args.recipe_name)\n    if os.path.exists(recipe_build_dir) and os.path.isdir(recipe_build_dir):\n        shutil.rmtree(recipe_build_dir)\n        print(f\"Deleted build files for recipe {args.recipe_name}\")\n```"
    },
    {
        "original": "```\ndef calculate_bias_shape(input_shape, bias_dims):\n    if 0 in bias_dims:\n        raise ValueError(\"Cannot add bias over the minibatch dimension\")\n    bias_shape = [input_shape[i] if i in bias_dims else 1 for i in range(len(input_shape))]\n    return tuple(bias_shape)\n```",
        "rewrite": "```python\ndef calculate_bias_shape(input_shape, bias_dims):\n    if 0 in bias_dims:\n        raise ValueError(\"Cannot add bias over the minibatch dimension\")\n    return tuple(input_shape[i] if i in bias_dims else 1 for i in range(len(input_shape)))\n```"
    },
    {
        "original": "```\ndef read_metadata(text, ext):\n    if ext == 'txt':\n        lines = text.split('\\n')\n        metadata = {}\n        for line in lines:\n            if ':' in line:\n                key, value = line.split(':', 1)\n                metadata[key.strip()] = value.strip()\n        return metadata\n    else:\n        return {}\n```",
        "rewrite": "```python\ndef read_metadata(text, ext):\n    if ext != 'txt':\n        return {}\n    metadata = {}\n    for line in text.split('\\n'):\n        key_value = line.split(':', 1)\n        if len(key_value) == 2:\n            metadata[key_value[0].strip()] = key_value[1].strip()\n    return metadata\n```"
    },
    {
        "original": "```\ndef _is_process_filtered(self, process, key=None):\n    \"\"\"\n    Return True if the process[key] should be filtered according to the current filter\n    \"\"\"\n    # Assuming self.filter is set elsewhere in your class\n    if not hasattr(self, 'filter'):\n        raise ValueError(\"Filter is not defined\")\n\n    if key is None:\n        return any(str(d) in str(self.filter) for d in process.values())\n    else:\n        return str(process.get(key)) in str",
        "rewrite": "```python\ndef _is_process_filtered(self, process, key=None):\n    if not hasattr(self, 'filter'):\n        raise ValueError(\"Filter is not defined\")\n\n    if key is None:\n        return any(str(d) in str(self.filter) for d in process.values())\n    else:\n        return str(process.get(key)) in str(self.filter)\n```"
    },
    {
        "original": "```\ndef modulation_type(self, value: int):\n    modulation_types = [\"ASK\", \"FSK\", \"PSK\", \"APSK (QAM)\"]\n    if 0 <= value <= 3:\n        return modulation_types[value]\n    else:\n        return None\n```",
        "rewrite": "```python\ndef modulation_type(self, value: int) -> str | None:\n    modulation_types = [\"ASK\", \"FSK\", \"PSK\", \"APSK (QAM)\"]\n    return modulation_types.get(value)\n```"
    },
    {
        "original": "```\ndef load(self, fname):\n    with open(fname, 'r') as f:\n        self.signatures = [line.strip() for line in f.readlines()]\n```",
        "rewrite": "```python\ndef load(self, fname):\n    with open(fname, 'r') as file:\n        self.signatures = [line.rstrip() for line in file]\n```"
    },
    {
        "original": "```python\nclass Server:\n    def __init__(self):\n        self.rooms = {}\n\n    def enter_room(self, sid, room, namespace=None):\n        if namespace is None:\n            namespace = self.__class__.__name__\n        if room not in self.rooms:\n            self.rooms[room] = set()\n        self.rooms[room].add((sid, namespace))\n```",
        "rewrite": "```python\nclass Server:\n    def __init__(self):\n        self.rooms = {}\n\n    def enter_room(self, sid: str, room: str, namespace: str = None) -> None:\n        namespace = namespace or self.__class__.__name__\n        if room not in self.rooms:\n            self.rooms[room] = set()\n        self.rooms[room].add((sid, namespace))\n```"
    },
    {
        "original": "```\ndef _get_args(self, **):\n    return {key: value for key, value in kwargs.items() if hasattr(self.__class__, key)}\n```",
        "rewrite": "```python\ndef _get_args(self, **kwargs):\n    return {key: value for key, value in kwargs.items() if hasattr(self.__class__, key)}\n```"
    },
    {
        "original": "```\nfrom pyogram import Client\nfrom pyogram.types import Message, InlineKeyboardMarkup, ReplyKeyboardMarkup, ReplyKeyboardRemove, ForceReply\nfrom typing import Union\n\nclass MyClient(Client):\n    def edit_caption(self, caption: str, parse_mode: str = \"\", reply_markup: Union[InlineKeyboardMarkup, ReplyKeyboardMarkup, ReplyKeyboardRemove, ForceReply] = None) -> Message:\n        return self.edit_message_caption(chat_id=self.chat.id, message_id=self.message_id,c",
        "rewrite": "```python\nfrom pyrogram import Client\nfrom pyrogram.types import Message, InlineKeyboardMarkup, ReplyKeyboardMarkup, ReplyKeyboardRemove, ForceReply\nfrom typing import Union\n\nclass MyClient(Client):\n    def edit_caption(self, \n                     caption: str = None,\n                     parse_mode: str = \"\",\n                     reply_markup: Union[InlineKeyboardMarkup, ReplyKeyboardMarkup, ReplyKeyboardRemove, ForceReply] = None,\n                     ) -> Message:\n        return self.edit_message_caption(\n            chat_id=self.chat.id,\n            message_id=self.message_id,\n            caption=caption,\n            parse_mode=parse_mode or \"markdown\",\n           "
    },
    {
        "original": "```\nimport numpy as np\nfrom scipy.linalg import kron\n\ndef _flip_kron_order(mat4x4: np.ndarray) -> np.ndarray:\n    # Get the size of sub-matrices\n    n = int(np.sqrt(mat4x4.shape[0]))\n\n    # Reshape mat4x4 into 3D array (n*n matrices)\n    mats = mat4x4.reshape(n, n, n, n)\n\n    # Flip kron order by swapping last two axes",
        "rewrite": "```python\nimport numpy as np\n\ndef flip_kron_order(mat4x4: np.ndarray) -> np.ndarray:\n    n = int(np.sqrt(mat4x4.shape[0]))\n    return mat4x4.reshape(n, n, n, n).swapaxes(-1, -2).reshape(16, 16)\n```"
    },
    {
        "original": "```\ndef pretty_print_schedule(self, hyperband_schedule, describe_hyperband=True):\n    print(\" Hyper-Band Parameters: \")\n    print(\"     - Try {} possible sets of hyperparameters\".format(len(hyperband_schedule)))\n    if describe_hyperband:\n        print(\"     - With an average of {} iterations per trial\".format(sum([len(trial) for trial in hyperband_schedule]) / len(hyperband_schedule)))\n    print(\"\")\n    \n    max_r = max(max(trial)",
        "rewrite": "```python\ndef pretty_print_schedule(self, hyperband_schedule, describe_hyperband=True):\n    print(\"Hyper-Band Parameters:\")\n    print(f\"     - Try {len(hyperband_schedule)} possible sets of hyperparameters\")\n    \n    if describe_hyperband:\n        average_iterations = sum(len(trial) for trial in hyperband_schedule) / len(hyperband_schedule)\n        print(f\"     - With an average of {average_iterations:.2f} iterations per trial\")\n    \n    max_r = max(max(trial) for trial in hyperband_schedule)\n```"
    },
    {
        "original": "```\nclass Matrix:\n    def __init__(self, a, b, c, d, e, f):\n        self.a = a\n        self.b = b\n        self.c = c\n        self.d = d\n        self.e = e\n        self.f = f\n\n    def shorthand(self):\n        return (self.a, self.b, self.c, self.d, self.e, self.f)\n```",
        "rewrite": "```python\nclass Matrix:\n    def __init__(self, *args):\n        if len(args) != 6:\n            raise ValueError(\"Expected 6 arguments\")\n        self.values = args\n\n    def shorthand(self):\n        return self.values\n```"
    },
    {
        "original": "```python\ndef is_cyclic(graph):\n    visited = set()\n    rec_stack = set()\n\n    def dfs(node):\n        visited.add(node)\n        rec_stack.add(node)\n\n        for neighbor in graph.get(node, []):\n            if neighbor not in visited:\n                if dfs(neighbor):\n                    return True\n            elif neighbor in rec_stack:\n                return True\n\n        rec_stack.remove(node)\n        return False\n\n    for node in graph:\n        if node not in visited:\n            if dfs",
        "rewrite": "```python\ndef is_cyclic(graph):\n    visited = set()\n    rec_stack = set()\n\n    def dfs(node):\n        visited.add(node)\n        rec_stack.add(node)\n\n        for neighbor in graph.get(node, []):\n            if neighbor not in visited:\n                if dfs(neighbor):\n                    return True\n            elif neighbor in rec_stack:\n                return True\n\n        rec_stack.remove(node)\n        return False\n\n    for node in graph:\n        if node not in visited:\n            if dfs(node):\n                return True\n\n    return False\n```\n\nHowever this implementation can further improved as shown below. We combine 'visited' and"
    },
    {
        "original": "```python\nfrom email import policy\nfrom email.parser import BytesParser\n\ndef get_header_items(self):\n    \"\"\"Get an iterable list of key/value pairs representing headers.\"\"\"\n    parser = BytesParser(policy=policy.default)\n    msg = parser.parsestr(self.request_text)\n    return [(k, v) for k, v in msg.items()]\n```",
        "rewrite": "```python\nfrom email import policy\nfrom email.parser import BytesParser\n\ndef get_header_items(self):\n    parser = BytesParser(policy=policy.default)\n    msg = parser.parsebytes(self.request_text.encode())\n    return list(msg.items())\n```"
    }
]